{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 00: Introduction to ML Systems\n",
    "\n",
    "Welcome to the first tutorial in our comprehensive ML System Design series! This tutorial provides the foundation for understanding the difference between building ML models and building production-ready ML systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Understand** the difference between ML algorithms and ML systems\n",
    "2. **Identify** components of production-ready ML systems\n",
    "3. **Learn** the 7-step ML system design framework\n",
    "4. **Decide** when to use ML vs traditional approaches\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by importing the necessary libraries for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For visualizations\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ML Algorithms vs ML Systems\n",
    "\n",
    "### What's the Difference?\n",
    "\n",
    "When many people think about machine learning, they focus on the **algorithm** - the model that learns patterns from data. However, in production environments, the algorithm is just one piece of a much larger puzzle.\n",
    "\n",
    "| Aspect | ML Algorithm | ML System |\n",
    "|--------|-------------|----------|\n",
    "| **Focus** | Mathematical model | End-to-end solution |\n",
    "| **Input** | Clean, prepared data | Raw, messy real-world data |\n",
    "| **Output** | Predictions | Actionable results |\n",
    "| **Environment** | Jupyter notebook | Production infrastructure |\n",
    "| **Concern** | Accuracy | Accuracy + Latency + Cost + Reliability |\n",
    "| **Lifecycle** | Train once | Continuous improvement |\n",
    "\n",
    "### The \"Tiny Box\" Analogy\n",
    "\n",
    "In a famous paper from Google, researchers showed that ML code (the algorithm) represents only a small fraction of a real-world ML system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: ML Code as a fraction of ML System\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Components of an ML System with their relative sizes\n",
    "components = {\n",
    "    'Data Collection': 15,\n",
    "    'Data Verification': 10,\n",
    "    'Feature Engineering': 15,\n",
    "    'ML Code': 5,  # The algorithm itself\n",
    "    'Configuration': 8,\n",
    "    'Serving Infrastructure': 15,\n",
    "    'Monitoring': 12,\n",
    "    'Resource Management': 10,\n",
    "    'Process Management': 10\n",
    "}\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "colors = ['#3498db' if k != 'ML Code' else '#e74c3c' for k in components.keys()]\n",
    "bars = ax.barh(list(components.keys()), list(components.values()), color=colors)\n",
    "\n",
    "# Highlight the ML Code bar\n",
    "ax.axvline(x=5, color='#e74c3c', linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Relative Effort/Complexity (%)', fontsize=12)\n",
    "ax.set_title('Components of a Production ML System\\n(ML Code is just ~5% of the total effort!)', fontsize=14)\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars, components.values()):\n",
    "    ax.text(value + 0.5, bar.get_y() + bar.get_height()/2, f'{value}%', \n",
    "            va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight: The actual ML algorithm is typically only ~5% of a production ML system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Example: Movie Recommendation\n",
    "\n",
    "Let's compare building a recommendation algorithm vs. a recommendation system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Algorithm-focused approach\n",
    "class SimpleRecommendationAlgorithm:\n",
    "    \"\"\"A simple collaborative filtering algorithm - just the 'ML Code' part\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.user_item_matrix = None\n",
    "        self.similarity_matrix = None\n",
    "    \n",
    "    def fit(self, ratings_matrix):\n",
    "        \"\"\"Train the model on user-item ratings\"\"\"\n",
    "        self.user_item_matrix = ratings_matrix\n",
    "        # Calculate item-item similarity using cosine similarity\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        self.similarity_matrix = cosine_similarity(ratings_matrix.T)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"Predict rating for a user-item pair\"\"\"\n",
    "        # Get items the user has rated\n",
    "        user_ratings = self.user_item_matrix[user_id]\n",
    "        # Weight by similarity\n",
    "        similarities = self.similarity_matrix[item_id]\n",
    "        weighted_sum = np.dot(user_ratings, similarities)\n",
    "        similarity_sum = np.sum(np.abs(similarities))\n",
    "        return weighted_sum / similarity_sum if similarity_sum > 0 else 0\n",
    "\n",
    "# Demo with sample data\n",
    "np.random.seed(42)\n",
    "sample_ratings = np.random.randint(0, 6, (10, 20))  # 10 users, 20 movies\n",
    "\n",
    "algo = SimpleRecommendationAlgorithm()\n",
    "algo.fit(sample_ratings)\n",
    "\n",
    "# Predict rating for user 0, item 5\n",
    "predicted_rating = algo.predict(0, 5)\n",
    "print(f\"üìä Algorithm predicts user 0 would rate movie 5: {predicted_rating:.2f}\")\n",
    "print(\"\\n‚ö†Ô∏è  This is JUST the algorithm. A production system needs much more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: System-focused approach (conceptual outline)\n",
    "class RecommendationSystemOutline:\n",
    "    \"\"\"Conceptual outline of a production recommendation system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.components = {\n",
    "            'data_ingestion': {\n",
    "                'description': 'Collect user interactions, ratings, clicks',\n",
    "                'technologies': ['Kafka', 'Kinesis', 'Spark Streaming'],\n",
    "                'considerations': ['Real-time vs batch', 'Data volume', 'Schema evolution']\n",
    "            },\n",
    "            'data_storage': {\n",
    "                'description': 'Store raw and processed data',\n",
    "                'technologies': ['PostgreSQL', 'Redis', 'S3', 'Feature Store'],\n",
    "                'considerations': ['Query patterns', 'Storage costs', 'Data retention']\n",
    "            },\n",
    "            'feature_engineering': {\n",
    "                'description': 'Transform raw data into ML features',\n",
    "                'technologies': ['Spark', 'Pandas', 'Feature Store'],\n",
    "                'considerations': ['Feature freshness', 'Consistency', 'Scalability']\n",
    "            },\n",
    "            'model_training': {\n",
    "                'description': 'Train and update recommendation models',\n",
    "                'technologies': ['PyTorch', 'TensorFlow', 'XGBoost'],\n",
    "                'considerations': ['Training frequency', 'Hyperparameter tuning', 'Versioning']\n",
    "            },\n",
    "            'model_serving': {\n",
    "                'description': 'Serve predictions with low latency',\n",
    "                'technologies': ['TorchServe', 'TensorFlow Serving', 'FastAPI'],\n",
    "                'considerations': ['Latency SLA', 'Throughput', 'Caching']\n",
    "            },\n",
    "            'monitoring': {\n",
    "                'description': 'Track system health and model performance',\n",
    "                'technologies': ['Prometheus', 'Grafana', 'DataDog'],\n",
    "                'considerations': ['Alerting', 'Drift detection', 'A/B testing']\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def describe(self):\n",
    "        \"\"\"Print system components\"\"\"\n",
    "        print(\"üèóÔ∏è  Production Recommendation System Components:\\n\")\n",
    "        for name, details in self.components.items():\n",
    "            print(f\"üì¶ {name.upper()}\")\n",
    "            print(f\"   Description: {details['description']}\")\n",
    "            print(f\"   Technologies: {', '.join(details['technologies'])}\")\n",
    "            print(f\"   Key Considerations: {', '.join(details['considerations'])}\")\n",
    "            print()\n",
    "\n",
    "system = RecommendationSystemOutline()\n",
    "system.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Components of Production ML Systems\n",
    "\n",
    "A production ML system consists of several interconnected components. Let's explore each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: ML System Architecture\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axis('off')\n",
    "\n",
    "# Define boxes for each component\n",
    "boxes = [\n",
    "    # Data Stack\n",
    "    {'name': 'Data Sources', 'x': 5, 'y': 75, 'w': 18, 'h': 20, 'color': '#3498db'},\n",
    "    {'name': 'Data\\nProcessing', 'x': 28, 'y': 75, 'w': 18, 'h': 20, 'color': '#3498db'},\n",
    "    {'name': 'Feature\\nStore', 'x': 51, 'y': 75, 'w': 18, 'h': 20, 'color': '#3498db'},\n",
    "    \n",
    "    # Model Stack\n",
    "    {'name': 'Model\\nTraining', 'x': 28, 'y': 45, 'w': 18, 'h': 20, 'color': '#e74c3c'},\n",
    "    {'name': 'Model\\nRegistry', 'x': 51, 'y': 45, 'w': 18, 'h': 20, 'color': '#e74c3c'},\n",
    "    \n",
    "    # Serving Stack\n",
    "    {'name': 'Model\\nServing', 'x': 74, 'y': 60, 'w': 18, 'h': 25, 'color': '#2ecc71'},\n",
    "    \n",
    "    # Monitoring Stack\n",
    "    {'name': 'Monitoring\\n& Logging', 'x': 28, 'y': 10, 'w': 41, 'h': 20, 'color': '#9b59b6'},\n",
    "]\n",
    "\n",
    "for box in boxes:\n",
    "    rect = plt.Rectangle((box['x'], box['y']), box['w'], box['h'], \n",
    "                         facecolor=box['color'], edgecolor='white', \n",
    "                         linewidth=2, alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(box['x'] + box['w']/2, box['y'] + box['h']/2, box['name'],\n",
    "            ha='center', va='center', fontsize=11, color='white', fontweight='bold')\n",
    "\n",
    "# Add arrows\n",
    "arrows = [\n",
    "    (23, 85, 5, 0),   # Data Sources -> Data Processing\n",
    "    (46, 85, 5, 0),   # Data Processing -> Feature Store\n",
    "    (60, 75, 0, -10), # Feature Store -> Model Training\n",
    "    (46, 55, 5, 0),   # Model Training -> Model Registry\n",
    "    (69, 55, 5, 5),   # Model Registry -> Model Serving\n",
    "    (69, 82, 5, 0),   # Feature Store -> Model Serving\n",
    "    (83, 60, 0, -20), # Model Serving -> Monitoring\n",
    "]\n",
    "\n",
    "for arrow in arrows:\n",
    "    ax.annotate('', xy=(arrow[0]+arrow[2], arrow[1]+arrow[3]), \n",
    "                xytext=(arrow[0], arrow[1]),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=2))\n",
    "\n",
    "# Add labels for stacks\n",
    "ax.text(5, 98, 'DATA STACK', fontsize=12, fontweight='bold', color='#3498db')\n",
    "ax.text(28, 68, 'MODEL STACK', fontsize=12, fontweight='bold', color='#e74c3c')\n",
    "ax.text(74, 88, 'SERVING\\nSTACK', fontsize=12, fontweight='bold', color='#2ecc71')\n",
    "ax.text(28, 33, 'MONITORING STACK', fontsize=12, fontweight='bold', color='#9b59b6')\n",
    "\n",
    "ax.set_title('Production ML System Architecture', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Stack\n",
    "\n",
    "The **Data Stack** handles everything related to data collection, processing, and storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Data Stack Components\n",
    "\n",
    "data_stack = {\n",
    "    \"Data Sources\": {\n",
    "        \"types\": [\n",
    "            \"User interactions (clicks, views, purchases)\",\n",
    "            \"Content metadata (titles, descriptions)\",\n",
    "            \"User profiles (demographics, preferences)\",\n",
    "            \"External data (3rd party, APIs)\"\n",
    "        ],\n",
    "        \"key_questions\": [\n",
    "            \"Where does the data come from?\",\n",
    "            \"What's the data freshness requirement?\",\n",
    "            \"How much data do we have?\"\n",
    "        ]\n",
    "    },\n",
    "    \"Data Processing\": {\n",
    "        \"steps\": [\n",
    "            \"Data validation and cleaning\",\n",
    "            \"Data transformation (ETL)\",\n",
    "            \"Data aggregation\",\n",
    "            \"Feature computation\"\n",
    "        ],\n",
    "        \"tools\": [\"Apache Spark\", \"Apache Flink\", \"dbt\", \"Airflow\"]\n",
    "    },\n",
    "    \"Feature Store\": {\n",
    "        \"purpose\": \"Centralized repository for ML features\",\n",
    "        \"benefits\": [\n",
    "            \"Feature reuse across models\",\n",
    "            \"Consistency between training and serving\",\n",
    "            \"Feature versioning\",\n",
    "            \"Real-time feature serving\"\n",
    "        ],\n",
    "        \"tools\": [\"Feast\", \"Tecton\", \"Hopsworks\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "for component, details in data_stack.items():\n",
    "    print(f\"\\nüîπ {component}\")\n",
    "    print(\"=\" * 40)\n",
    "    for key, values in details.items():\n",
    "        print(f\"  {key.title()}:\")\n",
    "        if isinstance(values, list):\n",
    "            for v in values:\n",
    "                print(f\"    ‚Ä¢ {v}\")\n",
    "        else:\n",
    "            print(f\"    {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Serving Infrastructure\n",
    "\n",
    "The **Serving Infrastructure** is responsible for deploying models and serving predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Serving Infrastructure Considerations\n",
    "\n",
    "serving_infrastructure = pd.DataFrame({\n",
    "    \"Aspect\": [\n",
    "        \"Latency\",\n",
    "        \"Throughput\", \n",
    "        \"Availability\",\n",
    "        \"Scalability\",\n",
    "        \"Cost\"\n",
    "    ],\n",
    "    \"Description\": [\n",
    "        \"Time to return prediction (e.g., <100ms)\",\n",
    "        \"Requests per second (e.g., 10K RPS)\",\n",
    "        \"Uptime guarantee (e.g., 99.9%)\",\n",
    "        \"Ability to handle load spikes\",\n",
    "        \"Infrastructure and compute costs\"\n",
    "    ],\n",
    "    \"Typical Target\": [\n",
    "        \"p50 < 50ms, p99 < 200ms\",\n",
    "        \"1K - 100K RPS\",\n",
    "        \"99.9% - 99.99%\",\n",
    "        \"Auto-scaling 2-10x\",\n",
    "        \"$0.001 - $0.01 per prediction\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"üöÄ Serving Infrastructure Requirements:\")\n",
    "print(\"=\" * 70)\n",
    "display(serving_infrastructure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation Pipeline\n",
    "\n",
    "The **Evaluation Pipeline** ensures models perform well both offline and online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evaluation Pipeline Components\n",
    "\n",
    "evaluation_types = {\n",
    "    \"Offline Evaluation\": {\n",
    "        \"when\": \"Before deployment\",\n",
    "        \"metrics\": [\"Accuracy\", \"Precision/Recall\", \"AUC-ROC\", \"NDCG\"],\n",
    "        \"data\": \"Historical test set\",\n",
    "        \"pros\": \"Fast, cheap, reproducible\",\n",
    "        \"cons\": \"May not reflect real-world performance\"\n",
    "    },\n",
    "    \"Online Evaluation\": {\n",
    "        \"when\": \"During/after deployment\",\n",
    "        \"metrics\": [\"Click-through rate\", \"Conversion rate\", \"Revenue\", \"Engagement\"],\n",
    "        \"data\": \"Live user traffic\",\n",
    "        \"pros\": \"Measures real impact\",\n",
    "        \"cons\": \"Slow, expensive, risky\"\n",
    "    }\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, (eval_type, details) in enumerate(evaluation_types.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create a text box\n",
    "    text = f\"{eval_type}\\n\\n\"\n",
    "    text += f\"When: {details['when']}\\n\\n\"\n",
    "    text += f\"Metrics:\\n\"\n",
    "    for m in details['metrics']:\n",
    "        text += f\"  ‚Ä¢ {m}\\n\"\n",
    "    text += f\"\\nData: {details['data']}\\n\"\n",
    "    text += f\"\\n‚úÖ Pros: {details['pros']}\\n\"\n",
    "    text += f\"‚ùå Cons: {details['cons']}\"\n",
    "    \n",
    "    color = '#3498db' if idx == 0 else '#2ecc71'\n",
    "    ax.text(0.5, 0.5, text, transform=ax.transAxes, fontsize=11,\n",
    "            verticalalignment='center', horizontalalignment='center',\n",
    "            bbox=dict(boxstyle='round,pad=1', facecolor=color, alpha=0.2))\n",
    "    ax.set_title(eval_type, fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Evaluation Pipeline: Offline vs Online', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Monitoring Systems\n",
    "\n",
    "**Monitoring** is critical for maintaining ML system health in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: What to Monitor in ML Systems\n",
    "\n",
    "monitoring_categories = {\n",
    "    \"System Metrics\": {\n",
    "        \"icon\": \"‚öôÔ∏è\",\n",
    "        \"metrics\": [\n",
    "            \"CPU/GPU utilization\",\n",
    "            \"Memory usage\",\n",
    "            \"Request latency\",\n",
    "            \"Error rates\",\n",
    "            \"Throughput\"\n",
    "        ]\n",
    "    },\n",
    "    \"Data Metrics\": {\n",
    "        \"icon\": \"üìä\",\n",
    "        \"metrics\": [\n",
    "            \"Input data distribution\",\n",
    "            \"Missing values\",\n",
    "            \"Feature statistics\",\n",
    "            \"Data freshness\",\n",
    "            \"Schema violations\"\n",
    "        ]\n",
    "    },\n",
    "    \"Model Metrics\": {\n",
    "        \"icon\": \"ü§ñ\",\n",
    "        \"metrics\": [\n",
    "            \"Prediction distribution\",\n",
    "            \"Model confidence scores\",\n",
    "            \"Online accuracy (if labels available)\",\n",
    "            \"Model drift\",\n",
    "            \"Feature importance changes\"\n",
    "        ]\n",
    "    },\n",
    "    \"Business Metrics\": {\n",
    "        \"icon\": \"üí∞\",\n",
    "        \"metrics\": [\n",
    "            \"Click-through rate\",\n",
    "            \"Conversion rate\",\n",
    "            \"Revenue impact\",\n",
    "            \"User satisfaction\",\n",
    "            \"Engagement metrics\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìà ML System Monitoring Categories:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, details in monitoring_categories.items():\n",
    "    print(f\"\\n{details['icon']} {category}\")\n",
    "    for metric in details['metrics']:\n",
    "        print(f\"   ‚Ä¢ {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The 7-Step ML System Design Framework\n",
    "\n",
    "This framework provides a structured approach to designing ML systems. Each step builds on the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: 7-Step Framework\n",
    "\n",
    "steps = [\n",
    "    {\"step\": 1, \"name\": \"Clarify Requirements\", \"color\": \"#e74c3c\", \n",
    "     \"description\": \"Understand business goals, constraints, and scale\"},\n",
    "    {\"step\": 2, \"name\": \"Frame the Problem\", \"color\": \"#e67e22\",\n",
    "     \"description\": \"Translate to ML objectives, define I/O\"},\n",
    "    {\"step\": 3, \"name\": \"Data Preparation\", \"color\": \"#f1c40f\",\n",
    "     \"description\": \"ETL, feature engineering, data pipeline\"},\n",
    "    {\"step\": 4, \"name\": \"Model Development\", \"color\": \"#2ecc71\",\n",
    "     \"description\": \"Select, train, and tune models\"},\n",
    "    {\"step\": 5, \"name\": \"Evaluation\", \"color\": \"#3498db\",\n",
    "     \"description\": \"Offline & online metrics, A/B testing\"},\n",
    "    {\"step\": 6, \"name\": \"Deployment\", \"color\": \"#9b59b6\",\n",
    "     \"description\": \"Serving infrastructure, scaling\"},\n",
    "    {\"step\": 7, \"name\": \"Monitoring\", \"color\": \"#34495e\",\n",
    "     \"description\": \"Track performance, detect drift, maintain\"}\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw steps as a circular flow\n",
    "import math\n",
    "\n",
    "center_x, center_y = 50, 45\n",
    "radius = 35\n",
    "\n",
    "for i, step in enumerate(steps):\n",
    "    angle = (i / len(steps)) * 2 * math.pi - math.pi/2\n",
    "    x = center_x + radius * math.cos(angle)\n",
    "    y = center_y + radius * math.sin(angle)\n",
    "    \n",
    "    # Draw circle for step\n",
    "    circle = plt.Circle((x, y), 8, color=step['color'], alpha=0.9)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "    # Add step number\n",
    "    ax.text(x, y, str(step['step']), fontsize=20, fontweight='bold',\n",
    "            ha='center', va='center', color='white')\n",
    "    \n",
    "    # Add step name (outside circle)\n",
    "    text_x = center_x + (radius + 15) * math.cos(angle)\n",
    "    text_y = center_y + (radius + 15) * math.sin(angle)\n",
    "    \n",
    "    # Adjust text alignment based on position\n",
    "    ha = 'center'\n",
    "    if x < center_x - 5:\n",
    "        ha = 'right'\n",
    "    elif x > center_x + 5:\n",
    "        ha = 'left'\n",
    "    \n",
    "    ax.text(text_x, text_y, f\"{step['name']}\\n{step['description']}\",\n",
    "            fontsize=9, ha=ha, va='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor=step['color'], alpha=0.2))\n",
    "\n",
    "# Draw arrows between steps\n",
    "for i in range(len(steps)):\n",
    "    angle1 = (i / len(steps)) * 2 * math.pi - math.pi/2\n",
    "    angle2 = ((i + 1) / len(steps)) * 2 * math.pi - math.pi/2\n",
    "    \n",
    "    x1 = center_x + radius * math.cos(angle1 + 0.3)\n",
    "    y1 = center_y + radius * math.sin(angle1 + 0.3)\n",
    "    x2 = center_x + radius * math.cos(angle2 - 0.3)\n",
    "    y2 = center_y + radius * math.sin(angle2 - 0.3)\n",
    "    \n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "ax.set_title('The 7-Step ML System Design Framework', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework Summary Table\n",
    "\n",
    "framework_df = pd.DataFrame({\n",
    "    \"Step\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"Name\": [\n",
    "        \"Clarify Requirements\",\n",
    "        \"Frame the Problem\",\n",
    "        \"Data Preparation\",\n",
    "        \"Model Development\",\n",
    "        \"Evaluation\",\n",
    "        \"Deployment\",\n",
    "        \"Monitoring\"\n",
    "    ],\n",
    "    \"Key Questions\": [\n",
    "        \"What are we optimizing? What are the constraints?\",\n",
    "        \"What type of ML problem is this? What are inputs/outputs?\",\n",
    "        \"What data do we have? How do we engineer features?\",\n",
    "        \"Which models to try? How to train them?\",\n",
    "        \"How do we measure success? What experiments to run?\",\n",
    "        \"How to serve predictions? How to scale?\",\n",
    "        \"How to detect issues? When to retrain?\"\n",
    "    ],\n",
    "    \"Key Outputs\": [\n",
    "        \"Requirements document, success metrics\",\n",
    "        \"ML objective, I/O specification, task type\",\n",
    "        \"ETL pipeline, feature store, dataset\",\n",
    "        \"Trained model, hyperparameters\",\n",
    "        \"Evaluation report, experiment results\",\n",
    "        \"Serving infrastructure, APIs\",\n",
    "        \"Dashboards, alerts, retraining triggers\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"üìã 7-Step Framework Summary:\")\n",
    "display(framework_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. When to Use ML vs Traditional Approaches\n",
    "\n",
    "Not every problem needs ML! Here's a framework to help you decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Framework: When to Use ML\n",
    "\n",
    "def should_use_ml(problem):\n",
    "    \"\"\"\n",
    "    A decision framework to determine if ML is appropriate for a problem.\n",
    "    \n",
    "    Parameters:\n",
    "    problem: dict with keys describing the problem characteristics\n",
    "    \n",
    "    Returns:\n",
    "    recommendation: str, explanation: str\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = {\n",
    "        'ml_favorable': 0,\n",
    "        'traditional_favorable': 0\n",
    "    }\n",
    "    \n",
    "    reasons = []\n",
    "    \n",
    "    # Check: Is there a pattern to learn?\n",
    "    if problem.get('has_patterns', False):\n",
    "        scores['ml_favorable'] += 2\n",
    "        reasons.append(\"‚úÖ Problem has patterns that can be learned\")\n",
    "    else:\n",
    "        scores['traditional_favorable'] += 2\n",
    "        reasons.append(\"‚ùå No clear patterns - rules might work better\")\n",
    "    \n",
    "    # Check: Do you have enough data?\n",
    "    data_size = problem.get('data_size', 'small')\n",
    "    if data_size == 'large':\n",
    "        scores['ml_favorable'] += 2\n",
    "        reasons.append(\"‚úÖ Large dataset available for training\")\n",
    "    elif data_size == 'medium':\n",
    "        scores['ml_favorable'] += 1\n",
    "        reasons.append(\"‚ö†Ô∏è Medium-sized dataset - might need simple models\")\n",
    "    else:\n",
    "        scores['traditional_favorable'] += 2\n",
    "        reasons.append(\"‚ùå Small dataset - ML may overfit\")\n",
    "    \n",
    "    # Check: Is the problem too complex for rules?\n",
    "    if problem.get('rule_complexity', 'low') == 'high':\n",
    "        scores['ml_favorable'] += 2\n",
    "        reasons.append(\"‚úÖ Too complex for hand-crafted rules\")\n",
    "    else:\n",
    "        scores['traditional_favorable'] += 1\n",
    "        reasons.append(\"‚ö†Ô∏è Simple rules might suffice\")\n",
    "    \n",
    "    # Check: Do you need to handle unseen cases?\n",
    "    if problem.get('needs_generalization', False):\n",
    "        scores['ml_favorable'] += 2\n",
    "        reasons.append(\"‚úÖ Need to generalize to new cases\")\n",
    "    else:\n",
    "        scores['traditional_favorable'] += 1\n",
    "        reasons.append(\"‚ö†Ô∏è Known cases can be handled with rules\")\n",
    "    \n",
    "    # Check: Is interpretability critical?\n",
    "    if problem.get('needs_interpretability', False):\n",
    "        scores['traditional_favorable'] += 1\n",
    "        reasons.append(\"‚ö†Ô∏è Interpretability needed - consider simple models or rules\")\n",
    "    \n",
    "    # Calculate recommendation\n",
    "    if scores['ml_favorable'] > scores['traditional_favorable']:\n",
    "        recommendation = \"üëç ML Recommended\"\n",
    "    elif scores['traditional_favorable'] > scores['ml_favorable']:\n",
    "        recommendation = \"üìè Traditional Approach Recommended\"\n",
    "    else:\n",
    "        recommendation = \"ü§î Consider both approaches\"\n",
    "    \n",
    "    return recommendation, reasons\n",
    "\n",
    "# Example problems\n",
    "problems = [\n",
    "    {\n",
    "        'name': 'Email Spam Detection',\n",
    "        'has_patterns': True,\n",
    "        'data_size': 'large',\n",
    "        'rule_complexity': 'high',\n",
    "        'needs_generalization': True,\n",
    "        'needs_interpretability': False\n",
    "    },\n",
    "    {\n",
    "        'name': 'Tax Calculation',\n",
    "        'has_patterns': False,\n",
    "        'data_size': 'small',\n",
    "        'rule_complexity': 'low',\n",
    "        'needs_generalization': False,\n",
    "        'needs_interpretability': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'Image Classification',\n",
    "        'has_patterns': True,\n",
    "        'data_size': 'large',\n",
    "        'rule_complexity': 'high',\n",
    "        'needs_generalization': True,\n",
    "        'needs_interpretability': False\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üéØ ML vs Traditional Approach Decision Framework\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for problem in problems:\n",
    "    print(f\"\\nüìå Problem: {problem['name']}\")\n",
    "    recommendation, reasons = should_use_ml(problem)\n",
    "    print(f\"   Recommendation: {recommendation}\")\n",
    "    print(\"   Analysis:\")\n",
    "    for reason in reasons:\n",
    "        print(f\"      {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: ML vs Traditional Decision Matrix\n",
    "\n",
    "decision_matrix = pd.DataFrame({\n",
    "    'Criteria': [\n",
    "        'Pattern Complexity',\n",
    "        'Data Availability',\n",
    "        'Need for Generalization',\n",
    "        'Rule Maintainability',\n",
    "        'Interpretability Requirement',\n",
    "        'Accuracy Requirement'\n",
    "    ],\n",
    "    'Favors ML': [\n",
    "        'Complex patterns, non-linear relationships',\n",
    "        'Large amounts of labeled data',\n",
    "        'Must handle unseen cases',\n",
    "        'Rules would be hard to maintain',\n",
    "        'Black-box acceptable',\n",
    "        'High accuracy critical'\n",
    "    ],\n",
    "    'Favors Traditional': [\n",
    "        'Simple, well-defined rules',\n",
    "        'Limited or no data',\n",
    "        'Known, finite set of cases',\n",
    "        'Rules are simple and stable',\n",
    "        'Must explain every decision',\n",
    "        'Good enough is sufficient'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"üìä ML vs Traditional Approach Decision Matrix:\")\n",
    "display(decision_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Hands-On Exercise: Analyze a Recommendation System\n",
    "\n",
    "Let's apply what we've learned by analyzing the architecture of a movie recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Map a Recommendation System to the 7-Step Framework\n",
    "\n",
    "class RecommendationSystemAnalysis:\n",
    "    \"\"\"\n",
    "    Analyze a movie recommendation system using the 7-step framework.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.steps = {}\n",
    "    \n",
    "    def add_step(self, step_num, step_name, details):\n",
    "        \"\"\"Add analysis for a framework step\"\"\"\n",
    "        self.steps[step_num] = {\n",
    "            'name': step_name,\n",
    "            'details': details\n",
    "        }\n",
    "    \n",
    "    def display_analysis(self):\n",
    "        \"\"\"Display the complete analysis\"\"\"\n",
    "        print(f\"\\nüé¨ System Analysis: {self.name}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for step_num in sorted(self.steps.keys()):\n",
    "            step = self.steps[step_num]\n",
    "            print(f\"\\nStep {step_num}: {step['name']}\")\n",
    "            print(\"-\" * 40)\n",
    "            for key, value in step['details'].items():\n",
    "                print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Create analysis for Netflix-like recommendation system\n",
    "netflix = RecommendationSystemAnalysis(\"Netflix-like Movie Recommendations\")\n",
    "\n",
    "netflix.add_step(1, \"Clarify Requirements\", {\n",
    "    \"Business Goal\": \"Increase user engagement and retention\",\n",
    "    \"Success Metric\": \"Time spent watching / Subscriber retention\",\n",
    "    \"Scale\": \"200M+ users, 15K+ titles\",\n",
    "    \"Latency Requirement\": \"< 200ms for recommendations\",\n",
    "    \"Personalization Level\": \"User-level personalization\"\n",
    "})\n",
    "\n",
    "netflix.add_step(2, \"Frame the Problem\", {\n",
    "    \"ML Objective\": \"Predict user engagement score for each movie\",\n",
    "    \"Input\": \"User features + Movie features + Context\",\n",
    "    \"Output\": \"Ranked list of movies\",\n",
    "    \"Task Type\": \"Learning-to-Rank / Regression\"\n",
    "})\n",
    "\n",
    "netflix.add_step(3, \"Data Preparation\", {\n",
    "    \"Data Sources\": \"Watch history, ratings, search queries, browse behavior\",\n",
    "    \"Features\": \"User embeddings, movie embeddings, temporal features\",\n",
    "    \"Data Pipeline\": \"Streaming ingestion + Batch processing\"\n",
    "})\n",
    "\n",
    "netflix.add_step(4, \"Model Development\", {\n",
    "    \"Model Architecture\": \"Two-tower neural network\",\n",
    "    \"Training Frequency\": \"Daily batch + Real-time updates\",\n",
    "    \"Candidate Generation\": \"Approximate nearest neighbor search\"\n",
    "})\n",
    "\n",
    "netflix.add_step(5, \"Evaluation\", {\n",
    "    \"Offline Metrics\": \"Recall@K, NDCG, Hit Rate\",\n",
    "    \"Online Metrics\": \"CTR, Watch Time, Retention\",\n",
    "    \"Testing\": \"A/B testing with holdout groups\"\n",
    "})\n",
    "\n",
    "netflix.add_step(6, \"Deployment\", {\n",
    "    \"Serving Strategy\": \"Two-stage: Candidate retrieval + Ranking\",\n",
    "    \"Infrastructure\": \"Distributed model serving\",\n",
    "    \"Caching\": \"Pre-computed candidates for cold start\"\n",
    "})\n",
    "\n",
    "netflix.add_step(7, \"Monitoring\", {\n",
    "    \"System Metrics\": \"Latency, throughput, error rates\",\n",
    "    \"Model Metrics\": \"Prediction distribution, feature drift\",\n",
    "    \"Business Metrics\": \"Daily active users, engagement trends\"\n",
    "})\n",
    "\n",
    "netflix.display_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try It Yourself! üöÄ\n",
    "\n",
    "Now it's your turn! Complete the analysis for a different ML system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your own ML system analysis\n",
    "# Choose one of the following systems:\n",
    "# - Fraud Detection System (for a bank)\n",
    "# - Search Ranking System (for an e-commerce site)\n",
    "# - Content Moderation System (for a social media platform)\n",
    "\n",
    "# Uncomment and complete the code below:\n",
    "\n",
    "# your_system = RecommendationSystemAnalysis(\"Your System Name\")\n",
    "\n",
    "# your_system.add_step(1, \"Clarify Requirements\", {\n",
    "#     \"Business Goal\": \"...\",\n",
    "#     \"Success Metric\": \"...\",\n",
    "#     \"Scale\": \"...\",\n",
    "#     \"Latency Requirement\": \"...\",\n",
    "# })\n",
    "\n",
    "# # Add steps 2-7...\n",
    "\n",
    "# your_system.display_analysis()\n",
    "\n",
    "print(\"üí° Tip: Think about what makes each system unique in terms of:\")\n",
    "print(\"   - What data is available?\")\n",
    "print(\"   - What are the latency constraints?\")\n",
    "print(\"   - What happens if the model is wrong?\")\n",
    "print(\"   - How do you measure success?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **ML Algorithm ‚â† ML System**: The algorithm is just ~5% of a production ML system. The rest includes data pipelines, serving infrastructure, monitoring, and more.\n",
    "\n",
    "2. **Four Main Components** of production ML systems:\n",
    "   - üìä **Data Stack**: Collection, processing, and storage\n",
    "   - üöÄ **Serving Infrastructure**: Low-latency predictions at scale\n",
    "   - üìè **Evaluation Pipeline**: Offline and online metrics\n",
    "   - üìà **Monitoring Systems**: Track health and detect issues\n",
    "\n",
    "3. **The 7-Step Framework** provides a systematic approach:\n",
    "   1. Clarify Requirements\n",
    "   2. Frame the Problem\n",
    "   3. Data Preparation\n",
    "   4. Model Development\n",
    "   5. Evaluation\n",
    "   6. Deployment\n",
    "   7. Monitoring\n",
    "\n",
    "4. **ML is not always the answer**: Consider traditional approaches when:\n",
    "   - Data is scarce\n",
    "   - Rules are simple and well-defined\n",
    "   - Interpretability is critical\n",
    "   - The problem is deterministic\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next tutorial, we'll dive deep into **Step 1: Clarifying Requirements** - learning how to ask the right questions to understand business objectives, constraints, and scale requirements.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- üìö [Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf) - Google's seminal paper\n",
    "- üìö [Machine Learning System Design Interview](https://www.amazon.com/Machine-Learning-System-Design-Interview/dp/1736049127) - Book reference\n",
    "- üé• [Made With ML](https://madewithml.com/) - Practical MLOps course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Review: Quick Self-Assessment Quiz\n",
    "\n",
    "quiz_questions = [\n",
    "    {\n",
    "        \"question\": \"What percentage of a production ML system is typically the ML algorithm itself?\",\n",
    "        \"options\": [\"A) 50%\", \"B) 25%\", \"C) 5%\", \"D) 80%\"],\n",
    "        \"answer\": \"C\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which component is responsible for serving predictions with low latency?\",\n",
    "        \"options\": [\"A) Data Stack\", \"B) Serving Infrastructure\", \"C) Evaluation Pipeline\", \"D) Feature Store\"],\n",
    "        \"answer\": \"B\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When should you prefer traditional approaches over ML?\",\n",
    "        \"options\": [\"A) When you have lots of data\", \"B) When patterns are complex\", \n",
    "                   \"C) When rules are simple and well-defined\", \"D) When you need generalization\"],\n",
    "        \"answer\": \"C\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üìù Quick Self-Assessment Quiz\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, q in enumerate(quiz_questions, 1):\n",
    "    print(f\"\\nQ{i}: {q['question']}\")\n",
    "    for opt in q['options']:\n",
    "        print(f\"   {opt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Answers: 1-C, 2-B, 3-C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
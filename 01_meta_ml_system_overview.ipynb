{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta ML System Design: Overview & Mental Models\n",
    "\n",
    "**Target Level:** Meta E5 â†’ E6  \n",
    "**Prerequisite:** Strong systems background, ML beginner  \n",
    "**Interview Focus:** Ranking systems, Feed/Ads/Reels/Notifications\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Covers\n",
    "\n",
    "This is your mental model for how Meta thinks about ML systems. Every system at Metaâ€”Feed ranking, Ads, Reels recommendations, Notificationsâ€”follows the same fundamental architecture pattern. Master this pattern, and you can design any Meta ML system.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Meta ML System Mental Model\n",
    "\n",
    "### Everything is Ranking\n",
    "\n",
    "At Meta scale, **every ML problem is fundamentally a ranking problem**:\n",
    "\n",
    "| Product | What Gets Ranked | Objective |\n",
    "|---------|------------------|----------|\n",
    "| News Feed | Posts from friends, groups, pages | Maximize meaningful engagement |\n",
    "| Ads | Advertiser creatives | Maximize revenue Ã— relevance |\n",
    "| Reels | Short videos | Maximize watch time + shares |\n",
    "| Notifications | Push notifications | Maximize opens without annoyance |\n",
    "| People You May Know | Friend suggestions | Maximize accepted connections |\n",
    "\n",
    "Even \"classification\" problems (spam detection, hate speech) feed into ranking: a spam score becomes a penalty in the ranking formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     META ML SYSTEM CANONICAL ARCHITECTURE                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              USER REQUEST\n",
    "                                   â”‚\n",
    "                                   â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         CANDIDATE GENERATION                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚\n",
    "â”‚  â”‚  Friends'   â”‚  â”‚   Group     â”‚  â”‚   Page      â”‚  â”‚    Ads      â”‚        â”‚\n",
    "â”‚  â”‚   Posts     â”‚  â”‚   Posts     â”‚  â”‚   Posts     â”‚  â”‚  Inventory  â”‚        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Goal: Reduce billions â†’ thousands (cheap retrieval, ~10ms)                 â”‚\n",
    "â”‚  Methods: Inverted index, embedding similarity, rule-based filters          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                   â”‚\n",
    "                                   â–¼ ~1000-10000 candidates\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                              FIRST-PASS RANKING                              â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Lightweight model (logistic regression, small neural net)                  â”‚\n",
    "â”‚  Goal: Reduce thousands â†’ hundreds (~50ms)                                  â”‚\n",
    "â”‚  Features: User features + item features (precomputed)                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                   â”‚\n",
    "                                   â–¼ ~100-500 candidates\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                              MAIN RANKING                                    â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Heavy model (deep neural network, multi-task learning)                     â”‚\n",
    "â”‚  Goal: Precise ordering of top candidates (~100ms)                          â”‚\n",
    "â”‚  Features: Dense features, cross features, context                          â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Predicts: P(click), P(like), P(comment), P(share), P(hide), P(report)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                   â”‚\n",
    "                                   â–¼ scored candidates\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                              RE-RANKING / BLENDING                           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  Business rules, diversity injection, freshness boost                       â”‚\n",
    "â”‚  Goal: Final slate optimization (~20ms)                                     â”‚\n",
    "â”‚  Examples: No duplicate authors, mix content types, boost breaking news     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                   â”‚\n",
    "                                   â–¼\n",
    "                           FINAL RANKED LIST\n",
    "                          (shown to user)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ğŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Explains the funnel clearlyâ€”candidate generation for recall, ranking for precision. Mentions latency budgets at each stage.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses why stages exist (cost/latency tradeoff), how models at each stage are trained differently, and what happens when one stage fails.\n",
    ">\n",
    "> **Common Pitfall:** Jumping straight to \"use a transformer\" without discussing the retrieval funnel. At Meta scale, you can't score billions of items with a heavy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Ranking Formula: Combining Multiple Objectives\n",
    "\n",
    "Meta's ranking systems don't optimize a single metric. They combine multiple predictions into a **value function**:\n",
    "\n",
    "```\n",
    "Score = wâ‚ Ã— P(click) \n",
    "      + wâ‚‚ Ã— P(like) \n",
    "      + wâ‚ƒ Ã— P(comment) \n",
    "      + wâ‚„ Ã— P(share) \n",
    "      + wâ‚… Ã— P(long_watch) \n",
    "      - wâ‚† Ã— P(hide) \n",
    "      - wâ‚‡ Ã— P(report)\n",
    "```\n",
    "\n",
    "**Key Insight:** The weights (wâ‚, wâ‚‚, ...) are **policy decisions**, not learned. Product teams set these based on what engagement they want to encourage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate model predictions for 10 posts\n",
    "np.random.seed(42)\n",
    "n_posts = 10\n",
    "\n",
    "posts = pd.DataFrame({\n",
    "    'post_id': range(n_posts),\n",
    "    'p_click': np.random.beta(2, 5, n_posts),      # Most posts: low-medium click prob\n",
    "    'p_like': np.random.beta(1, 8, n_posts),       # Likes are rarer\n",
    "    'p_comment': np.random.beta(1, 15, n_posts),   # Comments are rare\n",
    "    'p_share': np.random.beta(1, 20, n_posts),     # Shares are very rare\n",
    "    'p_hide': np.random.beta(1, 30, n_posts),      # Hides are rare (negative signal)\n",
    "})\n",
    "\n",
    "print(\"Model predictions for each post:\")\n",
    "print(posts.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different weight configurations represent different product priorities\n",
    "\n",
    "def compute_score(df, weights):\n",
    "    \"\"\"Compute ranking score given model predictions and weights.\"\"\"\n",
    "    return (\n",
    "        weights['click'] * df['p_click'] +\n",
    "        weights['like'] * df['p_like'] +\n",
    "        weights['comment'] * df['p_comment'] +\n",
    "        weights['share'] * df['p_share'] -\n",
    "        weights['hide'] * df['p_hide']\n",
    "    )\n",
    "\n",
    "# Scenario 1: Engagement-focused (optimize clicks)\n",
    "engagement_weights = {'click': 1.0, 'like': 0.5, 'comment': 0.3, 'share': 0.3, 'hide': 2.0}\n",
    "\n",
    "# Scenario 2: Quality-focused (prioritize meaningful interactions)\n",
    "quality_weights = {'click': 0.1, 'like': 0.5, 'comment': 2.0, 'share': 3.0, 'hide': 5.0}\n",
    "\n",
    "# Scenario 3: Viral-focused (maximize shares)\n",
    "viral_weights = {'click': 0.2, 'like': 0.2, 'comment': 0.5, 'share': 5.0, 'hide': 1.0}\n",
    "\n",
    "posts['score_engagement'] = compute_score(posts, engagement_weights)\n",
    "posts['score_quality'] = compute_score(posts, quality_weights)\n",
    "posts['score_viral'] = compute_score(posts, viral_weights)\n",
    "\n",
    "# Show how the same predictions lead to different rankings\n",
    "print(\"Rankings under different objective weights:\\n\")\n",
    "print(\"Engagement-focused ranking:\")\n",
    "print(posts.sort_values('score_engagement', ascending=False)[['post_id', 'score_engagement']].head(5))\n",
    "print(\"\\nQuality-focused ranking:\")\n",
    "print(posts.sort_values('score_quality', ascending=False)[['post_id', 'score_quality']].head(5))\n",
    "print(\"\\nViral-focused ranking:\")\n",
    "print(posts.sort_values('score_viral', ascending=False)[['post_id', 'score_viral']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ğŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Understands that ML predicts probabilities, but the final ranking combines them with business weights. Mentions that changing weights doesn't require retraining.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses how to tune weights (grid search over A/B tests), how weights interact (increasing share weight may accidentally promote clickbait), and governance around weight changes.\n",
    ">\n",
    "> **Common Pitfall:** Thinking the model directly optimizes for \"engagement.\" The model predicts individual actions; the value function defines what \"engagement\" means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Two Loops: Offline Training vs Online Serving\n",
    "\n",
    "Every Meta ML system has two distinct operational modes:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                            OFFLINE TRAINING LOOP                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚   â”‚  Log     â”‚â”€â”€â”€â–¶â”‚  Label   â”‚â”€â”€â”€â–¶â”‚  Train   â”‚â”€â”€â”€â–¶â”‚  Eval    â”‚            â”‚\n",
    "â”‚   â”‚  Data    â”‚    â”‚  Extract â”‚    â”‚  Model   â”‚    â”‚  Offline â”‚            â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚                                                        â”‚                   â”‚\n",
    "â”‚   Latency: Hours to days                              â”‚                   â”‚\n",
    "â”‚   Scale: Billions of examples                          â–¼                   â”‚\n",
    "â”‚   Goal: Best possible model quality        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚                                            â”‚  Model Registry  â”‚           â”‚\n",
    "â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                        â”‚\n",
    "                                                        â”‚ Model Push\n",
    "                                                        â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                            ONLINE SERVING LOOP                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚   â”‚  User    â”‚â”€â”€â”€â–¶â”‚  Feature â”‚â”€â”€â”€â–¶â”‚  Model   â”‚â”€â”€â”€â–¶â”‚  Ranked  â”‚            â”‚\n",
    "â”‚   â”‚  Request â”‚    â”‚  Fetch   â”‚    â”‚  Infer   â”‚    â”‚  Results â”‚            â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚   Latency: <200ms total                                                    â”‚\n",
    "â”‚   Scale: Millions of QPS                                                   â”‚\n",
    "â”‚   Goal: Lowest latency with acceptable quality                             â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences\n",
    "\n",
    "| Aspect | Offline Training | Online Serving |\n",
    "|--------|------------------|----------------|\n",
    "| **Latency tolerance** | Hours/days | Milliseconds |\n",
    "| **Feature complexity** | Use all features | Only fast-to-compute features |\n",
    "| **Data availability** | Full history | Real-time only |\n",
    "| **Failure mode** | Delayed model update | User-visible degradation |\n",
    "| **Scale metric** | Training throughput | QPS Ã— latency |\n",
    "\n",
    "### The Training-Serving Skew Problem\n",
    "\n",
    "One of the most common production issues: **features behave differently in training vs serving**.\n",
    "\n",
    "Examples:\n",
    "- Feature computed from 7-day history in training, but only last hour available in serving\n",
    "- Feature uses exact timestamp in training, but bucketed in serving for caching\n",
    "- Feature joins user table in training, but user table has different freshness in serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Training-Serving Skew\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Training data: we have exact user_activity_count\n",
    "user_activity_exact = np.random.poisson(50, n_samples)  # Exact count from logs\n",
    "content_quality = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# True click probability depends on both\n",
    "logits = 0.02 * user_activity_exact + 0.5 * content_quality - 2\n",
    "click_prob = 1 / (1 + np.exp(-logits))\n",
    "clicks = np.random.binomial(1, click_prob)\n",
    "\n",
    "# Train model with exact features\n",
    "X_train = np.column_stack([user_activity_exact, content_quality])\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, clicks)\n",
    "\n",
    "print(f\"Training AUC (exact features): {roc_auc_score(clicks, model.predict_proba(X_train)[:, 1]):.4f}\")\n",
    "\n",
    "# Serving: we only have bucketed user_activity (simulating stale/approximate features)\n",
    "# Bucket: 0-25, 25-50, 50-75, 75+\n",
    "user_activity_bucketed = np.digitize(user_activity_exact, bins=[0, 25, 50, 75]) * 25\n",
    "\n",
    "X_serve = np.column_stack([user_activity_bucketed, content_quality])\n",
    "print(f\"Serving AUC (bucketed features): {roc_auc_score(clicks, model.predict_proba(X_serve)[:, 1]):.4f}\")\n",
    "print(f\"\\nâš ï¸ AUC dropped due to feature skew!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ğŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Can explain training-serving skew and give examples. Proposes solutions like feature logging at serving time, or using the same feature computation code.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses systematic approachesâ€”feature stores with versioning, replay-based training, and monitoring for skew detection. Mentions specific failure cases they've debugged.\n",
    ">\n",
    "> **Common Pitfall:** Treating training and serving as the same environment. They're fundamentally different systems with different constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Freshness: A Meta Obsession\n",
    "\n",
    "At Meta, **how fresh your features are** directly impacts model quality. The world changes fast:\n",
    "\n",
    "- A post goes viral â†’ engagement features spike\n",
    "- User mood changes â†’ preference signals shift  \n",
    "- Breaking news happens â†’ content relevance changes\n",
    "\n",
    "```\n",
    "Feature Freshness Spectrum\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                                                                              \n",
    " STATIC          DAILY           HOURLY          REAL-TIME                   \n",
    "   â”‚               â”‚               â”‚                â”‚                        \n",
    "   â–¼               â–¼               â–¼                â–¼                        \n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   \n",
    "â”‚User  â”‚       â”‚User  â”‚       â”‚Post  â”‚        â”‚Session   â”‚                   \n",
    "â”‚demo- â”‚       â”‚long- â”‚       â”‚engage-â”‚        â”‚context   â”‚                   \n",
    "â”‚graphicsâ”‚      â”‚term  â”‚       â”‚ment  â”‚        â”‚features  â”‚                   \n",
    "â”‚      â”‚       â”‚prefs â”‚       â”‚stats â”‚        â”‚          â”‚                   \n",
    "â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   \n",
    "                                                                              \n",
    " Cheap to        Batch          Near-          Expensive                     \n",
    " compute         pipeline       real-time      to compute                    \n",
    "                                streaming                                     \n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of feature freshness on prediction quality\n",
    "\n",
    "def simulate_viral_post(hours_since_post, refresh_interval_hours):\n",
    "    \"\"\"\n",
    "    Simulate a viral post and show how stale features hurt predictions.\n",
    "    \n",
    "    The post goes viral at hour 5, but if we only refresh features every N hours,\n",
    "    our engagement prediction will be wrong.\n",
    "    \"\"\"\n",
    "    # True engagement over time (post goes viral at hour 5)\n",
    "    true_engagement = np.where(\n",
    "        hours_since_post < 5,\n",
    "        10 + hours_since_post * 2,  # Normal growth\n",
    "        10 + 5 * 2 + (hours_since_post - 5) ** 2 * 10  # Viral explosion\n",
    "    )\n",
    "    \n",
    "    # What our features show (updated every refresh_interval_hours)\n",
    "    last_refresh = (hours_since_post // refresh_interval_hours) * refresh_interval_hours\n",
    "    stale_engagement = np.where(\n",
    "        last_refresh < 5,\n",
    "        10 + last_refresh * 2,\n",
    "        10 + 5 * 2 + (last_refresh - 5) ** 2 * 10\n",
    "    )\n",
    "    \n",
    "    return true_engagement, stale_engagement\n",
    "\n",
    "hours = np.arange(0, 24, 0.5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, refresh_interval in zip(axes, [1, 4, 12]):\n",
    "    true_eng, stale_eng = simulate_viral_post(hours, refresh_interval)\n",
    "    \n",
    "    ax.plot(hours, true_eng, 'g-', label='True engagement', linewidth=2)\n",
    "    ax.plot(hours, stale_eng, 'r--', label='Feature value (stale)', linewidth=2)\n",
    "    ax.fill_between(hours, true_eng, stale_eng, alpha=0.3, color='red')\n",
    "    ax.axvline(x=5, color='orange', linestyle=':', label='Goes viral')\n",
    "    ax.set_xlabel('Hours since post')\n",
    "    ax.set_ylabel('Engagement')\n",
    "    ax.set_title(f'Refresh every {refresh_interval}h\\n(Red area = prediction error)')\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Feedback Loop: Your System Affects Its Own Training Data\n",
    "\n",
    "This is **the most important concept** for Meta ML systems:\n",
    "\n",
    "**Your model's predictions determine what users see â†’ which determines what they interact with â†’ which becomes your training data â†’ which trains your next model.**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                          THE FEEDBACK LOOP                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚   User Opens     â”‚\n",
    "         â”‚      App         â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â”‚\n",
    "                  â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚  Model Ranks     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚    Content       â”‚                                   â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚\n",
    "                  â”‚                                             â”‚\n",
    "                  â–¼                                             â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚\n",
    "         â”‚   User Sees      â”‚                                   â”‚\n",
    "         â”‚  Ranked Content  â”‚                                   â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚\n",
    "                  â”‚                                             â”‚\n",
    "                  â–¼                                             â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚\n",
    "         â”‚   User Takes     â”‚                                   â”‚\n",
    "         â”‚    Actions       â”‚                                   â”‚\n",
    "         â”‚  (click, like,   â”‚                                   â”‚\n",
    "         â”‚   hide, etc.)    â”‚                                   â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚\n",
    "                  â”‚                                             â”‚\n",
    "                  â–¼                                             â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "         â”‚   Actions        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Model         â”‚â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚   Logged         â”‚         â”‚   Retrained     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "\n",
    "   DANGER: Content never shown = never trained on = never shown\n",
    "           (The rich get richer, the invisible stay invisible)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Feedback loop leading to popularity bias\n",
    "\n",
    "def simulate_feedback_loop(n_items=20, n_rounds=10, exploration_rate=0.0):\n",
    "    \"\"\"\n",
    "    Simulate how a ranking system creates its own training data.\n",
    "    \n",
    "    Items have true quality, but the model only learns from shown items.\n",
    "    Without exploration, it reinforces initial beliefs.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # True quality of each item (unknown to model)\n",
    "    true_quality = np.random.uniform(0, 1, n_items)\n",
    "    \n",
    "    # Initial model scores (random guess)\n",
    "    model_scores = np.random.uniform(0, 1, n_items)\n",
    "    \n",
    "    exposure_counts = np.zeros(n_items)\n",
    "    positive_feedback = np.zeros(n_items)\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for round_num in range(n_rounds):\n",
    "        # Rank by model score (with some exploration)\n",
    "        if np.random.random() < exploration_rate:\n",
    "            # Explore: show random item\n",
    "            shown_item = np.random.randint(n_items)\n",
    "        else:\n",
    "            # Exploit: show highest scored item\n",
    "            shown_item = np.argmax(model_scores)\n",
    "        \n",
    "        # User engagement depends on true quality\n",
    "        engagement = np.random.random() < true_quality[shown_item]\n",
    "        \n",
    "        # Update model based on feedback\n",
    "        exposure_counts[shown_item] += 1\n",
    "        if engagement:\n",
    "            positive_feedback[shown_item] += 1\n",
    "        \n",
    "        # Update model score (simple: fraction of positive feedback)\n",
    "        for i in range(n_items):\n",
    "            if exposure_counts[i] > 0:\n",
    "                model_scores[i] = positive_feedback[i] / exposure_counts[i]\n",
    "            # Items with no exposure keep their initial (random) score!\n",
    "        \n",
    "        history.append({\n",
    "            'round': round_num,\n",
    "            'shown_item': shown_item,\n",
    "            'engagement': engagement,\n",
    "            'correlation': np.corrcoef(true_quality, model_scores)[0, 1]\n",
    "        })\n",
    "    \n",
    "    return history, exposure_counts, true_quality, model_scores\n",
    "\n",
    "# Run simulation without exploration\n",
    "history_no_explore, exposure_no_explore, true_q, model_s = simulate_feedback_loop(exploration_rate=0.0)\n",
    "\n",
    "# Run simulation with exploration\n",
    "history_explore, exposure_explore, _, _ = simulate_feedback_loop(exploration_rate=0.3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Exposure distribution\n",
    "axes[0].bar(range(20), exposure_no_explore, alpha=0.5, label='No exploration')\n",
    "axes[0].bar(range(20), exposure_explore, alpha=0.5, label='30% exploration')\n",
    "axes[0].set_xlabel('Item ID')\n",
    "axes[0].set_ylabel('Times shown')\n",
    "axes[0].set_title('Exposure Distribution After 10 Rounds')\n",
    "axes[0].legend()\n",
    "\n",
    "# Model-quality correlation over time\n",
    "axes[1].plot([h['round'] for h in history_no_explore], \n",
    "             [h['correlation'] for h in history_no_explore], \n",
    "             label='No exploration', marker='o')\n",
    "axes[1].plot([h['round'] for h in history_explore], \n",
    "             [h['correlation'] for h in history_explore], \n",
    "             label='30% exploration', marker='s')\n",
    "axes[1].set_xlabel('Round')\n",
    "axes[1].set_ylabel('Correlation (model score vs true quality)')\n",
    "axes[1].set_title('Model Quality Over Time')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Without exploration: {int(sum(exposure_no_explore == 0))} items NEVER shown\")\n",
    "print(f\"With 30% exploration: {int(sum(exposure_explore == 0))} items NEVER shown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ğŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Explains the feedback loop and why it leads to popularity bias. Proposes exploration (random traffic, epsilon-greedy) as a solution.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses exploration-exploitation tradeoff quantitatively, mentions specific techniques (Thompson sampling, contextual bandits), and connects to business impact (exploration has costâ€”lower short-term engagement).\n",
    ">\n",
    "> **Common Pitfall:** Ignoring the feedback loop entirely. Treating ML as a static prediction problem rather than a dynamic system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Meta's ML System Principles: Summary\n",
    "\n",
    "| Principle | What It Means | Why It Matters |\n",
    "|-----------|--------------|----------------|\n",
    "| **Everything is ranking** | Even classifiers produce scores for ranking | Unified architecture across products |\n",
    "| **Multi-stage funnel** | Candidate gen â†’ ranking â†’ re-ranking | Handles scale (billions of items) |\n",
    "| **Probability â†’ value function** | Models predict P(action), weights define value | Separates ML from product decisions |\n",
    "| **Training â‰  serving** | Different constraints, different optimizations | Prevents production surprises |\n",
    "| **Feature freshness matters** | Stale features = wrong predictions | Real-time systems need real-time data |\n",
    "| **Feedback loops exist** | Model predictions affect training data | Requires exploration, monitoring |\n",
    "| **Offline â‰  online metrics** | AUC doesn't guarantee CTR improvement | Must validate with A/B tests |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ Interview Drills\n",
    "\n",
    "### Drill 1: \"Explain the Meta ML architecture in 2 minutes\"\n",
    "\n",
    "**Model answer:**\n",
    "> \"At Meta, every ML systemâ€”Feed, Ads, Reelsâ€”follows a multi-stage funnel. First, candidate generation uses cheap retrieval to narrow billions of items to thousands. Then, a lightweight first-pass ranker reduces to hundreds. The main rankerâ€”a deep neural networkâ€”precisely scores these with hundreds of features. Finally, a re-ranker applies business logic like diversity. Each stage trades off recall vs. precision and cost vs. quality. The models predict probabilities of user actionsâ€”click, like, share, hideâ€”and a value function combines these into a final score. The weights in this function are product decisions, not learned. Key challenges are training-serving skew, feature freshness, and feedback loops where our predictions affect our future training data.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 2: \"What tradeoff would you call out first?\"\n",
    "\n",
    "**Strong answers:**\n",
    "- \"Latency vs. model complexity. Heavier models are more accurate but slower. At Meta scale, 50ms extra means billions of lost impressions.\"\n",
    "- \"Feature freshness vs. compute cost. Real-time features are expensive but capture current state. We need to choose which features are worth the cost.\"\n",
    "- \"Exploration vs. exploitation. Showing suboptimal content hurts short-term engagement but is necessary to learn and avoid filter bubbles.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 3: \"What would you change if latency doubles?\"\n",
    "\n",
    "**Strong answers:**\n",
    "- \"Reduce candidate set sizeâ€”tighter filters in candidate generation\"\n",
    "- \"Simplify ranking modelâ€”fewer layers, fewer features\"\n",
    "- \"More aggressive caching of user/item embeddings\"\n",
    "- \"Move computation offlineâ€”precompute more, personalize less at serving time\"\n",
    "- \"Shard by geographyâ€”colocate users and content\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 4: \"What breaks when traffic increases 10x?\"\n",
    "\n",
    "**Strong answers:**\n",
    "- \"Feature store becomes bottleneckâ€”cache hit rates drop\"\n",
    "- \"Model serving infrastructureâ€”need more replicas, but cold start latency hurts\"\n",
    "- \"Training pipelineâ€”more logs to process, may fall behind\"\n",
    "- \"Feature freshness degradesâ€”streaming pipeline can't keep up\"\n",
    "- \"A/B test velocity slowsâ€”need more traffic per experiment for significance\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook covered the **mental model**. The remaining notebooks dive deep:\n",
    "\n",
    "1. **Problem Framing** â†’ How to convert vague goals into ML objectives\n",
    "2. **Data & Labels** â†’ Where labels come from, biases in implicit feedback\n",
    "3. **Feature Engineering** â†’ What features matter, how to think about freshness\n",
    "4. **Modeling & Tradeoffs** â†’ Model architectures, multi-task learning\n",
    "5. **Evaluation** â†’ Offline vs online metrics, when they disagree\n",
    "6. **Serving & Experimentation** â†’ A/B testing, shadow deployment\n",
    "7. **Monitoring & Feedback Loops** â†’ Detecting drift, avoiding bias amplification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

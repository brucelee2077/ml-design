{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Clarifying Requirements (Meta Interview Frame)\n",
    "\n",
    "---\n",
    "\n",
    "## What the Chapter Says\n",
    "\n",
    "The first step in the ML System Design framework is **Clarifying Requirements**. The chapter specifies these exact question categories:\n",
    "\n",
    "1. **Business objective** - What is the company trying to achieve?\n",
    "2. **Features system supports** - e.g., like/dislike as labels\n",
    "3. **Data** - sources, size, labeled or not?\n",
    "4. **Constraints** - compute, cloud vs on-device, improve automatically?\n",
    "5. **Scale** - users, items, growth expectations\n",
    "6. **Performance** - real-time? latency vs accuracy tradeoffs?\n",
    "7. **Privacy/Ethics** - additional considerations\n",
    "\n",
    "**Key instruction**: Align scope with interviewer + write requirements down.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Interview Signal\n",
    "\n",
    "| Level | Expectations |\n",
    "|-------|-------------|\n",
    "| **E5** | Asks structured clarifying questions. Covers all categories. Writes down requirements. Doesn't jump to solutions. |\n",
    "| **E6** | Probes deeper on scale (\"how many events per second?\"). Anticipates constraints not mentioned. Identifies ambiguities in business objective. Asks about failure tolerance and iteration cadence. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Question Categories Framework\n",
    "\n",
    "Use this exact structure in every ML System Design interview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Create the framework table (must match chapter)\n",
    "categories = pd.DataFrame({\n",
    "    'Category': [\n",
    "        'Business Objective',\n",
    "        'Features System Supports',\n",
    "        'Data',\n",
    "        'Constraints',\n",
    "        'Scale',\n",
    "        'Performance',\n",
    "        'Privacy/Ethics'\n",
    "    ],\n",
    "    'Example Questions': [\n",
    "        'What metric defines success? Revenue? Engagement? Safety?',\n",
    "        'What actions can users take? Like/dislike? Comments? Shares?',\n",
    "        'What data exists? How much? Is it labeled? Fresh or historical?',\n",
    "        'Cloud or on-device? GPU available? Auto-improve or static model?',\n",
    "        'How many users? Items? Requests per second? Growth rate?',\n",
    "        'Real-time needed? Max latency? Accuracy vs speed tradeoff?',\n",
    "        'Sensitive data? Anonymization needed? Bias concerns?'\n",
    "    ],\n",
    "    'Why It Matters': [\n",
    "        'Defines the ML objective and success criteria',\n",
    "        'Determines what labels are available naturally',\n",
    "        'Shapes feature engineering and model choice',\n",
    "        'Limits solution space (can\\'t use GPUs if on-device)',\n",
    "        'Affects architecture: batch vs streaming, sharding',\n",
    "        'Drives latency requirements and model complexity',\n",
    "        'May require differential privacy, fairness constraints'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLARIFYING REQUIREMENTS FRAMEWORK (from Chapter)\")\n",
    "print(\"=\" * 80)\n",
    "print(categories.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual diagram of the categories\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('off')\n",
    "ax.set_title('Clarifying Requirements: Question Categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "categories_viz = [\n",
    "    ('Business\\nObjective', '#BBDEFB', 0, 6),\n",
    "    ('Features\\nSupported', '#C8E6C9', 2, 6),\n",
    "    ('Data', '#FFF9C4', 4, 6),\n",
    "    ('Constraints', '#FFCCBC', 6, 6),\n",
    "    ('Scale', '#E1BEE7', 1, 3.5),\n",
    "    ('Performance', '#B2DFDB', 3, 3.5),\n",
    "    ('Privacy/\\nEthics', '#F8BBD9', 5, 3.5),\n",
    "]\n",
    "\n",
    "for (label, color, x, y) in categories_viz:\n",
    "    rect = mpatches.FancyBboxPatch((x, y), 1.8, 1.5, boxstyle='round,pad=0.1',\n",
    "                                    facecolor=color, edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + 0.9, y + 0.75, label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Central box\n",
    "rect = mpatches.FancyBboxPatch((2.5, 0.5), 3, 1.5, boxstyle='round,pad=0.1',\n",
    "                                facecolor='white', edgecolor='red', linewidth=3)\n",
    "ax.add_patch(rect)\n",
    "ax.text(4, 1.25, 'WRITE\\nREQUIREMENTS\\nDOWN', ha='center', va='center', \n",
    "        fontsize=11, fontweight='bold', color='red')\n",
    "\n",
    "# Arrows\n",
    "arrow_props = dict(arrowstyle='->', color='gray', lw=1.5)\n",
    "for (_, _, x, y) in categories_viz:\n",
    "    ax.annotate('', xy=(4, 2), xytext=(x + 0.9, y), arrowprops=arrow_props)\n",
    "\n",
    "ax.set_xlim(-0.5, 8.5)\n",
    "ax.set_ylim(0, 8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hands-On: Simulated Interview Scenarios\n",
    "\n",
    "Let's practice the clarifying requirements step for multiple scenarios. These mirror the chapter's examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define interview scenarios from the chapter\n",
    "scenarios = {\n",
    "    'Event Ticket Selling App': {\n",
    "        'business_objective': 'Increase ticket sales',\n",
    "        'features_supported': ['event search', 'recommendations', 'like/save events', 'purchase'],\n",
    "        'data': {\n",
    "            'sources': ['user profiles', 'event catalog', 'purchase history', 'browsing logs'],\n",
    "            'size': '10M users, 500K events, 50M interactions/month',\n",
    "            'labeled': 'Yes - purchases are natural labels'\n",
    "        },\n",
    "        'constraints': {\n",
    "            'compute': 'Cloud-based, GPU available for training',\n",
    "            'auto_improve': 'Yes, retrain weekly'\n",
    "        },\n",
    "        'scale': {\n",
    "            'users': '10M',\n",
    "            'items': '500K events',\n",
    "            'growth': '20% YoY'\n",
    "        },\n",
    "        'performance': {\n",
    "            'latency': '< 100ms for recommendations',\n",
    "            'real_time': 'Yes for search, batch OK for email campaigns'\n",
    "        },\n",
    "        'privacy_ethics': 'Location data sensitive, GDPR compliance needed'\n",
    "    },\n",
    "    'Video Streaming App': {\n",
    "        'business_objective': 'Increase engagement (watch time)',\n",
    "        'features_supported': ['video feed', 'like/dislike', 'watch history', 'follow creators'],\n",
    "        'data': {\n",
    "            'sources': ['video metadata', 'user interactions', 'watch sessions', 'creator info'],\n",
    "            'size': '100M users, 10M videos, 1B watch events/day',\n",
    "            'labeled': 'Yes - watch time is natural label'\n",
    "        },\n",
    "        'constraints': {\n",
    "            'compute': 'Massive cloud infra, distributed training',\n",
    "            'auto_improve': 'Continuous learning, multiple times per day'\n",
    "        },\n",
    "        'scale': {\n",
    "            'users': '100M',\n",
    "            'items': '10M videos',\n",
    "            'growth': '50% YoY'\n",
    "        },\n",
    "        'performance': {\n",
    "            'latency': '< 50ms for feed ranking',\n",
    "            'real_time': 'Yes - immediate personalization'\n",
    "        },\n",
    "        'privacy_ethics': 'Content safety critical, age-appropriate filtering'\n",
    "    },\n",
    "    'Harmful Content Detection': {\n",
    "        'business_objective': 'Improve platform safety',\n",
    "        'features_supported': ['post creation', 'reporting', 'appeals'],\n",
    "        'data': {\n",
    "            'sources': ['post content (text/image/video)', 'user reports', 'moderator decisions'],\n",
    "            'size': '1B posts/day, 1M flagged posts/day',\n",
    "            'labeled': 'Partially - moderator labels expensive, user reports noisy'\n",
    "        },\n",
    "        'constraints': {\n",
    "            'compute': 'Must run on every post, massive scale',\n",
    "            'auto_improve': 'Yes, new harmful patterns emerge constantly'\n",
    "        },\n",
    "        'scale': {\n",
    "            'users': '1B',\n",
    "            'items': '1B posts/day',\n",
    "            'growth': '10% YoY'\n",
    "        },\n",
    "        'performance': {\n",
    "            'latency': '< 200ms per post',\n",
    "            'real_time': 'Yes - must classify before post is shown'\n",
    "        },\n",
    "        'privacy_ethics': 'False positives = censorship concerns, false negatives = safety risk'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display one scenario in detail\n",
    "import json\n",
    "print(\"=\" * 80)\n",
    "print(\"SCENARIO: Event Ticket Selling App\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(scenarios['Event Ticket Selling App'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a requirements template class\n",
    "class RequirementsTemplate:\n",
    "    \"\"\"Template for documenting ML system requirements (chapter-aligned)\"\"\"\n",
    "    \n",
    "    def __init__(self, system_name):\n",
    "        self.system_name = system_name\n",
    "        self.requirements = {\n",
    "            'business_objective': None,\n",
    "            'features_supported': [],\n",
    "            'data': {\n",
    "                'sources': [],\n",
    "                'size': None,\n",
    "                'labeled': None\n",
    "            },\n",
    "            'constraints': {\n",
    "                'compute': None,\n",
    "                'deployment': None,  # cloud vs on-device\n",
    "                'auto_improve': None\n",
    "            },\n",
    "            'scale': {\n",
    "                'users': None,\n",
    "                'items': None,\n",
    "                'qps': None,\n",
    "                'growth': None\n",
    "            },\n",
    "            'performance': {\n",
    "                'latency_requirement': None,\n",
    "                'real_time': None,\n",
    "                'accuracy_threshold': None\n",
    "            },\n",
    "            'privacy_ethics': {\n",
    "                'sensitive_data': None,\n",
    "                'anonymization': None,\n",
    "                'bias_concerns': None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def set_business_objective(self, objective):\n",
    "        self.requirements['business_objective'] = objective\n",
    "        return self\n",
    "    \n",
    "    def set_features(self, features):\n",
    "        self.requirements['features_supported'] = features\n",
    "        return self\n",
    "    \n",
    "    def set_data(self, sources, size, labeled):\n",
    "        self.requirements['data'] = {'sources': sources, 'size': size, 'labeled': labeled}\n",
    "        return self\n",
    "    \n",
    "    def set_constraints(self, compute, deployment, auto_improve):\n",
    "        self.requirements['constraints'] = {\n",
    "            'compute': compute, 'deployment': deployment, 'auto_improve': auto_improve\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def set_scale(self, users, items, qps, growth):\n",
    "        self.requirements['scale'] = {\n",
    "            'users': users, 'items': items, 'qps': qps, 'growth': growth\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def set_performance(self, latency, real_time, accuracy):\n",
    "        self.requirements['performance'] = {\n",
    "            'latency_requirement': latency, 'real_time': real_time, 'accuracy_threshold': accuracy\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def set_privacy_ethics(self, sensitive, anonymization, bias):\n",
    "        self.requirements['privacy_ethics'] = {\n",
    "            'sensitive_data': sensitive, 'anonymization': anonymization, 'bias_concerns': bias\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def summarize(self):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"REQUIREMENTS DOCUMENT: {self.system_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(json.dumps(self.requirements, indent=2))\n",
    "        return self.requirements\n",
    "\n",
    "# Example: Fill out requirements for Friend Recommendation\n",
    "friend_rec = RequirementsTemplate('Friend Recommendation System')\n",
    "friend_rec.set_business_objective('Increase network growth (maximize formed connections)')\n",
    "friend_rec.set_features(['friend suggestions', 'mutual friends display', 'accept/ignore actions'])\n",
    "friend_rec.set_data(\n",
    "    sources=['social graph', 'user profiles', 'interaction history', 'mutual connections'],\n",
    "    size='500M users, 100B edges in graph',\n",
    "    labeled='Yes - accepted requests are positive labels'\n",
    ")\n",
    "friend_rec.set_constraints(\n",
    "    compute='Cloud, distributed graph processing',\n",
    "    deployment='Cloud',\n",
    "    auto_improve='Daily retraining'\n",
    ")\n",
    "friend_rec.set_scale(\n",
    "    users='500M',\n",
    "    items='500M potential friends per user',\n",
    "    qps='100K friend suggestion requests/sec',\n",
    "    growth='10% YoY'\n",
    ")\n",
    "friend_rec.set_performance(\n",
    "    latency='< 200ms for top-10 suggestions',\n",
    "    real_time='Batch pre-computation acceptable',\n",
    "    accuracy='Precision@10 > 0.3'\n",
    ")\n",
    "friend_rec.set_privacy_ethics(\n",
    "    sensitive='Social connections are sensitive',\n",
    "    anonymization='Cannot show why recommendation was made (privacy)',\n",
    "    bias='Avoid filter bubbles, ensure diverse suggestions'\n",
    ")\n",
    "friend_rec.summarize();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice: Structured Question Asking\n",
    "\n",
    "Here's how to structure your clarifying questions in the interview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question templates for each category\n",
    "question_templates = {\n",
    "    'Business Objective': [\n",
    "        \"What is the primary business metric we're trying to optimize?\",\n",
    "        \"How is success currently measured for this product?\",\n",
    "        \"Are there secondary objectives we should consider?\",\n",
    "        \"What's the current baseline performance?\"\n",
    "    ],\n",
    "    'Features Supported': [\n",
    "        \"What user actions are available in the product?\",\n",
    "        \"Which actions can serve as implicit labels (e.g., like/dislike)?\",\n",
    "        \"Are there any upcoming features that might affect this?\",\n",
    "        \"How do users currently interact with the system?\"\n",
    "    ],\n",
    "    'Data': [\n",
    "        \"What data sources are available?\",\n",
    "        \"How much historical data do we have?\",\n",
    "        \"Is the data labeled? If so, how were labels obtained?\",\n",
    "        \"How fresh is the data? Real-time or batch?\",\n",
    "        \"What's the data quality like? Missing values? Noise?\"\n",
    "    ],\n",
    "    'Constraints': [\n",
    "        \"Is this cloud-based or needs to run on-device?\",\n",
    "        \"What compute resources are available for training?\",\n",
    "        \"What compute resources are available for inference?\",\n",
    "        \"Should the model improve automatically over time?\",\n",
    "        \"Are there budget constraints?\"\n",
    "    ],\n",
    "    'Scale': [\n",
    "        \"How many users does the system serve?\",\n",
    "        \"How many items (videos/posts/events) are in the catalog?\",\n",
    "        \"What's the expected queries per second (QPS)?\",\n",
    "        \"What's the expected growth rate?\"\n",
    "    ],\n",
    "    'Performance': [\n",
    "        \"What's the maximum acceptable latency?\",\n",
    "        \"Does the system need real-time predictions?\",\n",
    "        \"What's the tradeoff between latency and accuracy?\",\n",
    "        \"Are there specific accuracy thresholds we need to meet?\"\n",
    "    ],\n",
    "    'Privacy/Ethics': [\n",
    "        \"Is any of the data sensitive (PII, health, financial)?\",\n",
    "        \"Are there anonymization requirements?\",\n",
    "        \"Are there concerns about bias in the model?\",\n",
    "        \"Are there regulatory requirements (GDPR, etc.)?\",\n",
    "        \"What happens if the model makes a mistake? (Impact analysis)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"CLARIFYING QUESTION CHEAT SHEET\")\n",
    "print(\"=\" * 60)\n",
    "for category, questions in question_templates.items():\n",
    "    print(f\"\\n{category.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    for q in questions:\n",
    "        print(f\"  - {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tradeoffs Discussion (Chapter-Aligned)\n",
    "\n",
    "The chapter emphasizes these tradeoffs during requirements gathering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeoffs = pd.DataFrame({\n",
    "    'Tradeoff': [\n",
    "        'Latency vs Accuracy',\n",
    "        'Cloud vs On-Device',\n",
    "        'Manual Labels vs Natural Labels',\n",
    "        'Real-time vs Batch',\n",
    "        'Precision vs Recall'\n",
    "    ],\n",
    "    'When to favor Option A': [\n",
    "        'User-facing, interactive features',\n",
    "        'High compute needs, easier updates',\n",
    "        'When natural labels unavailable/noisy',\n",
    "        'Time-sensitive predictions',\n",
    "        'Harmful content (high-stakes false positives)'\n",
    "    ],\n",
    "    'When to favor Option B': [\n",
    "        'Offline batch processing, reports',\n",
    "        'Privacy-sensitive, no network needed',\n",
    "        'When user actions = labels (engagement)',\n",
    "        'Can precompute, cost-sensitive',\n",
    "        'Fraud detection (catch more, review later)'\n",
    "    ],\n",
    "    'Interview Signal': [\n",
    "        'E5: Knows tradeoff exists. E6: Quantifies (50ms vs 200ms, +2% accuracy)',\n",
    "        'E5: Can list differences. E6: Discusses hybrid approaches',\n",
    "        'E5: Understands both. E6: Discusses label quality over time',\n",
    "        'E5: Knows when each applies. E6: Discusses freshness SLAs',\n",
    "        'E5: Knows formulas. E6: Ties to business impact'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"KEY TRADEOFFS TO SURFACE DURING REQUIREMENTS\")\n",
    "print(\"=\" * 100)\n",
    "print(tradeoffs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hands-On: Mock Interview Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MockInterviewer:\n",
    "    \"\"\"Simulates an interviewer for requirements gathering practice\"\"\"\n",
    "    \n",
    "    def __init__(self, scenario):\n",
    "        self.scenario = scenario\n",
    "        self.questions_asked = []\n",
    "        self.revealed_info = set()\n",
    "    \n",
    "    def ask(self, question):\n",
    "        \"\"\"Simulate asking the interviewer a question\"\"\"\n",
    "        self.questions_asked.append(question)\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # Determine what information to reveal based on question\n",
    "        response = \"Could you be more specific?\"\n",
    "        \n",
    "        if 'business' in question_lower or 'objective' in question_lower or 'goal' in question_lower:\n",
    "            response = f\"Our main goal is: {self.scenario['business_objective']}\"\n",
    "            self.revealed_info.add('business_objective')\n",
    "            \n",
    "        elif 'feature' in question_lower or 'action' in question_lower or 'user' in question_lower:\n",
    "            response = f\"Users can: {', '.join(self.scenario['features_supported'])}\"\n",
    "            self.revealed_info.add('features')\n",
    "            \n",
    "        elif 'data' in question_lower or 'label' in question_lower:\n",
    "            response = f\"Data sources: {self.scenario['data']['sources']}. Size: {self.scenario['data']['size']}. Labels: {self.scenario['data']['labeled']}\"\n",
    "            self.revealed_info.add('data')\n",
    "            \n",
    "        elif 'scale' in question_lower or 'users' in question_lower or 'traffic' in question_lower:\n",
    "            response = f\"Scale: {self.scenario['scale']['users']} users, {self.scenario['scale']['items']} items, growing {self.scenario['scale']['growth']}\"\n",
    "            self.revealed_info.add('scale')\n",
    "            \n",
    "        elif 'latency' in question_lower or 'performance' in question_lower or 'speed' in question_lower:\n",
    "            response = f\"Latency requirement: {self.scenario['performance']['latency']}. Real-time: {self.scenario['performance']['real_time']}\"\n",
    "            self.revealed_info.add('performance')\n",
    "            \n",
    "        elif 'privacy' in question_lower or 'ethic' in question_lower or 'bias' in question_lower:\n",
    "            response = f\"Privacy/Ethics concerns: {self.scenario['privacy_ethics']}\"\n",
    "            self.revealed_info.add('privacy')\n",
    "            \n",
    "        elif 'constrain' in question_lower or 'compute' in question_lower or 'device' in question_lower:\n",
    "            response = f\"Constraints: {self.scenario['constraints']['compute']}. Auto-improve: {self.scenario['constraints']['auto_improve']}\"\n",
    "            self.revealed_info.add('constraints')\n",
    "        \n",
    "        print(f\"\\n[Interviewer]: {response}\")\n",
    "        return response\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"Score the candidate's question coverage\"\"\"\n",
    "        all_categories = {'business_objective', 'features', 'data', 'scale', 'performance', 'privacy', 'constraints'}\n",
    "        coverage = len(self.revealed_info) / len(all_categories)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"INTERVIEW SCORE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Questions asked: {len(self.questions_asked)}\")\n",
    "        print(f\"Categories covered: {len(self.revealed_info)}/{len(all_categories)} ({coverage*100:.0f}%)\")\n",
    "        print(f\"Covered: {self.revealed_info}\")\n",
    "        print(f\"Missed: {all_categories - self.revealed_info}\")\n",
    "        \n",
    "        if coverage >= 0.85:\n",
    "            print(\"\\n[Feedback]: Excellent coverage! You asked about all key areas.\")\n",
    "        elif coverage >= 0.6:\n",
    "            print(\"\\n[Feedback]: Good coverage, but missed some important areas.\")\n",
    "        else:\n",
    "            print(\"\\n[Feedback]: Need to ask more structured questions across all categories.\")\n",
    "\n",
    "# Demo\n",
    "print(\"MOCK INTERVIEW: Video Streaming Recommendation\")\n",
    "print(\"=\"*60)\n",
    "interviewer = MockInterviewer(scenarios['Video Streaming App'])\n",
    "\n",
    "# Simulate candidate questions\n",
    "interviewer.ask(\"What is the business objective we're trying to optimize?\")\n",
    "interviewer.ask(\"What user actions and features does the app support?\")\n",
    "interviewer.ask(\"What data do we have available and is it labeled?\")\n",
    "interviewer.ask(\"What's the scale - how many users and videos?\")\n",
    "interviewer.ask(\"What are the latency and performance requirements?\")\n",
    "interviewer.ask(\"Are there privacy or ethical concerns I should know about?\")\n",
    "interviewer.ask(\"What are the compute constraints?\")\n",
    "\n",
    "interviewer.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Meta Interview Signal (Detailed)\n",
    "\n",
    "### E5 Answer Expectations\n",
    "\n",
    "- Asks structured questions across all 7 categories\n",
    "- Writes down requirements as they're revealed\n",
    "- Doesn't jump to solutions before understanding the problem\n",
    "- Clarifies ambiguities (\"When you say engagement, do you mean watch time or interactions?\")\n",
    "- Summarizes requirements back to interviewer before proceeding\n",
    "\n",
    "### E6 Additions\n",
    "\n",
    "- **Probes deeper**: \"You mentioned 100M users - what's the DAU? Peak QPS? Geographic distribution?\"\n",
    "- **Anticipates constraints**: \"Since this is real-time video, I assume we need sub-100ms latency for ranking?\"\n",
    "- **Identifies ambiguities**: \"Increase engagement could mean watch time, sessions, or shares - which is primary?\"\n",
    "- **Discusses failure tolerance**: \"What happens if the recommendation service is down? Fallback to popular content?\"\n",
    "- **Iteration cadence**: \"How often do we expect to retrain? Is there a human-in-the-loop for new patterns?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Chapter Instruction: Write Requirements Down\n",
    "\n",
    "The chapter explicitly states: **\"Align scope with interviewer + write requirements down\"**\n",
    "\n",
    "Here's a template to use during interviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_template = \"\"\"\n",
    "================================================================================\n",
    "ML SYSTEM REQUIREMENTS DOCUMENT\n",
    "================================================================================\n",
    "System: [Name]\n",
    "Date: [Date]\n",
    "Interviewer alignment: [ ] Confirmed\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "1. BUSINESS OBJECTIVE\n",
    "--------------------------------------------------------------------------------\n",
    "Primary goal: _______________________________________________\n",
    "Success metric: _______________________________________________\n",
    "Current baseline: _______________________________________________\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "2. FEATURES SUPPORTED  \n",
    "--------------------------------------------------------------------------------\n",
    "User actions: _______________________________________________\n",
    "Available labels: _______________________________________________\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "3. DATA\n",
    "--------------------------------------------------------------------------------\n",
    "Sources: _______________________________________________\n",
    "Size: _______________________________________________\n",
    "Labeled: [ ] Yes  [ ] No  [ ] Partial\n",
    "Freshness: _______________________________________________\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "4. CONSTRAINTS\n",
    "--------------------------------------------------------------------------------\n",
    "Deployment: [ ] Cloud  [ ] On-device  [ ] Hybrid\n",
    "Compute: _______________________________________________\n",
    "Auto-improve: [ ] Yes  [ ] No\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "5. SCALE\n",
    "--------------------------------------------------------------------------------\n",
    "Users: _______________________________________________\n",
    "Items: _______________________________________________\n",
    "QPS: _______________________________________________\n",
    "Growth: _______________________________________________\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "6. PERFORMANCE\n",
    "--------------------------------------------------------------------------------\n",
    "Latency: _______________________________________________\n",
    "Real-time: [ ] Yes  [ ] No (batch OK)\n",
    "Accuracy vs Latency: _______________________________________________\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "7. PRIVACY / ETHICS\n",
    "--------------------------------------------------------------------------------\n",
    "Sensitive data: _______________________________________________\n",
    "Anonymization: _______________________________________________\n",
    "Bias concerns: _______________________________________________\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(requirements_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Drills\n",
    "\n",
    "### Drill 1: Category Recall\n",
    "From memory, list all 7 clarifying requirement categories. Time yourself - you should do this in under 30 seconds.\n",
    "\n",
    "### Drill 2: Question Generation\n",
    "For each category, write down 3 questions without looking at notes. Practice until you can do this fluently.\n",
    "\n",
    "### Drill 3: Mock Interview\n",
    "Ask a friend to give you a system design prompt. Spend exactly 5 minutes asking clarifying questions and filling out the requirements template.\n",
    "\n",
    "### Drill 4: Tradeoff Articulation\n",
    "For the scenario \"Ad Click Prediction\", articulate:\n",
    "- The latency vs accuracy tradeoff\n",
    "- The precision vs recall tradeoff (what's the cost of false positives vs false negatives?)\n",
    "\n",
    "### Drill 5: E6 Deep Dive\n",
    "Take the \"Harmful Content Detection\" scenario. Go beyond the basic questions:\n",
    "- What failure modes should you anticipate?\n",
    "- How would you handle adversarial users trying to evade detection?\n",
    "- What's the iteration velocity requirement for new harmful content patterns?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

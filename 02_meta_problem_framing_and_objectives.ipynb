{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta ML System Design: Problem Framing & Objectives\n",
    "\n",
    "**Target Level:** Meta E5 â†’ E6  \n",
    "**Core Skill:** Converting vague product goals into measurable ML objectives  \n",
    "**Interview Focus:** Demonstrating product-ML alignment thinking\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "The #1 differentiator between average and exceptional ML engineers at Meta:\n",
    "\n",
    "**Average:** \"We need to predict clicks\"\n",
    "\n",
    "**Exceptional:** \"We need to predict clicks, but optimizing only for clicks leads to clickbait. We should predict a weighted combination of click + dwell time + positive actions - hide - report, where the weights reflect our product values around meaningful engagement.\"\n",
    "\n",
    "This notebook teaches you to think like the second engineer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Problem Framing Framework\n",
    "\n",
    "Every ML system design starts with this question:\n",
    "\n",
    "**\"What are we actually trying to optimize?\"**\n",
    "\n",
    "At Meta, this requires translating between three levels:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                          PROBLEM FRAMING LEVELS                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Level 1: BUSINESS OBJECTIVE\n",
    "â”œâ”€â”€ \"Increase user engagement on Facebook\"\n",
    "â”œâ”€â”€ \"Grow Instagram Reels watch time\"\n",
    "â””â”€â”€ \"Improve advertiser ROI\"\n",
    "         â”‚\n",
    "         â”‚ Translation needed: What does \"engagement\" mean exactly?\n",
    "         â–¼\n",
    "Level 2: PRODUCT METRIC\n",
    "â”œâ”€â”€ Daily Active Users (DAU)\n",
    "â”œâ”€â”€ Time Spent per Session\n",
    "â”œâ”€â”€ Posts Created per User\n",
    "â””â”€â”€ Ad Revenue per User\n",
    "         â”‚\n",
    "         â”‚ Translation needed: What action causes this metric to move?\n",
    "         â–¼\n",
    "Level 3: ML OBJECTIVE\n",
    "â”œâ”€â”€ Predict P(click | user, post)\n",
    "â”œâ”€â”€ Predict P(watch > 10s | user, video)\n",
    "â”œâ”€â”€ Predict P(create_post | user, prompt)\n",
    "â””â”€â”€ Predict P(convert | user, ad)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ðŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Clearly articulates all three levels for a given problem. Shows awareness that business objectives need translation.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses the translation gapsâ€”why a product metric might not perfectly align with business objectives (Goodhart's Law), and how ML objectives can game product metrics.\n",
    ">\n",
    "> **Common Pitfall:** Jumping straight to \"predict clicks\" without explaining why clicks matter and what happens when you over-optimize for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Good vs Bad Problem Framing: Examples\n",
    "\n",
    "### Example 1: News Feed Ranking\n",
    "\n",
    "| Aspect | âŒ Bad Framing | âœ… Good Framing |\n",
    "|--------|---------------|----------------|\n",
    "| **Goal** | \"Predict what posts users will click\" | \"Predict what posts lead to meaningful engagement\" |\n",
    "| **ML Task** | Binary classification: click/no-click | Multi-task: P(click), P(like), P(comment), P(share), P(hide), P(report) |\n",
    "| **Label** | Click happened | Multiple signals with different weights |\n",
    "| **Problem** | Optimizes for clickbait | Balances engagement quality |\n",
    "| **Failure Mode** | Users click but regret it, leave platform | Considered in negative signals (hide, report) |\n",
    "\n",
    "### Example 2: Friend Suggestions (People You May Know)\n",
    "\n",
    "| Aspect | âŒ Bad Framing | âœ… Good Framing |\n",
    "|--------|---------------|----------------|\n",
    "| **Goal** | \"Predict friend request probability\" | \"Predict mutual friendship probability\" |\n",
    "| **ML Task** | P(send_request \\| suggestion) | P(accepted_friendship \\| suggestion) |\n",
    "| **Label** | Request sent | Request sent AND accepted |\n",
    "| **Problem** | Suggests people who get many requests | Suggests people likely to form real connections |\n",
    "| **Failure Mode** | Spam popular users, creepy suggestions | Considered: only suggest likely mutual connections |\n",
    "\n",
    "### Example 3: Notification Ranking\n",
    "\n",
    "| Aspect | âŒ Bad Framing | âœ… Good Framing |\n",
    "|--------|---------------|----------------|\n",
    "| **Goal** | \"Maximize notification opens\" | \"Maximize opens without causing notification fatigue\" |\n",
    "| **ML Task** | P(open \\| notification) | P(open) - Î» Ã— P(disable_notifications) |\n",
    "| **Label** | Notification opened | Open and long-term notification preferences |\n",
    "| **Problem** | Send too many notifications | Balances short-term engagement with retention |\n",
    "| **Failure Mode** | Users disable notifications or uninstall | Considered in penalty term |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Demonstration: Why single-objective optimization fails\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate 1000 posts with different characteristics\n",
    "n_posts = 1000\n",
    "\n",
    "# Post types:\n",
    "# - Clickbait: High click rate, low dwell time, high hide rate\n",
    "# - Quality: Medium click rate, high dwell time, low hide rate\n",
    "# - Boring: Low click rate, medium dwell time, low hide rate\n",
    "\n",
    "post_types = np.random.choice(['clickbait', 'quality', 'boring'], n_posts, p=[0.2, 0.3, 0.5])\n",
    "\n",
    "def generate_engagement(post_type):\n",
    "    if post_type == 'clickbait':\n",
    "        return {\n",
    "            'p_click': np.random.beta(8, 3),      # High clicks\n",
    "            'dwell_time': np.random.exponential(5),  # Low dwell\n",
    "            'p_like': np.random.beta(1, 10),      # Low likes\n",
    "            'p_hide': np.random.beta(4, 6),       # High hides\n",
    "        }\n",
    "    elif post_type == 'quality':\n",
    "        return {\n",
    "            'p_click': np.random.beta(4, 4),      # Medium clicks\n",
    "            'dwell_time': np.random.exponential(30), # High dwell\n",
    "            'p_like': np.random.beta(4, 4),       # Good likes\n",
    "            'p_hide': np.random.beta(1, 15),      # Low hides\n",
    "        }\n",
    "    else:  # boring\n",
    "        return {\n",
    "            'p_click': np.random.beta(2, 8),      # Low clicks\n",
    "            'dwell_time': np.random.exponential(15), # Medium dwell\n",
    "            'p_like': np.random.beta(2, 8),       # Low-medium likes\n",
    "            'p_hide': np.random.beta(1, 20),      # Very low hides\n",
    "        }\n",
    "\n",
    "posts = pd.DataFrame([generate_engagement(t) for t in post_types])\n",
    "posts['type'] = post_types\n",
    "\n",
    "# Strategy 1: Rank by P(click) only\n",
    "posts['score_click_only'] = posts['p_click']\n",
    "\n",
    "# Strategy 2: Rank by composite score\n",
    "posts['score_composite'] = (\n",
    "    0.3 * posts['p_click'] + \n",
    "    0.01 * posts['dwell_time'] +  # Normalized by typical dwell\n",
    "    0.3 * posts['p_like'] - \n",
    "    0.5 * posts['p_hide']\n",
    ")\n",
    "\n",
    "# Compare what gets ranked in top 100 for each strategy\n",
    "top_100_click = posts.nlargest(100, 'score_click_only')\n",
    "top_100_composite = posts.nlargest(100, 'score_composite')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Composition of top 100 by strategy\n",
    "for ax, top_posts, title in [(axes[0], top_100_click, 'Click-Only Ranking'),\n",
    "                              (axes[1], top_100_composite, 'Composite Ranking')]:\n",
    "    type_counts = top_posts['type'].value_counts()\n",
    "    colors = {'clickbait': 'red', 'quality': 'green', 'boring': 'gray'}\n",
    "    ax.bar(type_counts.index, type_counts.values, \n",
    "           color=[colors[t] for t in type_counts.index])\n",
    "    ax.set_ylabel('Count in Top 100')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(0, 80)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 100 composition:\")\n",
    "print(f\"\\nClick-only: {dict(top_100_click['type'].value_counts())}\")\n",
    "print(f\"Composite:  {dict(top_100_composite['type'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Multi-Objective Value Function\n",
    "\n",
    "At Meta, the ranking score is almost never a single prediction. It's a **value function** that combines multiple predictions:\n",
    "\n",
    "```\n",
    "Value = Î£ (wáµ¢ Ã— Páµ¢) for positive actions\n",
    "      - Î£ (wâ±¼ Ã— Pâ±¼) for negative actions\n",
    "      \n",
    "Where:\n",
    "- Páµ¢ = model prediction for action i\n",
    "- wáµ¢ = product-defined weight for action i\n",
    "```\n",
    "\n",
    "### Feed Ranking Example:\n",
    "```\n",
    "Value = w_click Ã— P(click)\n",
    "      + w_like Ã— P(like)\n",
    "      + w_comment Ã— P(comment)\n",
    "      + w_share Ã— P(share)\n",
    "      + w_long_view Ã— P(watch > 10s)\n",
    "      - w_hide Ã— P(hide)\n",
    "      - w_report Ã— P(report)\n",
    "      - w_unfollow Ã— P(unfollow_author)\n",
    "```\n",
    "\n",
    "### Why Separate Models from Weights?\n",
    "\n",
    "1. **Model changes require retraining** (days/weeks)\n",
    "2. **Weight changes are instant** (no retraining)\n",
    "3. **Product can tune weights** without ML team\n",
    "4. **A/B test weights** independently from model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Tuning weights to change behavior\n",
    "\n",
    "# Suppose we have a model that predicts these probabilities\n",
    "np.random.seed(42)\n",
    "n_posts = 500\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'post_id': range(n_posts),\n",
    "    'p_click': np.random.beta(3, 5, n_posts),\n",
    "    'p_like': np.random.beta(2, 8, n_posts),\n",
    "    'p_comment': np.random.beta(1, 15, n_posts),\n",
    "    'p_share': np.random.beta(1, 20, n_posts),\n",
    "    'p_hide': np.random.beta(1, 30, n_posts),\n",
    "    'is_video': np.random.binomial(1, 0.3, n_posts),  # 30% are videos\n",
    "})\n",
    "\n",
    "# Different weight configurations for different product goals\n",
    "weight_configs = {\n",
    "    'Engagement Focus': {\n",
    "        'click': 1.0, 'like': 0.5, 'comment': 0.5, 'share': 0.5, 'hide': 2.0\n",
    "    },\n",
    "    'Quality Focus': {\n",
    "        'click': 0.2, 'like': 1.0, 'comment': 2.0, 'share': 2.0, 'hide': 5.0\n",
    "    },\n",
    "    'Video Push': {\n",
    "        'click': 0.5, 'like': 0.5, 'comment': 0.5, 'share': 0.5, 'hide': 2.0,\n",
    "        'video_boost': 3.0  # Extra boost for videos\n",
    "    },\n",
    "}\n",
    "\n",
    "def compute_value(df, weights):\n",
    "    score = (\n",
    "        weights['click'] * df['p_click'] +\n",
    "        weights['like'] * df['p_like'] +\n",
    "        weights['comment'] * df['p_comment'] +\n",
    "        weights['share'] * df['p_share'] -\n",
    "        weights['hide'] * df['p_hide']\n",
    "    )\n",
    "    if 'video_boost' in weights:\n",
    "        score += weights['video_boost'] * df['is_video']\n",
    "    return score\n",
    "\n",
    "# Compute scores under each config\n",
    "for name, weights in weight_configs.items():\n",
    "    predictions[f'score_{name}'] = compute_value(predictions, weights)\n",
    "\n",
    "# Show how top 10 differs\n",
    "print(\"Top 10 posts under different objectives:\\n\")\n",
    "for name in weight_configs:\n",
    "    top_10 = predictions.nlargest(10, f'score_{name}')\n",
    "    video_pct = top_10['is_video'].mean() * 100\n",
    "    avg_hide = top_10['p_hide'].mean()\n",
    "    avg_share = top_10['p_share'].mean()\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  - {video_pct:.0f}% videos in top 10\")\n",
    "    print(f\"  - Avg P(hide): {avg_hide:.4f}\")\n",
    "    print(f\"  - Avg P(share): {avg_share:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ðŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Explains the value function concept and why it's useful. Shows awareness that weights are product decisions.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses how to tune weights (grid search with A/B tests), potential gaming issues (if comment weight is high, people may leave low-quality comments), and governance around weight changes.\n",
    ">\n",
    "> **Common Pitfall:** Trying to learn the weights end-to-end. While possible, it removes product control and makes the system a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Proxy Metrics: When You Can't Measure What You Want\n",
    "\n",
    "Often, what you **want** to optimize is not directly measurable:\n",
    "\n",
    "| What We Want | Why It's Hard | Proxy We Use |\n",
    "|--------------|--------------|-------------|\n",
    "| User satisfaction | Subjective, expensive to measure | Engagement signals + surveys |\n",
    "| Content quality | No universal definition | Shares, comments, dwell time |\n",
    "| Long-term retention | Takes months to observe | Session-level engagement |\n",
    "| Ad effectiveness | Delayed conversions | Click + estimated conversion |\n",
    "\n",
    "### The Proxy Problem\n",
    "\n",
    "```\n",
    "What we want:        User finds valuable content\n",
    "                            â†‘\n",
    "                     (not measurable)\n",
    "                            |\n",
    "What we measure:     User clicks on content\n",
    "                            â†‘\n",
    "                     (correlation, not causation)\n",
    "                            |\n",
    "What we optimize:    P(click | user, content)\n",
    "```\n",
    "\n",
    "**Goodhart's Law:** \"When a measure becomes a target, it ceases to be a good measure.\"\n",
    "\n",
    "If we optimize too hard for clicks, content creators learn to game clicks (clickbait), and clicks no longer indicate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Proxy metric divergence over time\n",
    "\n",
    "def simulate_proxy_divergence(n_rounds=50, optimization_strength=0.1):\n",
    "    \"\"\"\n",
    "    Simulate what happens when we optimize a proxy metric.\n",
    "    \n",
    "    Over time, content creators learn to game the proxy,\n",
    "    and correlation between proxy and true objective decreases.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Initial state: proxy (clicks) correlates with true objective (satisfaction)\n",
    "    correlation = 0.8\n",
    "    \n",
    "    # Gaming pressure: how much creators game the metric each round\n",
    "    gaming_pressure = 0.0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for round_num in range(n_rounds):\n",
    "        # As we optimize for proxy, creators learn to game it\n",
    "        gaming_pressure += optimization_strength * (1 - gaming_pressure)\n",
    "        \n",
    "        # Gaming reduces correlation between proxy and true objective\n",
    "        correlation = 0.8 * (1 - gaming_pressure) + 0.1 * gaming_pressure\n",
    "        \n",
    "        # Proxy metric goes up (we're optimizing it!)\n",
    "        proxy_metric = 1 + round_num * 0.02\n",
    "        \n",
    "        # True objective may not follow\n",
    "        true_objective = 1 + round_num * 0.02 * correlation\n",
    "        \n",
    "        history.append({\n",
    "            'round': round_num,\n",
    "            'proxy_metric': proxy_metric,\n",
    "            'true_objective': true_objective,\n",
    "            'correlation': correlation,\n",
    "            'gaming_pressure': gaming_pressure\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(history)\n",
    "\n",
    "# Compare weak vs strong optimization\n",
    "weak_opt = simulate_proxy_divergence(optimization_strength=0.02)\n",
    "strong_opt = simulate_proxy_divergence(optimization_strength=0.1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot metrics over time\n",
    "ax = axes[0]\n",
    "ax.plot(strong_opt['round'], strong_opt['proxy_metric'], 'b-', \n",
    "        label='Proxy (Clicks)', linewidth=2)\n",
    "ax.plot(strong_opt['round'], strong_opt['true_objective'], 'g--', \n",
    "        label='True Objective (Satisfaction)', linewidth=2)\n",
    "ax.fill_between(strong_opt['round'], \n",
    "                strong_opt['true_objective'], \n",
    "                strong_opt['proxy_metric'],\n",
    "                alpha=0.3, color='red', label='Gap (Gaming)')\n",
    "ax.set_xlabel('Optimization Rounds')\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('Strong Optimization: Proxy Diverges from Truth')\n",
    "ax.legend()\n",
    "\n",
    "# Plot correlation decay\n",
    "ax = axes[1]\n",
    "ax.plot(weak_opt['round'], weak_opt['correlation'], 'g-', \n",
    "        label='Weak optimization', linewidth=2)\n",
    "ax.plot(strong_opt['round'], strong_opt['correlation'], 'r-', \n",
    "        label='Strong optimization', linewidth=2)\n",
    "ax.set_xlabel('Optimization Rounds')\n",
    "ax.set_ylabel('Correlation (Proxy â†” True Objective)')\n",
    "ax.set_title('Correlation Decay Due to Gaming')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions to Proxy Divergence\n",
    "\n",
    "1. **Multiple proxies:** Combine several signals (clicks + dwell + likes - hides)\n",
    "2. **Negative signals:** Include \"regret\" signals (hide, unfollow, report)\n",
    "3. **Long-term outcomes:** Periodically check against retention, survey satisfaction\n",
    "4. **Regularization:** Don't optimize too hard; keep some exploration\n",
    "5. **Human review:** Periodic audits of top-ranked content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Position Bias and Selection Bias\n",
    "\n",
    "When framing problems, you must account for biases in your labels:\n",
    "\n",
    "### Position Bias\n",
    "\n",
    "Items shown in position 1 get more clicks than identical items in position 10, **regardless of relevance**.\n",
    "\n",
    "```\n",
    "Position    Observed CTR    True Relevance\n",
    "   1           15%              Medium\n",
    "   2           8%               High      â† Better item, worse position\n",
    "   3           5%               High  \n",
    "   4           3%               Low\n",
    "   ...\n",
    "```\n",
    "\n",
    "If you train on raw click data, you learn that \"position 1 items are good,\" not that \"relevant items are good.\"\n",
    "\n",
    "### Selection Bias\n",
    "\n",
    "You only observe outcomes for items you showed. Items never shown have no labels.\n",
    "\n",
    "```\n",
    "Candidate Pool: [A, B, C, D, E, F, G, H, I, J]\n",
    "                 â”‚  â”‚  â”‚                      \n",
    "Shown to user:  [A, B, C]  â† Only these get labels!\n",
    "                 â”‚  â”‚  â”‚\n",
    "User clicked:   [A]       â† Training signal\n",
    "\n",
    "Result: We never learn if D, E, F, G, H, I, J were good.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Position bias in click data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate 1000 impressions with position bias\n",
    "n_impressions = 5000\n",
    "\n",
    "# True relevance (what we want to learn)\n",
    "true_relevance = np.random.uniform(0, 1, n_impressions)\n",
    "\n",
    "# Position (1-10)\n",
    "position = np.random.randint(1, 11, n_impressions)\n",
    "\n",
    "# Position bias: higher positions get more clicks regardless of relevance\n",
    "position_bias = 1 / (position ** 0.5)  # Position 1 = 1.0, Position 10 = 0.32\n",
    "\n",
    "# Observed click probability = relevance Ã— position_bias\n",
    "click_prob = true_relevance * position_bias\n",
    "clicks = np.random.binomial(1, np.clip(click_prob, 0, 1))\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'true_relevance': true_relevance,\n",
    "    'position': position,\n",
    "    'position_bias': position_bias,\n",
    "    'click': clicks\n",
    "})\n",
    "\n",
    "# Naive model: predict click from relevance only (ignoring position)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Model 1: Naive (just relevance as feature, trained on biased clicks)\n",
    "X_naive = data[['true_relevance']].values\n",
    "model_naive = LogisticRegression()\n",
    "model_naive.fit(X_naive, clicks)\n",
    "\n",
    "# Model 2: Position-aware (include position as feature)\n",
    "X_position = data[['true_relevance', 'position']].values\n",
    "model_position = LogisticRegression()\n",
    "model_position.fit(X_position, clicks)\n",
    "\n",
    "# Evaluate: which model better captures TRUE relevance?\n",
    "# Test on position-1 data only (where bias is constant)\n",
    "pos1_mask = data['position'] == 1\n",
    "\n",
    "print(\"Correlation with TRUE relevance (on position-1 data):\")\n",
    "print(f\"  Naive model:    {np.corrcoef(model_naive.predict_proba(X_naive[pos1_mask])[:, 1], data.loc[pos1_mask, 'true_relevance'])[0,1]:.3f}\")\n",
    "print(f\"  Position-aware: {np.corrcoef(model_position.predict_proba(X_position[pos1_mask])[:, 1], data.loc[pos1_mask, 'true_relevance'])[0,1]:.3f}\")\n",
    "\n",
    "# Show average click rate by position\n",
    "print(\"\\nObserved CTR by position (demonstrates bias):\")\n",
    "ctr_by_pos = data.groupby('position')['click'].mean()\n",
    "for pos in range(1, 6):\n",
    "    print(f\"  Position {pos}: {ctr_by_pos[pos]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Position Bias\n",
    "\n",
    "1. **Include position as feature:** Let model learn the bias, then set position=1 at inference\n",
    "2. **Inverse propensity weighting:** Weight examples by 1/P(shown at this position)\n",
    "3. **Randomization:** Randomly shuffle some traffic to get unbiased labels\n",
    "4. **Multi-task learning:** Predict (relevance, position_ctr) separately\n",
    "\n",
    "> **ðŸ§  Meta Interview Signal**\n",
    ">\n",
    "> **Strong E5 Answer:** Identifies position bias as a problem and proposes at least one solution.\n",
    ">\n",
    "> **E6 Answer Adds:** Discusses tradeoffs between solutions (randomization costs engagement, IPW has high variance), and how to validate debiasing worked.\n",
    ">\n",
    "> **Common Pitfall:** Training directly on click data without mentioning position bias at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Framing for Different Meta Products\n",
    "\n",
    "### Feed Ranking\n",
    "```\n",
    "Business Goal: Keep users engaged with meaningful content\n",
    "Product Metric: Daily engagement, time spent, content creation\n",
    "ML Objective: Score(post) = Î£ wáµ¢ Ã— P(actionáµ¢ | user, post)\n",
    "Key Actions: click, like, comment, share, save, long_view, hide, report\n",
    "```\n",
    "\n",
    "### Ads Ranking\n",
    "```\n",
    "Business Goal: Maximize revenue while maintaining user experience\n",
    "Product Metric: Revenue, advertiser ROI, user ad tolerance\n",
    "ML Objective: Score(ad) = Bid Ã— P(click) Ã— P(convert | click) Ã— Quality\n",
    "Key Considerations: Ad load (how many ads), relevance, diversity\n",
    "```\n",
    "\n",
    "### Reels Recommendations\n",
    "```\n",
    "Business Goal: Maximize watch time and creator ecosystem\n",
    "Product Metric: Watch time, completion rate, creator uploads\n",
    "ML Objective: Score(reel) = P(watch > threshold) Ã— expected_watch_time\n",
    "Key Considerations: Novelty, diversity, cold start for new creators\n",
    "```\n",
    "\n",
    "### Notifications\n",
    "```\n",
    "Business Goal: Re-engage users without causing fatigue\n",
    "Product Metric: Opens, DAU lift, unsubscribe rate\n",
    "ML Objective: Score(notif) = P(open) Ã— value - Î» Ã— P(disable)\n",
    "Key Considerations: Timing, frequency capping, notification type priority\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive exercise: Frame a new problem\n",
    "\n",
    "def problem_framing_exercise():\n",
    "    \"\"\"\n",
    "    Given a vague product goal, practice translating it to ML objective.\n",
    "    \"\"\"\n",
    "    problems = [\n",
    "        {\n",
    "            \"product_goal\": \"Reduce harmful content on the platform\",\n",
    "            \"good_framing\": {\n",
    "                \"ml_objective\": \"P(violates_policy | content) as ranking penalty\",\n",
    "                \"labels\": \"Human review decisions, user reports, policy violations\",\n",
    "                \"tradeoffs\": \"False positives hurt creators, false negatives hurt users\",\n",
    "                \"multi_stage\": \"Fast classifier for all content â†’ deep model for borderline\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"product_goal\": \"Help users discover new interests\",\n",
    "            \"good_framing\": {\n",
    "                \"ml_objective\": \"P(engage | user, topic) for topics user hasn't seen\",\n",
    "                \"labels\": \"Engagement on content outside user's usual topics\",\n",
    "                \"tradeoffs\": \"Exploration hurts short-term engagement, helps long-term\",\n",
    "                \"multi_stage\": \"Topic model â†’ user interest prediction â†’ candidate ranking\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"product_goal\": \"Improve Marketplace trust and safety\",\n",
    "            \"good_framing\": {\n",
    "                \"ml_objective\": \"P(scam | listing) + P(successful_transaction | listing)\",\n",
    "                \"labels\": \"Reported scams, completed transactions, returns/disputes\",\n",
    "                \"tradeoffs\": \"Blocking scams vs. blocking legitimate sellers\",\n",
    "                \"multi_stage\": \"Listing classifier â†’ seller reputation â†’ buyer-seller match\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"PROBLEM FRAMING EXERCISE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, problem in enumerate(problems, 1):\n",
    "        print(f\"\\n{'â”€' * 70}\")\n",
    "        print(f\"Problem {i}: {problem['product_goal']}\")\n",
    "        print(f\"{'â”€' * 70}\")\n",
    "        print(\"\\nðŸ“‹ Good Framing:\")\n",
    "        for key, value in problem['good_framing'].items():\n",
    "            print(f\"   â€¢ {key}: {value}\")\n",
    "\n",
    "problem_framing_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Interview Drills\n",
    "\n",
    "### Drill 1: \"How would you frame the objective for [X product]?\"\n",
    "\n",
    "**Framework for answering:**\n",
    "1. State the business objective clearly\n",
    "2. Identify measurable proxy metrics\n",
    "3. Define the ML task (what are you predicting?)\n",
    "4. List positive and negative signals\n",
    "5. Describe the value function\n",
    "6. Acknowledge tradeoffs and failure modes\n",
    "\n",
    "**Example answer for \"Instagram Explore page\":**\n",
    "\n",
    "> \"The business objective is helping users discover content they'll love, which drives engagement and retention. The ML task is ranking candidate posts by expected value. Value is a weighted combination of P(save), P(like), P(follow_author), P(long_view) minus P(hide) and P(report). The weights prioritize saves and follows because they indicate genuine interest, not just casual consumption. Failure modes include filter bubblesâ€”if we only show similar content, users get bored. We'd need exploration and diversity constraints in re-ranking.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 2: \"What's wrong with just predicting clicks?\"\n",
    "\n",
    "**Strong answer:**\n",
    "> \"Clicks are easy to game with clickbaitâ€”sensational headlines, misleading thumbnails. Clicks don't distinguish between satisfied users and frustrated users who clicked but immediately left. We should also predict dwell time, positive actions (like, comment, share), and negative signals (hide, report). The value function should penalize content that gets clicks but causes regret.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 3: \"How would you handle position bias?\"\n",
    "\n",
    "**Strong answer:**\n",
    "> \"Position bias means items in position 1 get more clicks regardless of relevance. Three solutions: (1) Include position as a feature during training, then set position=1 at inference to get unbiased scores. (2) Use inverse propensity weightingâ€”weight training examples by 1/P(shown at this position). (3) Randomize a small percentage of traffic to collect unbiased labels. Each has tradeoffs: randomization hurts short-term metrics, IPW has high variance for rare positions, and the feature approach assumes position bias is constant across users.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Drill 4: \"How do you know your proxy metric is still valid?\"\n",
    "\n",
    "**Strong answer:**\n",
    "> \"Proxy metrics degrade over time as the system optimizes for them and creators learn to game them. We validate by: (1) Periodic user surveys asking about satisfaction, (2) Checking correlation with long-term outcomes like retention, (3) Human review of top-ranked content, (4) Monitoring for divergenceâ€”if clicks go up but time spent or returns go down, the proxy is breaking. When proxy-truth correlation drops, we add new signals or regularize optimization.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Problem Framing Checklist\n",
    "\n",
    "Before building any ML system, verify:\n",
    "\n",
    "- [ ] **Business objective is clear:** What does success look like?\n",
    "- [ ] **Product metrics identified:** How will we measure success?\n",
    "- [ ] **ML task defined:** What exactly are we predicting?\n",
    "- [ ] **Labels available:** Where do labels come from? Any bias?\n",
    "- [ ] **Positive signals listed:** What user actions indicate value?\n",
    "- [ ] **Negative signals listed:** What actions indicate harm?\n",
    "- [ ] **Value function designed:** How do we combine predictions?\n",
    "- [ ] **Failure modes identified:** What could go wrong?\n",
    "- [ ] **Proxy validity checked:** Will this proxy still work in 6 months?\n",
    "- [ ] **Position/selection bias addressed:** How do we debias labels?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

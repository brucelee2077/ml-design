{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Framing the Problem as an ML Task\n",
    "\n",
    "---\n",
    "\n",
    "## What the Chapter Says\n",
    "\n",
    "The second framework step is **\"Framing the Problem as an ML Task\"** with these exact sub-steps:\n",
    "\n",
    "1. **Define ML objective** (translate business objective → ML objective)\n",
    "2. **Specify system inputs/outputs**\n",
    "3. **Choose the right ML category**\n",
    "\n",
    "The chapter provides a key table mapping business objectives to ML objectives, and a decision tree for choosing ML categories.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Interview Signal\n",
    "\n",
    "| Level | Expectations |\n",
    "|-------|-------------|\n",
    "| **E5** | Correctly translates business objective to ML objective. Clearly defines inputs/outputs. Chooses appropriate ML category with justification. |\n",
    "| **E6** | Discusses tradeoffs between different ML objectives. Proposes multi-model architectures when appropriate. Considers proxy metrics and their limitations. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D1) Business Objective → ML Objective (Chapter Table)\n",
    "\n",
    "This table is **directly from the chapter** and must be memorized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "# Chapter's exact table: Business Objective → ML Objective\n",
    "objective_mapping = pd.DataFrame({\n",
    "    'Application': [\n",
    "        'Event ticket selling app',\n",
    "        'Video streaming app',\n",
    "        'Ad click prediction',\n",
    "        'Harmful content detection',\n",
    "        'Friend recommendation'\n",
    "    ],\n",
    "    'Business Objective': [\n",
    "        'Increase ticket sales',\n",
    "        'Increase engagement',\n",
    "        'Increase clicks',\n",
    "        'Improve safety',\n",
    "        'Increase network growth'\n",
    "    ],\n",
    "    'ML Objective': [\n",
    "        'Maximize event registrations',\n",
    "        'Maximize watch time',\n",
    "        'Maximize CTR (Click-Through Rate)',\n",
    "        'Predict if content is harmful',\n",
    "        'Maximize formed connections'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CHAPTER TABLE: Business Objective → ML Objective\")\n",
    "print(\"=\"*80)\n",
    "print(objective_mapping.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mapping\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis('off')\n",
    "ax.set_title('Business Objective → ML Objective Translation', fontsize=14, fontweight='bold')\n",
    "\n",
    "apps = objective_mapping['Application'].tolist()\n",
    "business = objective_mapping['Business Objective'].tolist()\n",
    "ml_obj = objective_mapping['ML Objective'].tolist()\n",
    "\n",
    "y_positions = [4.5, 3.5, 2.5, 1.5, 0.5]\n",
    "colors = ['#BBDEFB', '#C8E6C9', '#FFF9C4', '#FFCCBC', '#E1BEE7']\n",
    "\n",
    "for i, (app, biz, ml, y, color) in enumerate(zip(apps, business, ml_obj, y_positions, colors)):\n",
    "    # App box\n",
    "    rect1 = mpatches.FancyBboxPatch((0.5, y), 3, 0.8, boxstyle='round,pad=0.05',\n",
    "                                     facecolor=color, edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect1)\n",
    "    ax.text(2, y+0.4, app, ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Business objective box\n",
    "    rect2 = mpatches.FancyBboxPatch((4.5, y), 3, 0.8, boxstyle='round,pad=0.05',\n",
    "                                     facecolor='#E0E0E0', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect2)\n",
    "    ax.text(6, y+0.4, biz, ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    # Arrow\n",
    "    ax.annotate('', xy=(8.5, y+0.4), xytext=(7.5, y+0.4),\n",
    "               arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "    \n",
    "    # ML objective box\n",
    "    rect3 = mpatches.FancyBboxPatch((9, y), 4, 0.8, boxstyle='round,pad=0.05',\n",
    "                                     facecolor='#C8E6C9', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect3)\n",
    "    ax.text(11, y+0.4, ml, ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Headers\n",
    "ax.text(2, 5.3, 'Application', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "ax.text(6, 5.3, 'Business Objective', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "ax.text(11, 5.3, 'ML Objective', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, 14)\n",
    "ax.set_ylim(0, 6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D2) Specify Inputs/Outputs (Chapter Examples)\n",
    "\n",
    "The chapter provides specific input/output specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter's input/output examples\n",
    "io_examples = pd.DataFrame({\n",
    "    'System': [\n",
    "        'Harmful content detection',\n",
    "        'Event recommendation (Scenario 1)',\n",
    "        'Event recommendation (Scenario 2)'\n",
    "    ],\n",
    "    'Input': [\n",
    "        'Post (text, image, video)',\n",
    "        'User',\n",
    "        '(User, Event)'\n",
    "    ],\n",
    "    'Output': [\n",
    "        'Probability of harmfulness',\n",
    "        'Probability vector over many events',\n",
    "        'Single probability of engagement'\n",
    "    ],\n",
    "    'Notes': [\n",
    "        'May use separate models: violence, nudity, hate speech → final decision',\n",
    "        'One forward pass → ranks all events for user',\n",
    "        'Must score each (user, event) pair individually'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CHAPTER: Input/Output Specifications\")\n",
    "print(\"=\"*80)\n",
    "print(io_examples.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagram: Two input-output scenarios (from chapter)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scenario 1: User → Probability vector\n",
    "ax1 = axes[0]\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Scenario 1: User → Probability Vector', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Input box\n",
    "rect1 = mpatches.FancyBboxPatch((0.5, 2), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#BBDEFB', edgecolor='black', linewidth=2)\n",
    "ax1.add_patch(rect1)\n",
    "ax1.text(1.5, 2.75, 'User', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Arrow\n",
    "ax1.annotate('', xy=(3.5, 2.75), xytext=(2.5, 2.75),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Model box\n",
    "rect2 = mpatches.FancyBboxPatch((3.5, 2), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#FFF9C4', edgecolor='black', linewidth=2)\n",
    "ax1.add_patch(rect2)\n",
    "ax1.text(4.5, 2.75, 'ML Model', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Arrow\n",
    "ax1.annotate('', xy=(6.5, 2.75), xytext=(5.5, 2.75),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Output: Multiple probability boxes\n",
    "for i, (item, prob) in enumerate([('Event A', 0.85), ('Event B', 0.72), ('Event C', 0.45), ('...', '')]):\n",
    "    y = 3.5 - i * 0.8\n",
    "    rect = mpatches.FancyBboxPatch((6.5, y), 2.5, 0.6, boxstyle='round,pad=0.05',\n",
    "                                    facecolor='#C8E6C9', edgecolor='black', linewidth=1)\n",
    "    ax1.add_patch(rect)\n",
    "    if prob:\n",
    "        ax1.text(7.75, y+0.3, f'{item}: P={prob}', ha='center', va='center', fontsize=10)\n",
    "    else:\n",
    "        ax1.text(7.75, y+0.3, item, ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 5)\n",
    "\n",
    "# Scenario 2: (User, Event) → Single probability\n",
    "ax2 = axes[1]\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Scenario 2: (User, Event) → Single Probability', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Input boxes\n",
    "rect1 = mpatches.FancyBboxPatch((0.5, 3), 1.5, 1, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#BBDEFB', edgecolor='black', linewidth=2)\n",
    "ax2.add_patch(rect1)\n",
    "ax2.text(1.25, 3.5, 'User', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "rect2 = mpatches.FancyBboxPatch((0.5, 1.5), 1.5, 1, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#E1BEE7', edgecolor='black', linewidth=2)\n",
    "ax2.add_patch(rect2)\n",
    "ax2.text(1.25, 2, 'Event', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Arrows merging\n",
    "ax2.annotate('', xy=(3, 2.75), xytext=(2, 3.5), arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "ax2.annotate('', xy=(3, 2.75), xytext=(2, 2), arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Model box\n",
    "rect3 = mpatches.FancyBboxPatch((3, 2), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#FFF9C4', edgecolor='black', linewidth=2)\n",
    "ax2.add_patch(rect3)\n",
    "ax2.text(4, 2.75, 'ML Model', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Arrow\n",
    "ax2.annotate('', xy=(6, 2.75), xytext=(5, 2.75),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "# Single output\n",
    "rect4 = mpatches.FancyBboxPatch((6, 2), 2.5, 1.5, boxstyle='round,pad=0.1',\n",
    "                                 facecolor='#C8E6C9', edgecolor='black', linewidth=2)\n",
    "ax2.add_patch(rect4)\n",
    "ax2.text(7.25, 2.75, 'P = 0.73', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-model architecture example (from chapter)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('off')\n",
    "ax.set_title('Multi-Model Architecture: Harmful Content Detection', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Input\n",
    "rect = mpatches.FancyBboxPatch((0.5, 2.5), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#BBDEFB', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(1.5, 3.25, 'Post\\n(text/image/video)', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Individual models\n",
    "models = [\n",
    "    ('Violence\\nDetector', 4.5, '#FFCDD2'),\n",
    "    ('Nudity\\nDetector', 3.25, '#F8BBD9'),\n",
    "    ('Hate Speech\\nDetector', 2, '#E1BEE7'),\n",
    "]\n",
    "\n",
    "for (name, y, color) in models:\n",
    "    ax.annotate('', xy=(3.5, y+0.5), xytext=(2.5, 3.25),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    rect = mpatches.FancyBboxPatch((3.5, y), 2.5, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor=color, edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(4.75, y+0.4, name, ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Aggregator\n",
    "for (_, y, _) in models:\n",
    "    ax.annotate('', xy=(7, 3.25), xytext=(6, y+0.4),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "rect = mpatches.FancyBboxPatch((7, 2.5), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#FFF9C4', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(8, 3.25, 'Final\\nDecision', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Output\n",
    "ax.annotate('', xy=(10, 3.25), xytext=(9, 3.25),\n",
    "           arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "rect = mpatches.FancyBboxPatch((10, 2.5), 2, 1.5, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#C8E6C9', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(11, 3.25, 'P(harmful)\\n= 0.87', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, 13)\n",
    "ax.set_ylim(1, 6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D3) Choosing ML Category (Chapter Decision Tree)\n",
    "\n",
    "The chapter provides this exact categorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter's ML category tree\n",
    "ml_categories = \"\"\"\n",
    "ML CATEGORIES (from Chapter)\n",
    "================================================================================\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           MACHINE LEARNING                                   │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "                                    │\n",
    "          ┌─────────────────────────┼─────────────────────────┐\n",
    "          ▼                         ▼                         ▼\n",
    "┌──────────────────┐    ┌──────────────────┐    ┌──────────────────┐\n",
    "│   SUPERVISED     │    │  UNSUPERVISED    │    │  REINFORCEMENT   │\n",
    "│   LEARNING       │    │  LEARNING        │    │  LEARNING        │\n",
    "└──────────────────┘    └──────────────────┘    └──────────────────┘\n",
    "          │                       │\n",
    "    ┌─────┴─────┐          ┌──────┼──────┐\n",
    "    ▼           ▼          ▼      ▼      ▼\n",
    "┌────────┐ ┌────────┐  ┌─────┐ ┌─────┐ ┌─────────┐\n",
    "│Classif.│ │Regress.│  │Clust│ │Assoc│ │Dim Red. │\n",
    "└────────┘ └────────┘  └─────┘ └─────┘ └─────────┘\n",
    "    │\n",
    "  ┌─┴─┐\n",
    "  ▼   ▼\n",
    "┌───┐┌────────┐\n",
    "│Bin││Multicls│\n",
    "└───┘└────────┘\n",
    "\n",
    "================================================================================\n",
    "KEY CHAPTER NOTE: \"In practice, many real systems use supervised learning \n",
    "                   because labels help\"\n",
    "================================================================================\n",
    "\"\"\"\n",
    "print(ml_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual decision tree\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.axis('off')\n",
    "ax.set_title('ML Category Decision Tree (Chapter)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Main node\n",
    "rect = mpatches.FancyBboxPatch((5.5, 7), 3, 0.8, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#BBDEFB', edgecolor='black', linewidth=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(7, 7.4, 'Machine Learning', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Level 1 nodes\n",
    "level1 = [\n",
    "    ('Supervised\\nLearning', 2, '#C8E6C9'),\n",
    "    ('Unsupervised\\nLearning', 7, '#FFF9C4'),\n",
    "    ('Reinforcement\\nLearning', 12, '#FFCCBC'),\n",
    "]\n",
    "\n",
    "for (name, x, color) in level1:\n",
    "    ax.annotate('', xy=(x, 5.8), xytext=(7, 7),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    rect = mpatches.FancyBboxPatch((x-1, 5), 2, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor=color, edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 5.4, name, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Supervised Learning branches\n",
    "supervised_branches = [('Classification', 1), ('Regression', 3)]\n",
    "for (name, x) in supervised_branches:\n",
    "    ax.annotate('', xy=(x, 3.8), xytext=(2, 5),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    rect = mpatches.FancyBboxPatch((x-0.8, 3), 1.6, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor='#E8F5E9', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 3.4, name, ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Classification branches\n",
    "class_branches = [('Binary', 0.5), ('Multiclass', 1.5)]\n",
    "for (name, x) in class_branches:\n",
    "    ax.annotate('', xy=(x, 1.8), xytext=(1, 3),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    rect = mpatches.FancyBboxPatch((x-0.4, 1), 0.8, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor='#F1F8E9', edgecolor='black', linewidth=1)        \n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 1.4, name, ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Unsupervised Learning branches\n",
    "unsupervised_branches = [('Clustering', 6), ('Association', 7), ('Dim Reduction', 8)]\n",
    "for (name, x) in unsupervised_branches:\n",
    "    ax.annotate('', xy=(x, 3.8), xytext=(7, 5),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    rect = mpatches.FancyBboxPatch((x-0.7, 3), 1.4, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor='#FFFDE7', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 3.4, name, ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Note box\n",
    "note_rect = mpatches.FancyBboxPatch((9, 0.5), 5, 1.5, boxstyle='round,pad=0.1',\n",
    "                                     facecolor='#FFEBEE', edgecolor='red', linewidth=2, linestyle='--')\n",
    "ax.add_patch(note_rect)\n",
    "ax.text(11.5, 1.25, 'Chapter Note:\\n\"In practice, many real systems\\nuse supervised learning\\nbecause labels help\"',\n",
    "        ha='center', va='center', fontsize=9, style='italic')\n",
    "\n",
    "ax.set_xlim(-0.5, 14.5)\n",
    "ax.set_ylim(0, 8.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D4) Talking Points Checklist (Chapter Required)\n",
    "\n",
    "The chapter specifies this exact interview checklist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talking_points = pd.DataFrame({\n",
    "    'Talking Point': [\n",
    "        'What is a good ML objective?',\n",
    "        'Inputs/outputs of system',\n",
    "        'Supervised vs Unsupervised?',\n",
    "        'Regression vs Classification?',\n",
    "        'Binary vs Multiclass?',\n",
    "        'Output range?'\n",
    "    ],\n",
    "    'What to Discuss': [\n",
    "        'Alignment with business metric, measurability, proxy metrics, tradeoffs',\n",
    "        'Define for each model if multi-model system',\n",
    "        'Do we have labels? Are they reliable?',\n",
    "        'Continuous output (regression) vs discrete (classification)',\n",
    "        'Two classes (yes/no) vs many classes (categories)',\n",
    "        'Probability [0,1], score, class label'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'CTR is measurable but may not capture long-term engagement',\n",
    "        'Harmful detection: post → P(harmful); Video rec: user → ranked videos',\n",
    "        'Feed ranking: supervised (have likes). Anomaly detection: unsupervised',\n",
    "        'Predicting watch time: regression. Predicting click: classification',\n",
    "        'Spam detection: binary. Topic classification: multiclass',\n",
    "        'CTR model outputs probability 0.0 to 1.0'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"CHAPTER: Interview Talking Points Checklist\")\n",
    "print(\"=\"*100)\n",
    "for _, row in talking_points.iterrows():\n",
    "    print(f\"\\n{row['Talking Point']}\")\n",
    "    print(f\"  Discuss: {row['What to Discuss']}\")\n",
    "    print(f\"  Example: {row['Example']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hands-On: Framing Practice with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate different ML framing scenarios\n",
    "np.random.seed(42)\n",
    "\n",
    "# Scenario: Video Recommendation - maximize watch time\n",
    "n_samples = 5000\n",
    "\n",
    "# Generate synthetic (user, video) pairs with watch time\n",
    "video_rec_data = pd.DataFrame({\n",
    "    'user_id': np.random.randint(1, 501, n_samples),\n",
    "    'video_id': np.random.randint(1, 1001, n_samples),\n",
    "    'user_age_bucket': np.random.choice(['18-24', '25-34', '35-44', '45+'], n_samples),\n",
    "    'video_length_sec': np.random.choice([30, 60, 180, 600, 1800], n_samples),\n",
    "    'video_category': np.random.choice(['sports', 'music', 'news', 'comedy', 'education'], n_samples),\n",
    "})\n",
    "\n",
    "# Watch time depends on factors (simulated)\n",
    "video_rec_data['watch_time_sec'] = (\n",
    "    video_rec_data['video_length_sec'] * \n",
    "    np.random.beta(2, 3, n_samples)  # Most people don't finish videos\n",
    ").astype(int)\n",
    "\n",
    "# Binary label: did user watch > 50% of video?\n",
    "video_rec_data['engaged'] = (video_rec_data['watch_time_sec'] / video_rec_data['video_length_sec'] > 0.5).astype(int)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCENARIO: Video Recommendation\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBusiness Objective: Increase engagement\")\n",
    "print(f\"ML Objective: Maximize watch time\")\n",
    "print(f\"\\nData sample:\")\n",
    "print(video_rec_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame as REGRESSION: Predict watch time directly\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAMING OPTION 1: Regression (predict watch time)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Encode categorical features\n",
    "le_age = LabelEncoder()\n",
    "le_cat = LabelEncoder()\n",
    "\n",
    "X_reg = video_rec_data.copy()\n",
    "X_reg['age_encoded'] = le_age.fit_transform(X_reg['user_age_bucket'])\n",
    "X_reg['cat_encoded'] = le_cat.fit_transform(X_reg['video_category'])\n",
    "\n",
    "features = ['video_length_sec', 'age_encoded', 'cat_encoded']\n",
    "X = X_reg[features]\n",
    "y_regression = X_reg['watch_time_sec']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train)\n",
    "y_pred_reg = reg_model.predict(X_test)\n",
    "\n",
    "print(f\"Input: (user features, video features)\")\n",
    "print(f\"Output: Predicted watch time (continuous, 0 to video_length)\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_reg)):.2f} seconds\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_reg):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame as CLASSIFICATION: Predict engaged (yes/no)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAMING OPTION 2: Binary Classification (predict engagement)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "y_classification = X_reg['engaged']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_model = LogisticRegression()\n",
    "clf_model.fit(X_train, y_train)\n",
    "y_pred_clf = clf_model.predict(X_test)\n",
    "y_proba_clf = clf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Input: (user features, video features)\")\n",
    "print(f\"Output: P(engaged), probability in [0, 1]\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_pred_clf):.3f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_pred_clf):.3f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_pred_clf):.3f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, y_proba_clf):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare framings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FRAMING COMPARISON (Interview Discussion)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Aspect': ['Output Type', 'Business Alignment', 'Label Availability', 'Model Complexity', 'Ranking Ability'],\n",
    "    'Regression (Watch Time)': [\n",
    "        'Continuous (seconds)',\n",
    "        'Direct - watch time IS the goal',\n",
    "        'Natural labels from logs',\n",
    "        'Simple, interpretable',\n",
    "        'Natural ordering by predicted time'\n",
    "    ],\n",
    "    'Classification (Engaged)': [\n",
    "        'Probability [0,1]',\n",
    "        'Proxy - engagement threshold arbitrary',\n",
    "        'Derived from watch time',\n",
    "        'Simple, interpretable',\n",
    "        'Natural ordering by probability'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n[E5 Answer]: Both work. Regression directly optimizes watch time. Classification is easier to interpret.\")\n",
    "print(\"[E6 Addition]: In production, we might use watch time regression for ranking, but classification for\\n               understanding engagement patterns. Could combine both in a multi-objective setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 2: Harmful Content Detection (Multi-Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate harmful content detection with multiple models\n",
    "np.random.seed(42)\n",
    "n_posts = 3000\n",
    "\n",
    "# Generate synthetic posts with different harmful content types\n",
    "harmful_data = pd.DataFrame({\n",
    "    'post_id': range(n_posts),\n",
    "    'text_length': np.random.randint(10, 500, n_posts),\n",
    "    'has_image': np.random.choice([0, 1], n_posts, p=[0.4, 0.6]),\n",
    "    'has_video': np.random.choice([0, 1], n_posts, p=[0.7, 0.3]),\n",
    "})\n",
    "\n",
    "# Simulate individual model predictions (separate models per chapter)\n",
    "harmful_data['p_violence'] = np.clip(np.random.beta(1, 10, n_posts) + \n",
    "                                      0.3 * harmful_data['has_video'], 0, 1)\n",
    "harmful_data['p_nudity'] = np.clip(np.random.beta(1, 15, n_posts) + \n",
    "                                    0.2 * harmful_data['has_image'], 0, 1)\n",
    "harmful_data['p_hate_speech'] = np.clip(np.random.beta(1, 12, n_posts) + \n",
    "                                         0.1 * (harmful_data['text_length'] > 200), 0, 1)\n",
    "\n",
    "# Final decision: max of individual probabilities (one policy)\n",
    "harmful_data['p_harmful_max'] = harmful_data[['p_violence', 'p_nudity', 'p_hate_speech']].max(axis=1)\n",
    "\n",
    "# Alternative: weighted combination\n",
    "weights = {'p_violence': 0.4, 'p_nudity': 0.3, 'p_hate_speech': 0.3}\n",
    "harmful_data['p_harmful_weighted'] = sum(\n",
    "    harmful_data[col] * w for col, w in weights.items()\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SCENARIO: Harmful Content Detection (Multi-Model)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBusiness Objective: Improve platform safety\")\n",
    "print(f\"ML Objective: Predict if content is harmful\")\n",
    "print(f\"\\nInput: Post (text, image, video)\")\n",
    "print(f\"Output: Probability of harmfulness [0, 1]\")\n",
    "print(f\"\\nMulti-Model Architecture:\")\n",
    "print(f\"  - Violence Detector → P(violence)\")\n",
    "print(f\"  - Nudity Detector → P(nudity)\")\n",
    "print(f\"  - Hate Speech Detector → P(hate_speech)\")\n",
    "print(f\"  - Final Decision → P(harmful)\")\n",
    "print(f\"\\nData sample:\")\n",
    "print(harmful_data[['post_id', 'p_violence', 'p_nudity', 'p_hate_speech', 'p_harmful_max']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize aggregation strategies\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Max strategy\n",
    "ax1 = axes[0]\n",
    "ax1.hist(harmful_data['p_harmful_max'], bins=50, alpha=0.7, color='#FFCCBC', edgecolor='black')\n",
    "ax1.axvline(0.5, color='red', linestyle='--', label='Threshold=0.5')\n",
    "ax1.set_xlabel('P(harmful)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Max Aggregation: P(harmful) = max(P_violence, P_nudity, P_hate)', fontsize=11)\n",
    "ax1.legend()\n",
    "\n",
    "# Weighted strategy\n",
    "ax2 = axes[1]\n",
    "ax2.hist(harmful_data['p_harmful_weighted'], bins=50, alpha=0.7, color='#C8E6C9', edgecolor='black')\n",
    "ax2.axvline(0.5, color='red', linestyle='--', label='Threshold=0.5')\n",
    "ax2.set_xlabel('P(harmful)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Weighted Aggregation: 0.4*violence + 0.3*nudity + 0.3*hate', fontsize=11)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n[E5 Answer]: Max is conservative - flags if ANY detector fires. Weighted gives smoother scores.\")\n",
    "print(\"[E6 Addition]: Max has lower false negatives (safer) but more false positives (more appeals).\")\n",
    "print(\"               Could use learned aggregator (meta-model) trained on human review decisions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tradeoffs (Chapter-Aligned)\n",
    "\n",
    "| Tradeoff | Discussion | Interview Signal |\n",
    "|----------|------------|------------------|\n",
    "| **Direct vs Proxy Objective** | Watch time (direct) vs CTR (proxy for engagement) | E5: Knows difference. E6: Discusses when proxy fails |\n",
    "| **Single vs Multi-Model** | One model for all vs separate specialized models | E5: Can design both. E6: Discusses latency, maintenance tradeoffs |\n",
    "| **Classification vs Regression** | Discrete categories vs continuous output | E5: Knows when to use each. E6: Proposes hybrid approaches |\n",
    "| **Granularity of Output** | Binary vs multiclass vs probability | E5: Matches output to business need. E6: Discusses calibration |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Meta Interview Signal (Detailed)\n",
    "\n",
    "### E5 Answer Expectations\n",
    "\n",
    "- Correctly translates business objective to ML objective (memorize the chapter table)\n",
    "- Clearly defines inputs and outputs for the system\n",
    "- Chooses appropriate ML category with justification\n",
    "- Can walk through the talking points checklist\n",
    "\n",
    "### E6 Additions\n",
    "\n",
    "- **Tradeoffs**: \"We could maximize CTR, but that might lead to clickbait. Watch time is a better proxy for genuine engagement.\"\n",
    "- **Multi-model**: \"For harmful content, separate models let us tune precision/recall independently for each harm type.\"\n",
    "- **Proxy metrics**: \"CTR is easy to measure but doesn't capture long-term user satisfaction. We might track 7-day retention as a guardrail.\"\n",
    "- **Output calibration**: \"The probability needs to be well-calibrated if we're using it for ranking or thresholding decisions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Drills\n",
    "\n",
    "### Drill 1: Table Recall\n",
    "Reproduce the Business Objective → ML Objective table from memory for all 5 applications.\n",
    "\n",
    "### Drill 2: Input/Output Specification\n",
    "For each system below, define the input and output:\n",
    "- Search ranking\n",
    "- Email spam detection\n",
    "- Product recommendation\n",
    "- Fraud detection\n",
    "\n",
    "### Drill 3: ML Category Selection\n",
    "For each task, choose the ML category and justify:\n",
    "- Predicting house prices\n",
    "- Grouping customers into segments\n",
    "- Playing chess\n",
    "- Detecting fraudulent transactions\n",
    "\n",
    "### Drill 4: Multi-Model Design\n",
    "Design a multi-model architecture for \"Content Moderation\" that handles:\n",
    "- Violence\n",
    "- Nudity\n",
    "- Hate speech\n",
    "- Spam\n",
    "- Misinformation\n",
    "\n",
    "How would you combine the outputs?\n",
    "\n",
    "### Drill 5: Talking Points Practice\n",
    "For the \"Friend Recommendation\" system, walk through all 6 talking points from the checklist."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

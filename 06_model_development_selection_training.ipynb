{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Model Development: Selection and Training\n",
    "\n",
    "---\n",
    "\n",
    "## What the Chapter Says\n",
    "\n",
    "The chapter covers **Model Development** with these components:\n",
    "\n",
    "### F1) Model Selection Process\n",
    "1. **Baseline** (e.g., most popular videos)\n",
    "2. **Simple models** (e.g., logistic regression)\n",
    "3. **Complex models** (e.g., deep neural networks)\n",
    "4. **Ensemble** options: bagging, boosting, stacking\n",
    "\n",
    "### F2) Model Training Topics\n",
    "- Dataset construction (5 steps)\n",
    "- Labels: hand labeling vs natural labeling\n",
    "- Class imbalance handling\n",
    "- Loss function selection\n",
    "- Training from scratch vs fine-tuning\n",
    "- Distributed training: data parallelism vs model parallelism\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Interview Signal\n",
    "\n",
    "| Level | Expectations |\n",
    "|-------|-------------|\n",
    "| **E5** | Knows model selection progression. Can implement baseline → simple → complex. Understands class imbalance mitigation. |\n",
    "| **E6** | Proposes ensemble strategies. Discusses distributed training at scale. Designs label collection pipelines. Considers feedback loops and iteration velocity. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F1) Model Selection Process (Chapter Content)\n",
    "\n",
    "The chapter specifies this exact progression:\n",
    "\n",
    "```\n",
    "Baseline → Simple Models → Complex Models → Ensemble\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model selection progression\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.axis('off')\n",
    "ax.set_title('Model Selection Progression (Chapter)', fontsize=14, fontweight='bold')\n",
    "\n",
    "stages = [\n",
    "    ('BASELINE', 1, '#BBDEFB', 'Most popular videos\\nRandom prediction\\nHeuristic rules'),\n",
    "    ('SIMPLE', 4.5, '#C8E6C9', 'Logistic Regression\\nLinear Regression\\nNaive Bayes'),\n",
    "    ('COMPLEX', 8, '#FFF9C4', 'Decision Trees\\nGBDT / Random Forest\\nNeural Networks'),\n",
    "    ('ENSEMBLE', 11.5, '#FFCCBC', 'Bagging\\nBoosting\\nStacking'),\n",
    "]\n",
    "\n",
    "for (label, x, color, examples) in stages:\n",
    "    rect = mpatches.FancyBboxPatch((x, 1), 2.5, 3, boxstyle='round,pad=0.1',\n",
    "                                    facecolor=color, edgecolor='black', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + 1.25, 3.5, label, ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    ax.text(x + 1.25, 2, examples, ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Arrows\n",
    "for x in [3.5, 7, 10.5]:\n",
    "    ax.annotate('', xy=(x + 1, 2.5), xytext=(x, 2.5),\n",
    "               arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "ax.set_xlim(0, 15)\n",
    "ax.set_ylim(0, 5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter's model options list\n",
    "model_options = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Logistic Regression',\n",
    "        'Linear Regression',\n",
    "        'Decision Trees',\n",
    "        'GBDT / Random Forests',\n",
    "        'SVM',\n",
    "        'Naive Bayes',\n",
    "        'Factorization Machines',\n",
    "        'Neural Networks'\n",
    "    ],\n",
    "    'Type': [\n",
    "        'Simple (Classification)',\n",
    "        'Simple (Regression)',\n",
    "        'Simple/Medium',\n",
    "        'Complex (Ensemble)',\n",
    "        'Simple/Medium',\n",
    "        'Simple',\n",
    "        'Complex',\n",
    "        'Complex'\n",
    "    ],\n",
    "    'Use Case': [\n",
    "        'Binary/multiclass classification, baseline for CTR',\n",
    "        'Continuous output, watch time prediction',\n",
    "        'Interpretable, handles non-linear',\n",
    "        'Tabular data, feature interactions',\n",
    "        'Small data, high-dimensional',\n",
    "        'Text classification, fast training',\n",
    "        'Recommendations, sparse features',\n",
    "        'Complex patterns, multimodal data'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL OPTIONS LIST (Chapter Content)\")\n",
    "print(\"=\"*80)\n",
    "print(model_options.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection considerations (from chapter)\n",
    "considerations = pd.DataFrame({\n",
    "    'Consideration': [\n",
    "        'Data needs',\n",
    "        'Training speed',\n",
    "        'Hyperparameters / Tuning',\n",
    "        'Continual learning',\n",
    "        'Compute requirements',\n",
    "        'Interpretability'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'How much data does the model need to perform well?',\n",
    "        'How fast can we iterate? Training time matters.',\n",
    "        'How many hyperparameters? How hard to tune?',\n",
    "        'Can the model be updated incrementally?',\n",
    "        'CPU vs GPU? Memory requirements?',\n",
    "        'Can we explain predictions to users/regulators?'\n",
    "    ],\n",
    "    'Simple Models': [\n",
    "        'Low - works with small datasets',\n",
    "        'Fast - minutes to hours',\n",
    "        'Few - easy to tune',\n",
    "        'Often yes (online learning)',\n",
    "        'Low - CPU sufficient',\n",
    "        'High - coefficients are meaningful'\n",
    "    ],\n",
    "    'Complex Models': [\n",
    "        'High - needs large datasets',\n",
    "        'Slow - hours to days',\n",
    "        'Many - requires extensive tuning',\n",
    "        'Sometimes (fine-tuning)',\n",
    "        'High - GPU required',\n",
    "        'Low - black box'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"MODEL SELECTION CONSIDERATIONS (Chapter Content)\")\n",
    "print(\"=\"*100)\n",
    "print(considerations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hands-On: Model Selection Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic CTR dataset\n",
    "np.random.seed(42)\n",
    "n = 10000\n",
    "\n",
    "# Features\n",
    "data = pd.DataFrame({\n",
    "    'user_engagement_score': np.random.beta(2, 5, n),\n",
    "    'item_popularity': np.random.beta(2, 3, n),\n",
    "    'time_on_platform_days': np.random.exponential(30, n),\n",
    "    'num_past_clicks': np.random.poisson(5, n),\n",
    "    'is_weekend': np.random.choice([0, 1], n, p=[0.71, 0.29]),\n",
    "    'device_mobile': np.random.choice([0, 1], n, p=[0.35, 0.65]),\n",
    "})\n",
    "\n",
    "# Target: CTR (click = 1, no click = 0)\n",
    "# True relationship with some noise\n",
    "prob = 1 / (1 + np.exp(-(\n",
    "    -2 + \n",
    "    3 * data['user_engagement_score'] + \n",
    "    2 * data['item_popularity'] + \n",
    "    0.01 * data['num_past_clicks'] +\n",
    "    0.5 * data['device_mobile'] +\n",
    "    np.random.normal(0, 0.5, n)\n",
    ")))\n",
    "data['clicked'] = (np.random.random(n) < prob).astype(int)\n",
    "\n",
    "# Create class imbalance (realistic CTR ~3%)\n",
    "imbalance_mask = np.random.random(n) < 0.15\n",
    "data.loc[~imbalance_mask & (data['clicked'] == 1), 'clicked'] = 0\n",
    "\n",
    "print(\"SYNTHETIC CTR DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Click rate: {data['clicked'].mean()*100:.2f}%\")\n",
    "print(f\"\\nFeatures: {list(data.columns[:-1])}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = data.drop('clicked', axis=1)\n",
    "y = data['clicked']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nClick distribution - Train: {y_train.mean()*100:.2f}%, Test: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: BASELINE (from chapter)\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Baseline 1: Always predict majority class (no click)\n",
    "baseline_always_zero = np.zeros(len(y_test))\n",
    "\n",
    "# Baseline 2: Random prediction based on class distribution\n",
    "click_rate = y_train.mean()\n",
    "baseline_random = (np.random.random(len(y_test)) < click_rate).astype(int)\n",
    "\n",
    "# Baseline 3: Most popular items heuristic (item_popularity > threshold)\n",
    "threshold = X_train['item_popularity'].quantile(0.7)\n",
    "baseline_popular = (X_test['item_popularity'] > threshold).astype(int)\n",
    "\n",
    "print(\"\\nBaseline 1: Always predict 'no click'\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, baseline_always_zero):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, baseline_always_zero, zero_division=0):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, baseline_always_zero, zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nBaseline 2: Random (based on training click rate)\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, baseline_random):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, baseline_random):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, baseline_random):.4f}\")\n",
    "\n",
    "print(\"\\nBaseline 3: Popularity heuristic (high popularity → click)\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, baseline_popular):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, baseline_popular):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, baseline_popular):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: SIMPLE MODELS (from chapter)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: SIMPLE MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, lr_proba):.4f}\")\n",
    "\n",
    "# Decision Tree (simple version)\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_proba = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nDecision Tree (max_depth=5):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, dt_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, dt_pred):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, dt_pred):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, dt_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: COMPLEX MODELS (from chapter)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: COMPLEX MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nRandom Forest (100 trees):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, rf_proba):.4f}\")\n",
    "\n",
    "# Gradient Boosting\n",
    "gbdt = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "gbdt.fit(X_train, y_train)\n",
    "gbdt_pred = gbdt.predict(X_test)\n",
    "gbdt_proba = gbdt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nGradient Boosting (GBDT):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, gbdt_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, gbdt_pred):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, gbdt_pred):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, gbdt_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: ENSEMBLE (from chapter - bagging, boosting, stacking)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: ENSEMBLE METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "Ensemble Types (from chapter):\n",
    "\n",
    "1. BAGGING (Bootstrap Aggregating)\n",
    "   - Train multiple models on random subsets of data\n",
    "   - Combine by voting (classification) or averaging (regression)\n",
    "   - Example: Random Forest\n",
    "\n",
    "2. BOOSTING\n",
    "   - Train models sequentially, focusing on errors of previous models\n",
    "   - Each model learns from mistakes of predecessors\n",
    "   - Example: GBDT, XGBoost, LightGBM\n",
    "\n",
    "3. STACKING\n",
    "   - Train multiple diverse models\n",
    "   - Use a meta-model to combine their predictions\n",
    "   - Leverages strengths of different model types\n",
    "\"\"\")\n",
    "\n",
    "# Simple stacking example\n",
    "print(\"\\nSimple Stacking Example:\")\n",
    "\n",
    "# Level 1: Base models\n",
    "stacking_features = np.column_stack([\n",
    "    lr_proba,\n",
    "    dt_proba,\n",
    "    rf_proba,\n",
    "    gbdt_proba\n",
    "])\n",
    "\n",
    "# Simple averaging (a form of stacking)\n",
    "avg_proba = stacking_features.mean(axis=1)\n",
    "avg_pred = (avg_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"Average Ensemble (LR + DT + RF + GBDT):\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, avg_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, avg_pred):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, avg_pred):.4f}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_score(y_test, avg_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Baseline (popular)', 'Logistic Regression', 'Decision Tree', \n",
    "              'Random Forest', 'GBDT', 'Ensemble (avg)'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, baseline_popular),\n",
    "        accuracy_score(y_test, lr_pred),\n",
    "        accuracy_score(y_test, dt_pred),\n",
    "        accuracy_score(y_test, rf_pred),\n",
    "        accuracy_score(y_test, gbdt_pred),\n",
    "        accuracy_score(y_test, avg_pred)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, baseline_popular),\n",
    "        precision_score(y_test, lr_pred),\n",
    "        precision_score(y_test, dt_pred),\n",
    "        precision_score(y_test, rf_pred),\n",
    "        precision_score(y_test, gbdt_pred),\n",
    "        precision_score(y_test, avg_pred)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, baseline_popular),\n",
    "        recall_score(y_test, lr_pred),\n",
    "        recall_score(y_test, dt_pred),\n",
    "        recall_score(y_test, rf_pred),\n",
    "        recall_score(y_test, gbdt_pred),\n",
    "        recall_score(y_test, avg_pred)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_test, baseline_popular),\n",
    "        roc_auc_score(y_test, lr_proba),\n",
    "        roc_auc_score(y_test, dt_proba),\n",
    "        roc_auc_score(y_test, rf_proba),\n",
    "        roc_auc_score(y_test, gbdt_proba),\n",
    "        roc_auc_score(y_test, avg_proba)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F2) Dataset Construction (Chapter - 5 Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter's 5 dataset construction steps\n",
    "dataset_steps = pd.DataFrame({\n",
    "    'Step': ['1', '2', '3', '4', '5'],\n",
    "    'Action': [\n",
    "        'Collect raw data',\n",
    "        'Identify features & labels',\n",
    "        'Select sampling strategy',\n",
    "        'Split data',\n",
    "        'Address class imbalance'\n",
    "    ],\n",
    "    'Details': [\n",
    "        'Gather from logs, databases, APIs, external sources',\n",
    "        'What predicts the target? What is the target?',\n",
    "        'Random, stratified, time-based, importance sampling',\n",
    "        'Train/validation/test split, avoid leakage',\n",
    "        'Resampling, loss weighting, etc.'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATASET CONSTRUCTION STEPS (Chapter)\")\n",
    "print(\"=\"*70)\n",
    "print(dataset_steps.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Labels: Hand Labeling vs Natural Labeling (Chapter Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter's labeling types\n",
    "labeling_types = pd.DataFrame({\n",
    "    'Type': ['Hand Labeling', 'Natural Labeling'],\n",
    "    'Description': [\n",
    "        'Human annotators manually label data',\n",
    "        'Labels derived from user behavior/system events'\n",
    "    ],\n",
    "    'Example': [\n",
    "        'Annotators label images as \"cat\" or \"dog\"',\n",
    "        'User liked post → label=1, else label=0 (feed relevance)'\n",
    "    ],\n",
    "    'Pros': [\n",
    "        'High quality, flexible definition',\n",
    "        'Cheap, scalable, real-time'\n",
    "    ],\n",
    "    'Cons': [\n",
    "        'Expensive, slow, limited scale',\n",
    "        'Noisy, may not capture true intent'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LABELING TYPES (Chapter Content)\")\n",
    "print(\"=\"*80)\n",
    "print(labeling_types.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"CHAPTER EXAMPLE: Natural Label for Feed Relevance\")\n",
    "print(\"-\"*60)\n",
    "print(\"\"\"\n",
    "Input: (user, post)\n",
    "Label: 1 if user liked the post, else 0\n",
    "\n",
    "This is a 'natural' label because:\n",
    "- No human annotation required\n",
    "- Derived directly from user behavior\n",
    "- Scales to billions of examples\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Class Imbalance (Chapter Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class imbalance mitigation strategies from chapter\n",
    "print(\"=\"*70)\n",
    "print(\"CLASS IMBALANCE MITIGATION (Chapter Content)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Problem: Majority class (no click) >> Minority class (click)\n",
    "\n",
    "Chapter Mitigation Strategies:\n",
    "\n",
    "1. RESAMPLING:\n",
    "   - Oversample minority: Duplicate minority class samples\n",
    "   - Undersample majority: Remove majority class samples\n",
    "\n",
    "2. ALTER LOSS FUNCTION:\n",
    "   - Weight minority more: Give higher loss weight to minority class\n",
    "   - Focal loss: Focus on hard examples\n",
    "   - Class-balanced loss: Inverse frequency weighting\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate class imbalance handling\n",
    "print(\"Original class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Imbalance ratio: {(y_train==0).sum() / (y_train==1).sum():.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Resampling - Oversample minority\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"METHOD 1: Oversample Minority\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate classes\n",
    "X_majority = X_train[y_train == 0]\n",
    "X_minority = X_train[y_train == 1]\n",
    "y_majority = y_train[y_train == 0]\n",
    "y_minority = y_train[y_train == 1]\n",
    "\n",
    "# Oversample minority\n",
    "X_minority_upsampled, y_minority_upsampled = resample(\n",
    "    X_minority, y_minority,\n",
    "    replace=True,\n",
    "    n_samples=len(X_majority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_balanced = pd.concat([X_majority, X_minority_upsampled])\n",
    "y_balanced = pd.concat([y_majority, y_minority_upsampled])\n",
    "\n",
    "print(f\"After oversampling:\")\n",
    "print(y_balanced.value_counts())\n",
    "\n",
    "# Train and evaluate\n",
    "lr_balanced = LogisticRegression(max_iter=1000)\n",
    "lr_balanced.fit(X_balanced, y_balanced)\n",
    "lr_balanced_pred = lr_balanced.predict(X_test)\n",
    "lr_balanced_proba = lr_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\nLogistic Regression with Oversampling:\")\n",
    "print(f\"  Recall: {recall_score(y_test, lr_balanced_pred):.4f} (was {recall_score(y_test, lr_pred):.4f})\")\n",
    "print(f\"  Precision: {precision_score(y_test, lr_balanced_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Class Weights\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"METHOD 2: Class Weights (Alter Loss)\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# Using class_weight='balanced' automatically weights by inverse frequency\n",
    "lr_weighted = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr_weighted.fit(X_train, y_train)\n",
    "lr_weighted_pred = lr_weighted.predict(X_test)\n",
    "lr_weighted_proba = lr_weighted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Logistic Regression with Class Weights:\")\n",
    "print(f\"  Recall: {recall_score(y_test, lr_weighted_pred):.4f} (was {recall_score(y_test, lr_pred):.4f})\")\n",
    "print(f\"  Precision: {precision_score(y_test, lr_weighted_pred):.4f}\")\n",
    "print(f\"  F1: {f1_score(y_test, lr_weighted_pred):.4f}\")\n",
    "\n",
    "print(\"\\n[Chapter Mentions]: focal loss and class-balanced loss for deep learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training: Scratch vs Fine-tuning, Distributed Training (Chapter Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING APPROACHES (Chapter Content - High Level)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "TRAINING FROM SCRATCH vs FINE-TUNING:\n",
    "--------------------------------------\n",
    "• Training from scratch: Initialize weights randomly, train on your data\n",
    "  - Use when: Lots of domain-specific data, unique task\n",
    "  \n",
    "• Fine-tuning: Start from pre-trained weights, adapt to your task\n",
    "  - Use when: Limited data, task similar to pre-training objective\n",
    "  - Examples: BERT for text, ResNet for images\n",
    "\n",
    "\n",
    "DISTRIBUTED TRAINING:\n",
    "---------------------\n",
    "Two main approaches:\n",
    "\n",
    "1. DATA PARALLELISM:\n",
    "   - Same model copied to multiple workers\n",
    "   - Each worker trains on different data shard\n",
    "   - Gradients are aggregated\n",
    "   - Use when: Model fits in single GPU memory\n",
    "\n",
    "2. MODEL PARALLELISM:\n",
    "   - Model split across multiple workers\n",
    "   - Each worker holds part of the model\n",
    "   - Use when: Model too large for single GPU (e.g., GPT-3)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual: Data Parallelism vs Model Parallelism\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Data Parallelism\n",
    "ax1 = axes[0]\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Data Parallelism', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Data shards\n",
    "for i in range(3):\n",
    "    rect = mpatches.FancyBboxPatch((0.5, 3-i*1), 1.5, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor='#BBDEFB', edgecolor='black', linewidth=1)\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.text(1.25, 3.4-i*1, f'Data Shard {i+1}', ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Model copies\n",
    "for i in range(3):\n",
    "    ax1.annotate('', xy=(3, 3.4-i*1), xytext=(2, 3.4-i*1),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1))\n",
    "    rect = mpatches.FancyBboxPatch((3, 3-i*1), 1.5, 0.8, boxstyle='round,pad=0.1',\n",
    "                                    facecolor='#C8E6C9', edgecolor='black', linewidth=1)\n",
    "    ax1.add_patch(rect)\n",
    "    ax1.text(3.75, 3.4-i*1, f'Model Copy', ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Gradient aggregation\n",
    "for i in range(3):\n",
    "    ax1.annotate('', xy=(5.75, 2.4), xytext=(4.5, 3.4-i*1),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1))\n",
    "\n",
    "rect = mpatches.FancyBboxPatch((5.5, 2), 2, 0.8, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#FFCCBC', edgecolor='black', linewidth=2)\n",
    "ax1.add_patch(rect)\n",
    "ax1.text(6.5, 2.4, 'Aggregate\\nGradients', ha='center', va='center', fontsize=9)\n",
    "\n",
    "ax1.set_xlim(0, 8)\n",
    "ax1.set_ylim(0, 5)\n",
    "\n",
    "# Model Parallelism\n",
    "ax2 = axes[1]\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Model Parallelism', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Input\n",
    "rect = mpatches.FancyBboxPatch((0.5, 2), 1.5, 1, boxstyle='round,pad=0.1',\n",
    "                                facecolor='#BBDEFB', edgecolor='black', linewidth=1)\n",
    "ax2.add_patch(rect)\n",
    "ax2.text(1.25, 2.5, 'Input', ha='center', va='center', fontsize=10)\n",
    "\n",
    "# Model parts on different GPUs\n",
    "parts = [('GPU 1\\nLayers 1-10', 2.5, '#C8E6C9'), \n",
    "         ('GPU 2\\nLayers 11-20', 4.5, '#FFF9C4'),\n",
    "         ('GPU 3\\nLayers 21-30', 6.5, '#E1BEE7')]\n",
    "\n",
    "for i, (label, x, color) in enumerate(parts):\n",
    "    if i > 0:\n",
    "        ax2.annotate('', xy=(x, 2.5), xytext=(x-1.5, 2.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "    else:\n",
    "        ax2.annotate('', xy=(x, 2.5), xytext=(2, 2.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "    rect = mpatches.FancyBboxPatch((x, 2), 1.3, 1, boxstyle='round,pad=0.1',\n",
    "                                    facecolor=color, edgecolor='black', linewidth=1)\n",
    "    ax2.add_patch(rect)\n",
    "    ax2.text(x+0.65, 2.5, label, ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax2.set_xlim(0, 8.5)\n",
    "ax2.set_ylim(0, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F3) Model Dev Talking Points Checklist (Chapter Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dev_checklist = pd.DataFrame({\n",
    "    'Topic': [\n",
    "        'Model suitability tradeoffs',\n",
    "        'Labels quality & feedback loops',\n",
    "        'Imbalance handling',\n",
    "        'Overfitting/underfitting',\n",
    "        'Continual learning cadence'\n",
    "    ],\n",
    "    'Questions to Address': [\n",
    "        'Training time? Data needs? Compute? Latency? On-device? Interpretability?',\n",
    "        'How are labels obtained? Time-to-label for natural labels?',\n",
    "        'Class ratio? Resampling or loss weighting?',\n",
    "        'Bias/variance tradeoff? Regularization?',\n",
    "        'Retrain daily/weekly/monthly? Online learning?'\n",
    "    ],\n",
    "    'E5 Answer': [\n",
    "        'GBDT is fast to train, interpretable, works well on tabular data',\n",
    "        'Natural labels from clicks, 1-day delay for label collection',\n",
    "        '10:1 imbalance, using class_weight to handle',\n",
    "        'Added L2 regularization to prevent overfitting',\n",
    "        'Retrain weekly with fresh data'\n",
    "    ],\n",
    "    'E6 Addition': [\n",
    "        'Latency budget is 10ms, so we cache embeddings and use lightweight model',\n",
    "        'Feedback loop: today\\'s predictions affect tomorrow\\'s labels, need to monitor',\n",
    "        'Focal loss focuses on hard negatives, better than oversampling at scale',\n",
    "        'Early stopping on validation set, monitor calibration',\n",
    "        'Continuous learning with streaming data, A/B test before full rollout'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL DEVELOPMENT TALKING POINTS CHECKLIST (Chapter)\")\n",
    "print(\"=\"*100)\n",
    "for _, row in model_dev_checklist.iterrows():\n",
    "    print(f\"\\n{row['Topic']}\")\n",
    "    print(f\"  Q: {row['Questions to Address']}\")\n",
    "    print(f\"  E5: {row['E5 Answer']}\")\n",
    "    print(f\"  E6: {row['E6 Addition']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tradeoffs (Chapter-Aligned)\n",
    "\n",
    "| Tradeoff | Discussion | Interview Signal |\n",
    "|----------|------------|------------------|\n",
    "| **Simple vs Complex** | Interpretability vs performance | E5: Knows progression. E6: Justifies model choice for use case |\n",
    "| **Hand vs Natural Labels** | Quality vs scale | E5: Understands both. E6: Discusses label noise handling |\n",
    "| **Oversample vs Weight Loss** | Data augmentation vs loss function | E5: Can implement. E6: Discusses pros/cons at scale |\n",
    "| **Data vs Model Parallelism** | Scale compute vs scale model | E5: Knows difference. E6: Proposes for specific model size |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Meta Interview Signal (Detailed)\n",
    "\n",
    "### E5 Answer Expectations\n",
    "\n",
    "- Follows baseline → simple → complex progression\n",
    "- Implements class imbalance mitigation\n",
    "- Understands hand vs natural labeling\n",
    "- Can explain model selection considerations\n",
    "\n",
    "### E6 Additions\n",
    "\n",
    "- **Iteration velocity**: \"We need fast experimentation, so we start with GBDT before trying neural nets\"\n",
    "- **Feedback loops**: \"User behavior changes based on model predictions - we need to monitor for distribution shift\"\n",
    "- **Scale**: \"At Meta scale, we use data parallelism across 1000s of GPUs with synchronized SGD\"\n",
    "- **Label quality**: \"We sample 1% of natural labels for human review to estimate label noise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Drills\n",
    "\n",
    "### Drill 1: Model Progression\n",
    "For CTR prediction, walk through:\n",
    "- What baseline would you use?\n",
    "- What simple model would you try first?\n",
    "- What complex model would you consider?\n",
    "\n",
    "### Drill 2: Class Imbalance\n",
    "You have a fraud detection dataset with 0.1% fraud rate. Explain:\n",
    "- Why is this problematic?\n",
    "- What two approaches would you try?\n",
    "- What metrics would you use (not accuracy)?\n",
    "\n",
    "### Drill 3: Labeling Strategy\n",
    "For each task, decide hand labeling vs natural labeling:\n",
    "- Feed ranking (relevant posts)\n",
    "- Harmful content detection\n",
    "- Image classification (objects)\n",
    "\n",
    "### Drill 4: Distributed Training\n",
    "You need to train a model with:\n",
    "- 10B training examples\n",
    "- 500M parameters\n",
    "Which parallelism strategy? Why?\n",
    "\n",
    "### Drill 5: Model Dev Checklist\n",
    "Walk through all 5 talking points for a video recommendation system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

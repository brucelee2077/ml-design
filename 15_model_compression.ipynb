{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 15: Model Compression Techniques\n",
    "\n",
    "## Module 6: Deployment and Serving\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Apply knowledge distillation** - Train smaller student models from larger teachers\n",
    "2. **Implement model pruning** - Remove unnecessary weights and neurons\n",
    "3. **Use quantization techniques** - Reduce model precision for faster inference\n",
    "4. **Compare compression methods** - Analyze accuracy-size-speed trade-offs\n",
    "5. **Design efficient architectures** - Build models optimized for deployment\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Model Compression](#1-introduction)\n",
    "2. [Knowledge Distillation](#2-knowledge-distillation)\n",
    "3. [Model Pruning](#3-pruning)\n",
    "4. [Quantization](#4-quantization)\n",
    "5. [Architecture Optimization](#5-architecture)\n",
    "6. [Compression Comparison](#6-comparison)\n",
    "7. [Hands-on Exercises](#7-exercises)\n",
    "8. [Summary](#8-summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to Model Compression <a name=\"1-introduction\"></a>\n",
    "\n",
    "Model compression reduces the size and computational requirements of ML models while maintaining acceptable accuracy.\n",
    "\n",
    "### Why Compress Models?\n",
    "\n",
    "- **Mobile deployment**: Limited memory and compute\n",
    "- **Edge devices**: IoT, embedded systems\n",
    "- **Cost reduction**: Lower inference costs\n",
    "- **Latency**: Faster predictions\n",
    "\n",
    "### Compression Techniques\n",
    "\n",
    "| Technique | Size Reduction | Speed Improvement | Accuracy Impact |\n",
    "|-----------|----------------|-------------------|----------------|\n",
    "| Knowledge Distillation | 2-10x | 2-10x | Low-Medium |\n",
    "| Pruning | 2-10x | 1.5-3x | Low |\n",
    "| Quantization | 2-4x | 2-4x | Very Low |\n",
    "| Architecture | Varies | Varies | Varies |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample datasets\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_large, y_large = make_classification(\n",
    "    n_samples=5000, n_features=50, n_informative=30,\n",
    "    n_classes=5, n_clusters_per_class=2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "    X_large, y_large, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "scaler_large = StandardScaler()\n",
    "X_train_large_scaled = scaler_large.fit_transform(X_train_large)\n",
    "X_test_large_scaled = scaler_large.transform(X_test_large)\n",
    "\n",
    "print(f\"Digits: {X_train.shape[0]} train, {X_test.shape[0]} test\")\n",
    "print(f\"Large: {X_train_large.shape[0]} train, {X_test_large.shape[0]} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    \"\"\"Estimate model size in bytes.\"\"\"\n",
    "    return len(pickle.dumps(model))\n",
    "\n",
    "def measure_inference_time(model, X, n_runs=100):\n",
    "    \"\"\"Measure average inference time.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        model.predict(X)\n",
    "        times.append(time.time() - start)\n",
    "    return np.mean(times) * 1000\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, name=\"Model\"):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    size = get_model_size(model)\n",
    "    inf_time = measure_inference_time(model, X_test[:100])\n",
    "    \n",
    "    return {\n",
    "        'name': name, 'train_acc': train_acc, 'test_acc': test_acc,\n",
    "        'size_kb': size / 1024, 'inference_ms': inf_time, 'train_time_s': train_time\n",
    "    }\n",
    "\n",
    "print(\"Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Knowledge Distillation <a name=\"2-knowledge-distillation\"></a>\n",
    "\n",
    "Knowledge distillation transfers knowledge from a large \"teacher\" model to a smaller \"student\" model.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Teacher Model**: Large, accurate model\n",
    "- **Student Model**: Smaller, faster model\n",
    "- **Soft Labels**: Teacher's probability outputs\n",
    "- **Temperature**: Softens probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDistillation:\n",
    "    \"\"\"Knowledge distillation from teacher to student.\"\"\"\n",
    "    \n",
    "    def __init__(self, teacher, student, temperature=3.0, alpha=0.5):\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def softmax_temp(self, logits, temp):\n",
    "        \"\"\"Softmax with temperature.\"\"\"\n",
    "        logits = np.array(logits)\n",
    "        scaled = logits / temp\n",
    "        exp_scaled = np.exp(scaled - np.max(scaled, axis=-1, keepdims=True))\n",
    "        return exp_scaled / np.sum(exp_scaled, axis=-1, keepdims=True)\n",
    "    \n",
    "    def get_soft_labels(self, X):\n",
    "        \"\"\"Get soft labels from teacher.\"\"\"\n",
    "        if hasattr(self.teacher, 'predict_proba'):\n",
    "            proba = self.teacher.predict_proba(X)\n",
    "            return self.softmax_temp(np.log(proba + 1e-10), self.temperature)\n",
    "        preds = self.teacher.predict(X)\n",
    "        n_classes = len(np.unique(preds))\n",
    "        one_hot = np.zeros((len(preds), n_classes))\n",
    "        one_hot[np.arange(len(preds)), preds] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def distill(self, X_train, y_train):\n",
    "        \"\"\"Perform knowledge distillation.\"\"\"\n",
    "        print(\"Training teacher...\")\n",
    "        self.teacher.fit(X_train, y_train)\n",
    "        teacher_acc = accuracy_score(y_train, self.teacher.predict(X_train))\n",
    "        print(f\"  Teacher accuracy: {teacher_acc:.4f}\")\n",
    "        \n",
    "        print(\"Training student with soft labels...\")\n",
    "        teacher_preds = self.teacher.predict(X_train)\n",
    "        mask = np.random.random(len(y_train)) > self.alpha\n",
    "        mixed_labels = np.where(mask, teacher_preds, y_train)\n",
    "        \n",
    "        self.student.fit(X_train, mixed_labels)\n",
    "        student_acc = accuracy_score(y_train, self.student.predict(X_train))\n",
    "        print(f\"  Student accuracy: {student_acc:.4f}\")\n",
    "        \n",
    "        return self.student\n",
    "    \n",
    "    def compare(self, X_test, y_test):\n",
    "        \"\"\"Compare teacher and student.\"\"\"\n",
    "        t_acc = accuracy_score(y_test, self.teacher.predict(X_test))\n",
    "        s_acc = accuracy_score(y_test, self.student.predict(X_test))\n",
    "        t_size = get_model_size(self.teacher)\n",
    "        s_size = get_model_size(self.student)\n",
    "        t_time = measure_inference_time(self.teacher, X_test)\n",
    "        s_time = measure_inference_time(self.student, X_test)\n",
    "        \n",
    "        return {\n",
    "            'teacher': {'accuracy': t_acc, 'size_kb': t_size/1024, 'inference_ms': t_time},\n",
    "            'student': {'accuracy': s_acc, 'size_kb': s_size/1024, 'inference_ms': s_time},\n",
    "            'compression': {\n",
    "                'acc_retention': s_acc / t_acc,\n",
    "                'size_reduction': t_size / s_size,\n",
    "                'speedup': t_time / s_time\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# Demo distillation\n",
    "teacher = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "student = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "kd = KnowledgeDistillation(teacher, student, temperature=3.0, alpha=0.3)\n",
    "kd.distill(X_train_scaled, y_train)\n",
    "\n",
    "comp = kd.compare(X_test_scaled, y_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Knowledge Distillation Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTeacher: Acc={comp['teacher']['accuracy']:.4f}, Size={comp['teacher']['size_kb']:.1f}KB\")\n",
    "print(f\"Student: Acc={comp['student']['accuracy']:.4f}, Size={comp['student']['size_kb']:.1f}KB\")\n",
    "print(f\"\\nCompression: {comp['compression']['size_reduction']:.1f}x size, {comp['compression']['speedup']:.1f}x speed\")\n",
    "print(f\"Accuracy retention: {comp['compression']['acc_retention']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature experiment\n",
    "temperatures = [1.0, 2.0, 3.0, 5.0, 10.0]\n",
    "temp_results = []\n",
    "\n",
    "print(\"Temperature Effect on Distillation:\")\n",
    "for temp in temperatures:\n",
    "    t = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "    s = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "    kd_t = KnowledgeDistillation(t, s, temperature=temp, alpha=0.3)\n",
    "    kd_t.distill(X_train_scaled, y_train)\n",
    "    c = kd_t.compare(X_test_scaled, y_test)\n",
    "    temp_results.append({'temp': temp, 'student_acc': c['student']['accuracy'], 'teacher_acc': c['teacher']['accuracy']})\n",
    "    print(f\"T={temp}: Student={c['student']['accuracy']:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "df_temp = pd.DataFrame(temp_results)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(df_temp['temp'], df_temp['student_acc'], marker='o', label='Student', color='coral')\n",
    "ax.axhline(df_temp['teacher_acc'].iloc[0], linestyle='--', color='steelblue', label='Teacher')\n",
    "ax.set_xlabel('Temperature')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Temperature Effect on Distillation')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Model Pruning <a name=\"3-pruning\"></a>\n",
    "\n",
    "Pruning removes unimportant weights or neurons to reduce model size.\n",
    "\n",
    "### Types of Pruning\n",
    "\n",
    "| Type | Description | Hardware Friendly |\n",
    "|------|-------------|------------------|\n",
    "| Weight Pruning | Remove individual weights | No (sparse) |\n",
    "| Structured | Remove neurons/filters | Yes |\n",
    "| Iterative | Gradual pruning | Varies |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPruning:\n",
    "    \"\"\"Model pruning techniques.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def prune_random_forest(model, keep_ratio=0.5):\n",
    "        \"\"\"Prune RF by keeping top trees.\"\"\"\n",
    "        n_keep = max(1, int(len(model.estimators_) * keep_ratio))\n",
    "        pruned = RandomForestClassifier(n_estimators=n_keep, random_state=42)\n",
    "        pruned.estimators_ = model.estimators_[:n_keep]\n",
    "        pruned.n_classes_ = model.n_classes_\n",
    "        pruned.classes_ = model.classes_\n",
    "        pruned.n_features_in_ = model.n_features_in_\n",
    "        return pruned\n",
    "    \n",
    "    @staticmethod\n",
    "    def magnitude_pruning(weights, sparsity=0.5):\n",
    "        \"\"\"Magnitude-based weight pruning.\"\"\"\n",
    "        threshold = np.percentile(np.abs(weights), sparsity * 100)\n",
    "        pruned = np.where(np.abs(weights) < threshold, 0, weights)\n",
    "        actual_sparsity = np.sum(pruned == 0) / pruned.size\n",
    "        return pruned, actual_sparsity\n",
    "\n",
    "\n",
    "# RF Pruning Demo\n",
    "print(\"=\"*50)\n",
    "print(\"Random Forest Pruning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf_full = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "rf_full.fit(X_train_scaled, y_train)\n",
    "\n",
    "pruning_results = []\n",
    "for keep in [1.0, 0.75, 0.5, 0.25, 0.1]:\n",
    "    if keep == 1.0:\n",
    "        pruned = rf_full\n",
    "    else:\n",
    "        pruned = ModelPruning.prune_random_forest(rf_full, keep)\n",
    "    \n",
    "    acc = accuracy_score(y_test, pruned.predict(X_test_scaled))\n",
    "    size = get_model_size(pruned)\n",
    "    inf_time = measure_inference_time(pruned, X_test_scaled)\n",
    "    \n",
    "    pruning_results.append({'keep': keep, 'trees': len(pruned.estimators_), \n",
    "                           'acc': acc, 'size_kb': size/1024, 'time_ms': inf_time})\n",
    "    print(f\"Keep {keep:.0%}: {len(pruned.estimators_)} trees, Acc={acc:.4f}, Size={size/1024:.1f}KB\")\n",
    "\n",
    "# Visualize\n",
    "df_prune = pd.DataFrame(pruning_results)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(df_prune['keep'], df_prune['acc'], marker='o', color='steelblue')\n",
    "axes[0].set_xlabel('Keep Ratio')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy vs Pruning')\n",
    "\n",
    "axes[1].plot(df_prune['keep'], df_prune['size_kb'], marker='s', color='coral')\n",
    "axes[1].set_xlabel('Keep Ratio')\n",
    "axes[1].set_ylabel('Size (KB)')\n",
    "axes[1].set_title('Size vs Pruning')\n",
    "\n",
    "axes[2].plot(df_prune['keep'], df_prune['time_ms'], marker='^', color='forestgreen')\n",
    "axes[2].set_xlabel('Keep Ratio')\n",
    "axes[2].set_ylabel('Time (ms)')\n",
    "axes[2].set_title('Inference Time vs Pruning')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Magnitude Pruning Simulation\n",
    "print(\"=\"*50)\n",
    "print(\"Weight Magnitude Pruning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "np.random.seed(42)\n",
    "weights = np.random.randn(10000)\n",
    "\n",
    "sparsity_results = []\n",
    "for sparsity in [0.0, 0.3, 0.5, 0.7, 0.9, 0.95]:\n",
    "    pruned, actual = ModelPruning.magnitude_pruning(weights, sparsity)\n",
    "    non_zero = np.count_nonzero(pruned)\n",
    "    compression = len(weights) / non_zero if non_zero > 0 else float('inf')\n",
    "    sparsity_results.append({'target': sparsity, 'actual': actual, 'compression': compression})\n",
    "    print(f\"Target: {sparsity:.0%}, Actual: {actual:.2%}, Compression: {compression:.1f}x\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(weights, bins=50, alpha=0.7, label='Original', color='steelblue')\n",
    "pruned_50, _ = ModelPruning.magnitude_pruning(weights, 0.5)\n",
    "axes[0].hist(pruned_50[pruned_50 != 0], bins=50, alpha=0.5, label='Pruned 50%', color='coral')\n",
    "axes[0].set_xlabel('Weight Value')\n",
    "axes[0].set_title('Weight Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "df_sp = pd.DataFrame(sparsity_results)\n",
    "axes[1].plot(df_sp['target'], df_sp['compression'], marker='o', color='forestgreen')\n",
    "axes[1].set_xlabel('Sparsity')\n",
    "axes[1].set_ylabel('Compression Ratio')\n",
    "axes[1].set_title('Compression vs Sparsity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Quantization <a name=\"4-quantization\"></a>\n",
    "\n",
    "Quantization reduces weight precision from floating-point to lower-bit representations.\n",
    "\n",
    "### Quantization Types\n",
    "\n",
    "| Type | Bits | Size Reduction |\n",
    "|------|------|---------------|\n",
    "| FP32 | 32 | 1x (baseline) |\n",
    "| FP16 | 16 | 2x |\n",
    "| INT8 | 8 | 4x |\n",
    "| INT4 | 4 | 8x |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantization:\n",
    "    \"\"\"Quantization techniques.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantize_int8(values):\n",
    "        \"\"\"Quantize to INT8.\"\"\"\n",
    "        values = np.array(values, dtype=np.float32)\n",
    "        max_abs = np.max(np.abs(values))\n",
    "        scale = max_abs / 127.0 if max_abs > 0 else 1.0\n",
    "        quantized = np.round(values / scale).astype(np.int8)\n",
    "        quantized = np.clip(quantized, -128, 127)\n",
    "        return quantized, scale\n",
    "    \n",
    "    @staticmethod\n",
    "    def dequantize_int8(quantized, scale):\n",
    "        \"\"\"Dequantize from INT8.\"\"\"\n",
    "        return quantized.astype(np.float32) * scale\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantize_int4(values):\n",
    "        \"\"\"Quantize to INT4.\"\"\"\n",
    "        values = np.array(values, dtype=np.float32)\n",
    "        max_abs = np.max(np.abs(values))\n",
    "        scale = max_abs / 7.0 if max_abs > 0 else 1.0\n",
    "        quantized = np.round(values / scale).astype(np.int8)\n",
    "        quantized = np.clip(quantized, -8, 7)\n",
    "        return quantized, scale\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc_error(original, dequantized):\n",
    "        \"\"\"Calculate quantization error.\"\"\"\n",
    "        mse = np.mean((original - dequantized) ** 2)\n",
    "        mae = np.mean(np.abs(original - dequantized))\n",
    "        rel_error = mae / (np.mean(np.abs(original)) + 1e-10)\n",
    "        return {'mse': mse, 'mae': mae, 'rel_error': rel_error}\n",
    "\n",
    "\n",
    "# Quantization Demo\n",
    "print(\"=\"*50)\n",
    "print(\"Quantization Demonstration\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_weights = np.random.randn(10000).astype(np.float32)\n",
    "\n",
    "# INT8\n",
    "int8_w, scale_8 = Quantization.quantize_int8(sample_weights)\n",
    "dequant_8 = Quantization.dequantize_int8(int8_w, scale_8)\n",
    "error_8 = Quantization.calc_error(sample_weights, dequant_8)\n",
    "\n",
    "# INT4\n",
    "int4_w, scale_4 = Quantization.quantize_int4(sample_weights)\n",
    "dequant_4 = int4_w.astype(np.float32) * scale_4\n",
    "error_4 = Quantization.calc_error(sample_weights, dequant_4)\n",
    "\n",
    "print(f\"\\nINT8: Scale={scale_8:.4f}, Rel Error={error_8['rel_error']:.4%}\")\n",
    "print(f\"INT4: Scale={scale_4:.4f}, Rel Error={error_4['rel_error']:.4%}\")\n",
    "\n",
    "# Memory savings\n",
    "n_params = 10_000_000\n",
    "print(f\"\\nMemory for 10M params:\")\n",
    "print(f\"  FP32: {n_params * 4 / 1e6:.1f} MB\")\n",
    "print(f\"  INT8: {n_params * 1 / 1e6:.1f} MB (4x reduction)\")\n",
    "print(f\"  INT4: {n_params * 0.5 / 1e6:.1f} MB (8x reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize quantization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Distribution comparison\n",
    "axes[0].hist(sample_weights, bins=50, alpha=0.7, label='FP32', color='steelblue')\n",
    "axes[0].hist(dequant_8, bins=50, alpha=0.5, label='INT8', color='coral')\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_title('FP32 vs INT8')\n",
    "axes[0].legend()\n",
    "\n",
    "# Error distribution\n",
    "error_dist = sample_weights - dequant_8\n",
    "axes[1].hist(error_dist, bins=50, color='coral', alpha=0.7)\n",
    "axes[1].set_xlabel('Quantization Error')\n",
    "axes[1].set_title('INT8 Quantization Error')\n",
    "\n",
    "# Size vs Error trade-off\n",
    "precisions = ['FP32', 'INT8', 'INT4']\n",
    "sizes = [40, 10, 5]  # MB for 10M params\n",
    "errors = [0, error_8['rel_error'], error_4['rel_error']]\n",
    "\n",
    "ax2 = axes[2]\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2.bar(precisions, sizes, color='steelblue', alpha=0.7)\n",
    "ax2_twin.plot(precisions, errors, marker='o', color='coral', linewidth=2)\n",
    "ax2.set_ylabel('Size (MB)', color='steelblue')\n",
    "ax2_twin.set_ylabel('Relative Error', color='coral')\n",
    "ax2.set_title('Size vs Error Trade-off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Architecture Optimization <a name=\"5-architecture\"></a>\n",
    "\n",
    "Efficient architectures are designed for low latency and small footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different architectures\n",
    "print(\"=\"*50)\n",
    "print(\"Architecture Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "architectures = {\n",
    "    'Large MLP': MLPClassifier(hidden_layer_sizes=(500, 200, 100), max_iter=500, random_state=42),\n",
    "    'Medium MLP': MLPClassifier(hidden_layer_sizes=(200, 100), max_iter=500, random_state=42),\n",
    "    'Small MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "    'Tiny MLP': MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42),\n",
    "    'Logistic': LogisticRegression(max_iter=500, random_state=42),\n",
    "    'Large RF': RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42),\n",
    "    'Small RF': RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "arch_results = []\n",
    "for name, model in architectures.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "    size = get_model_size(model)\n",
    "    inf_time = measure_inference_time(model, X_test_scaled)\n",
    "    arch_results.append({'name': name, 'acc': acc, 'size_kb': size/1024, 'time_ms': inf_time})\n",
    "    print(f\"{name:<15}: Acc={acc:.4f}, Size={size/1024:.1f}KB, Time={inf_time:.2f}ms\")\n",
    "\n",
    "df_arch = pd.DataFrame(arch_results).sort_values('acc', ascending=False)\n",
    "\n",
    "# Efficiency score\n",
    "df_arch['efficiency'] = df_arch['acc'] / (df_arch['size_kb'] * df_arch['time_ms'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize architectures\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Accuracy vs Size\n",
    "axes[0].scatter(df_arch['size_kb'], df_arch['acc'], s=100, c=df_arch['time_ms'], cmap='viridis')\n",
    "for _, row in df_arch.iterrows():\n",
    "    axes[0].annotate(row['name'], (row['size_kb'], row['acc']), fontsize=8)\n",
    "axes[0].set_xlabel('Size (KB)')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy vs Size')\n",
    "\n",
    "# Size comparison\n",
    "df_sorted = df_arch.sort_values('size_kb')\n",
    "axes[1].barh(df_sorted['name'], df_sorted['size_kb'], color='steelblue')\n",
    "axes[1].set_xlabel('Size (KB)')\n",
    "axes[1].set_title('Model Size')\n",
    "\n",
    "# Efficiency\n",
    "df_eff = df_arch.sort_values('efficiency')\n",
    "axes[2].barh(df_eff['name'], df_eff['efficiency'], color='forestgreen')\n",
    "axes[2].set_xlabel('Efficiency Score')\n",
    "axes[2].set_title('Efficiency (Acc / Size*Time)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Compression Comparison <a name=\"6-comparison\"></a>\n",
    "\n",
    "Compare all compression techniques on the same baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison\n",
    "print(\"=\"*60)\n",
    "print(\"Comprehensive Compression Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Baseline\n",
    "baseline = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)\n",
    "baseline.fit(X_train_large_scaled, y_train_large)\n",
    "\n",
    "comparison = [{\n",
    "    'method': 'Baseline',\n",
    "    'accuracy': accuracy_score(y_test_large, baseline.predict(X_test_large_scaled)),\n",
    "    'size_kb': get_model_size(baseline) / 1024,\n",
    "    'inference_ms': measure_inference_time(baseline, X_test_large_scaled)\n",
    "}]\n",
    "\n",
    "# 1. Knowledge Distillation\n",
    "print(\"\\n1. Knowledge Distillation...\")\n",
    "student_kd = DecisionTreeClassifier(max_depth=15, random_state=42)\n",
    "teacher_preds = baseline.predict(X_train_large_scaled)\n",
    "mask = np.random.random(len(y_train_large)) > 0.3\n",
    "mixed = np.where(mask, teacher_preds, y_train_large)\n",
    "student_kd.fit(X_train_large_scaled, mixed)\n",
    "\n",
    "comparison.append({\n",
    "    'method': 'Knowledge Distillation',\n",
    "    'accuracy': accuracy_score(y_test_large, student_kd.predict(X_test_large_scaled)),\n",
    "    'size_kb': get_model_size(student_kd) / 1024,\n",
    "    'inference_ms': measure_inference_time(student_kd, X_test_large_scaled)\n",
    "})\n",
    "\n",
    "# 2. Pruning (50%)\n",
    "print(\"2. Pruning (50%)...\")\n",
    "pruned = ModelPruning.prune_random_forest(baseline, 0.5)\n",
    "\n",
    "comparison.append({\n",
    "    'method': 'Pruning (50%)',\n",
    "    'accuracy': accuracy_score(y_test_large, pruned.predict(X_test_large_scaled)),\n",
    "    'size_kb': get_model_size(pruned) / 1024,\n",
    "    'inference_ms': measure_inference_time(pruned, X_test_large_scaled)\n",
    "})\n",
    "\n",
    "# 3. Smaller Architecture\n",
    "print(\"3. Smaller Architecture...\")\n",
    "small_rf = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "small_rf.fit(X_train_large_scaled, y_train_large)\n",
    "\n",
    "comparison.append({\n",
    "    'method': 'Smaller Architecture',\n",
    "    'accuracy': accuracy_score(y_test_large, small_rf.predict(X_test_large_scaled)),\n",
    "    'size_kb': get_model_size(small_rf) / 1024,\n",
    "    'inference_ms': measure_inference_time(small_rf, X_test_large_scaled)\n",
    "})\n",
    "\n",
    "# Create comparison table\n",
    "df_comp = pd.DataFrame(comparison)\n",
    "baseline_acc = df_comp.loc[0, 'accuracy']\n",
    "baseline_size = df_comp.loc[0, 'size_kb']\n",
    "baseline_time = df_comp.loc[0, 'inference_ms']\n",
    "\n",
    "df_comp['acc_retention'] = df_comp['accuracy'] / baseline_acc\n",
    "df_comp['size_reduction'] = baseline_size / df_comp['size_kb']\n",
    "df_comp['speedup'] = baseline_time / df_comp['inference_ms']\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(df_comp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "methods = df_comp['method']\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "# Accuracy\n",
    "colors = ['steelblue' if m == 'Baseline' else 'coral' for m in methods]\n",
    "axes[0].bar(x, df_comp['accuracy'], color=colors)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy Comparison')\n",
    "axes[0].axhline(baseline_acc, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Size\n",
    "axes[1].bar(x, df_comp['size_kb'], color=colors)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Size (KB)')\n",
    "axes[1].set_title('Model Size Comparison')\n",
    "\n",
    "# Speed\n",
    "axes[2].bar(x, df_comp['inference_ms'], color=colors)\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(methods, rotation=45, ha='right')\n",
    "axes[2].set_ylabel('Inference Time (ms)')\n",
    "axes[2].set_title('Speed Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nCompression Summary (vs Baseline):\")\n",
    "for _, row in df_comp.iterrows():\n",
    "    if row['method'] != 'Baseline':\n",
    "        print(f\"  {row['method']}:\")\n",
    "        print(f\"    Accuracy: {row['acc_retention']:.1%} retained\")\n",
    "        print(f\"    Size: {row['size_reduction']:.1f}x smaller\")\n",
    "        print(f\"    Speed: {row['speedup']:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Hands-on Exercises <a name=\"7-exercises\"></a>\n",
    "\n",
    "### Exercise 1: Find Optimal Compression\n",
    "Find the best compression method that maintains >95% accuracy retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "print(\"Exercise 1: Finding Optimal Compression\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test various compression levels\n",
    "results = []\n",
    "\n",
    "# Pruning at different levels\n",
    "for keep in [0.9, 0.7, 0.5, 0.3]:\n",
    "    pruned = ModelPruning.prune_random_forest(baseline, keep)\n",
    "    acc = accuracy_score(y_test_large, pruned.predict(X_test_large_scaled))\n",
    "    retention = acc / baseline_acc\n",
    "    size_red = baseline_size / (get_model_size(pruned)/1024)\n",
    "    \n",
    "    results.append({\n",
    "        'method': f'Prune {1-keep:.0%}',\n",
    "        'acc_retention': retention,\n",
    "        'size_reduction': size_red,\n",
    "        'meets_target': retention >= 0.95\n",
    "    })\n",
    "\n",
    "df_ex = pd.DataFrame(results)\n",
    "print(df_ex.to_string(index=False))\n",
    "\n",
    "best = df_ex[df_ex['meets_target']].sort_values('size_reduction', ascending=False).iloc[0]\n",
    "print(f\"\\nBest option: {best['method']} ({best['size_reduction']:.1f}x size reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Combine Compression Techniques\n",
    "Combine distillation and architecture optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "print(\"Exercise 2: Combined Compression\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Distill to efficient architecture\n",
    "efficient_student = LogisticRegression(max_iter=1000, random_state=42)\n",
    "teacher_preds = baseline.predict(X_train_large_scaled)\n",
    "efficient_student.fit(X_train_large_scaled, teacher_preds)\n",
    "\n",
    "combined_acc = accuracy_score(y_test_large, efficient_student.predict(X_test_large_scaled))\n",
    "combined_size = get_model_size(efficient_student)\n",
    "combined_time = measure_inference_time(efficient_student, X_test_large_scaled)\n",
    "\n",
    "print(f\"Combined approach (Distillation + LogReg):\")\n",
    "print(f\"  Accuracy: {combined_acc:.4f} ({combined_acc/baseline_acc:.1%} retention)\")\n",
    "print(f\"  Size: {combined_size/1024:.1f}KB ({baseline_size/(combined_size/1024):.1f}x reduction)\")\n",
    "print(f\"  Speed: {combined_time:.2f}ms ({baseline_time/combined_time:.1f}x faster)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Summary <a name=\"8-summary\"></a>\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Knowledge Distillation**: Transfer knowledge from large to small models\n",
    "   - Temperature controls softness of labels\n",
    "   - Alpha balances hard vs soft labels\n",
    "\n",
    "2. **Pruning**: Remove unnecessary weights\n",
    "   - Magnitude-based removes small weights\n",
    "   - Structured pruning is more hardware-efficient\n",
    "\n",
    "3. **Quantization**: Reduce precision\n",
    "   - INT8 gives 4x compression with minimal loss\n",
    "   - INT4 gives 8x but more accuracy impact\n",
    "\n",
    "4. **Architecture**: Design efficient models\n",
    "   - Consider accuracy/size/speed trade-offs\n",
    "   - Smaller models can still be effective\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Start with architecture optimization\n",
    "- Apply quantization for easy wins\n",
    "- Use distillation for maximum compression\n",
    "- Combine techniques for best results\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Tutorial 16: Serving and Prediction Pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
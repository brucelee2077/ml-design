{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 02: Framing Problems as ML Tasks\n",
    "\n",
    "Welcome to the third tutorial in our ML System Design series! This tutorial focuses on one of the most critical skills in ML system design: **framing business problems as ML tasks**.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Translate** business objectives to ML objectives\n",
    "2. **Define** appropriate input/output specifications\n",
    "3. **Choose** between single and multi-model architectures\n",
    "4. **Design** effective model pipeline architectures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "from enum import Enum\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Problem Framing Matters\n",
    "\n",
    "Problem framing is the bridge between business requirements and technical implementation. A good frame:\n",
    "\n",
    "- **Simplifies** the problem to its essential components\n",
    "- **Defines** clear success criteria\n",
    "- **Enables** appropriate model selection\n",
    "- **Facilitates** evaluation and iteration\n",
    "\n",
    "A poor frame can lead to:\n",
    "- Building the wrong model\n",
    "- Optimizing for the wrong metric\n",
    "- Impossible-to-solve problems\n",
    "- Wasted engineering effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Problem Framing in the ML Pipeline\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 20)\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw pipeline stages\n",
    "stages = [\n",
    "    ('Business\\nProblem', 5, '#e74c3c'),\n",
    "    ('Problem\\nFraming', 25, '#f39c12'),\n",
    "    ('ML\\nObjective', 45, '#27ae60'),\n",
    "    ('Model\\nDesign', 65, '#3498db'),\n",
    "    ('Implementation', 85, '#9b59b6')\n",
    "]\n",
    "\n",
    "for name, x, color in stages:\n",
    "    rect = plt.Rectangle((x-8, 5), 16, 10, facecolor=color, edgecolor='white', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 10, name, ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "# Draw arrows\n",
    "for i in range(len(stages)-1):\n",
    "    ax.annotate('', xy=(stages[i+1][1]-9, 10), xytext=(stages[i][1]+9, 10),\n",
    "               arrowprops=dict(arrowstyle='->', color='gray', lw=2))\n",
    "\n",
    "# Highlight problem framing\n",
    "ax.annotate('This Tutorial!', xy=(25, 16), ha='center', fontsize=12, \n",
    "            fontweight='bold', color='#f39c12')\n",
    "\n",
    "ax.set_title('Problem Framing in the ML System Design Pipeline', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Business to ML Objective Translation\n",
    "\n",
    "The first step in problem framing is translating a business objective into an ML objective that can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework for translating business objectives\n",
    "\n",
    "@dataclass\n",
    "class ObjectiveTranslation:\n",
    "    \"\"\"Represents the translation from business to ML objective\"\"\"\n",
    "    business_objective: str\n",
    "    proxy_metric: str\n",
    "    ml_objective: str\n",
    "    optimization_target: str\n",
    "    potential_issues: List[str]\n",
    "\n",
    "# Common translations\n",
    "translations = [\n",
    "    ObjectiveTranslation(\n",
    "        business_objective=\"Increase ticket sales for events\",\n",
    "        proxy_metric=\"Event registration rate\",\n",
    "        ml_objective=\"Predict which events a user will register for\",\n",
    "        optimization_target=\"P(registration | user, event)\",\n",
    "        potential_issues=[\"Cold start for new events\", \"Seasonality effects\"]\n",
    "    ),\n",
    "    ObjectiveTranslation(\n",
    "        business_objective=\"Maximize user engagement on platform\",\n",
    "        proxy_metric=\"Time spent / sessions per day\",\n",
    "        ml_objective=\"Predict content that maximizes watch time\",\n",
    "        optimization_target=\"E[watch_time | user, content]\",\n",
    "        potential_issues=[\"Clickbait optimization\", \"Filter bubbles\"]\n",
    "    ),\n",
    "    ObjectiveTranslation(\n",
    "        business_objective=\"Reduce customer support costs\",\n",
    "        proxy_metric=\"Ticket resolution rate, deflection rate\",\n",
    "        ml_objective=\"Classify and route tickets, suggest answers\",\n",
    "        optimization_target=\"P(correct_category | ticket_text)\",\n",
    "        potential_issues=[\"Edge cases\", \"User frustration with automation\"]\n",
    "    ),\n",
    "    ObjectiveTranslation(\n",
    "        business_objective=\"Prevent fraudulent transactions\",\n",
    "        proxy_metric=\"Fraud rate, false positive rate\",\n",
    "        ml_objective=\"Classify transactions as fraud/legitimate\",\n",
    "        optimization_target=\"P(fraud | transaction_features)\",\n",
    "        potential_issues=[\"Class imbalance\", \"Adversarial behavior\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display as table\n",
    "df = pd.DataFrame([{\n",
    "    'Business Objective': t.business_objective,\n",
    "    'Proxy Metric': t.proxy_metric,\n",
    "    'ML Objective': t.ml_objective,\n",
    "    'Optimization Target': t.optimization_target\n",
    "} for t in translations])\n",
    "\n",
    "print(\"Business to ML Objective Translation Examples:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Translation Framework\n",
    "\n",
    "class ObjectiveTranslator:\n",
    "    \"\"\"Helper class to translate business objectives to ML objectives\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.templates = {\n",
    "            \"increase\": \"Predict {target} that maximizes {metric}\",\n",
    "            \"reduce\": \"Predict {target} that minimizes {metric}\",\n",
    "            \"optimize\": \"Predict optimal {target} for {metric}\",\n",
    "            \"detect\": \"Classify {target} as {classes}\",\n",
    "            \"recommend\": \"Rank {items} by predicted {metric} for {user}\",\n",
    "            \"generate\": \"Generate {output} given {input}\"\n",
    "        }\n",
    "    \n",
    "    def translate(self, business_obj: str, context: Dict[str, str]) -> str:\n",
    "        \"\"\"Translate a business objective to ML objective\"\"\"\n",
    "        # Find matching template\n",
    "        for keyword, template in self.templates.items():\n",
    "            if keyword in business_obj.lower():\n",
    "                return template.format(**context)\n",
    "        return f\"Predict outcome for: {business_obj}\"\n",
    "    \n",
    "    def suggest_metrics(self, ml_objective: str) -> List[str]:\n",
    "        \"\"\"Suggest appropriate metrics for an ML objective\"\"\"\n",
    "        metrics = {\n",
    "            \"predict\": [\"MSE\", \"MAE\", \"R-squared\"],\n",
    "            \"classify\": [\"Precision\", \"Recall\", \"F1\", \"AUC-ROC\"],\n",
    "            \"rank\": [\"NDCG\", \"MRR\", \"Precision@K\"],\n",
    "            \"generate\": [\"BLEU\", \"ROUGE\", \"Perplexity\"]\n",
    "        }\n",
    "        \n",
    "        for task_type, task_metrics in metrics.items():\n",
    "            if task_type in ml_objective.lower():\n",
    "                return task_metrics\n",
    "        return [\"Custom metric needed\"]\n",
    "\n",
    "# Example usage\n",
    "translator = ObjectiveTranslator()\n",
    "\n",
    "examples = [\n",
    "    (\"Increase user retention\", {\"target\": \"content\", \"metric\": \"retention\"}),\n",
    "    (\"Detect spam emails\", {\"target\": \"emails\", \"classes\": \"spam/not-spam\"}),\n",
    "    (\"Recommend products to users\", {\"items\": \"products\", \"metric\": \"purchase probability\", \"user\": \"user\"})\n",
    "]\n",
    "\n",
    "print(\"Objective Translation Examples:\")\n",
    "print(\"=\" * 60)\n",
    "for business_obj, context in examples:\n",
    "    ml_obj = translator.translate(business_obj, context)\n",
    "    metrics = translator.suggest_metrics(ml_obj)\n",
    "    print(f\"\\nBusiness: {business_obj}\")\n",
    "    print(f\"ML Objective: {ml_obj}\")\n",
    "    print(f\"Suggested Metrics: {', '.join(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Pitfalls in Objective Translation\n",
    "\n",
    "| Pitfall | Example | Solution |\n",
    "|---------|---------|----------|\n",
    "| Proxy Mismatch | Optimizing for clicks instead of conversions | Align proxy with true business value |\n",
    "| Short-term Focus | Maximizing immediate engagement | Include long-term metrics (retention) |\n",
    "| Gaming Risk | Clickbait titles for CTR | Multiple objectives, constraints |\n",
    "| Missing Constraints | High accuracy but 1-hour latency | Specify all requirements upfront |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Defining System Input/Output\n",
    "\n",
    "Once we have an ML objective, we need to precisely define what the system takes as input and produces as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/Output Specification Framework\n",
    "\n",
    "@dataclass\n",
    "class IOSpecification:\n",
    "    \"\"\"Defines the input/output specification for an ML system\"\"\"\n",
    "    name: str\n",
    "    input_type: str\n",
    "    input_schema: Dict[str, str]\n",
    "    output_type: str\n",
    "    output_schema: Dict[str, str]\n",
    "    context: List[str]\n",
    "    \n",
    "    def display(self):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"System: {self.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"\\nINPUT ({self.input_type}):\")\n",
    "        for field, dtype in self.input_schema.items():\n",
    "            print(f\"  - {field}: {dtype}\")\n",
    "        print(f\"\\nCONTEXT:\")\n",
    "        for ctx in self.context:\n",
    "            print(f\"  - {ctx}\")\n",
    "        print(f\"\\nOUTPUT ({self.output_type}):\")\n",
    "        for field, dtype in self.output_schema.items():\n",
    "            print(f\"  - {field}: {dtype}\")\n",
    "\n",
    "# Example: Video Recommendation System\n",
    "video_rec_io = IOSpecification(\n",
    "    name=\"Video Recommendation System\",\n",
    "    input_type=\"User Request\",\n",
    "    input_schema={\n",
    "        \"user_id\": \"string\",\n",
    "        \"device_type\": \"enum[mobile, web, tv]\",\n",
    "        \"timestamp\": \"datetime\",\n",
    "        \"page_context\": \"enum[home, search, watch]\"\n",
    "    },\n",
    "    output_type=\"Ranked List\",\n",
    "    output_schema={\n",
    "        \"video_ids\": \"List[string]\",\n",
    "        \"scores\": \"List[float]\",\n",
    "        \"explanations\": \"List[string] (optional)\"\n",
    "    },\n",
    "    context=[\n",
    "        \"User's watch history (last 100 videos)\",\n",
    "        \"User's profile (age, location, preferences)\",\n",
    "        \"Current trending videos\",\n",
    "        \"Time of day, day of week\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "video_rec_io.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Content Moderation System\n",
    "content_mod_io = IOSpecification(\n",
    "    name=\"Content Moderation System\",\n",
    "    input_type=\"Content Item\",\n",
    "    input_schema={\n",
    "        \"content_id\": \"string\",\n",
    "        \"content_type\": \"enum[text, image, video]\",\n",
    "        \"content_data\": \"bytes or string\",\n",
    "        \"author_id\": \"string\",\n",
    "        \"metadata\": \"Dict[string, any]\"\n",
    "    },\n",
    "    output_type=\"Moderation Decision\",\n",
    "    output_schema={\n",
    "        \"decision\": \"enum[approve, review, reject]\",\n",
    "        \"violation_types\": \"List[string]\",\n",
    "        \"confidence_score\": \"float\",\n",
    "        \"explanation\": \"string\"\n",
    "    },\n",
    "    context=[\n",
    "        \"Author's history and trust score\",\n",
    "        \"Community guidelines and policies\",\n",
    "        \"Regional content restrictions\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "content_mod_io.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/Output Design Patterns\n",
    "\n",
    "io_patterns = pd.DataFrame({\n",
    "    'Pattern': [\n",
    "        'Single Item -> Single Label',\n",
    "        'Single Item -> Multiple Labels',\n",
    "        'Single Item -> Ranked List',\n",
    "        'Multiple Items -> Scores',\n",
    "        'Query + Context -> Response',\n",
    "        'Sequence -> Sequence'\n",
    "    ],\n",
    "    'Example Use Case': [\n",
    "        'Spam detection (email -> spam/not spam)',\n",
    "        'Content tagging (image -> list of tags)',\n",
    "        'Recommendations (user -> ranked items)',\n",
    "        'Batch scoring (candidates -> relevance scores)',\n",
    "        'Search (query + user -> ranked results)',\n",
    "        'Translation (source text -> target text)'\n",
    "    ],\n",
    "    'ML Task Type': [\n",
    "        'Binary Classification',\n",
    "        'Multi-label Classification',\n",
    "        'Ranking / Retrieval',\n",
    "        'Scoring / Regression',\n",
    "        'Contextual Ranking',\n",
    "        'Sequence-to-Sequence'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Common I/O Patterns in ML Systems:\")\n",
    "display(io_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Single vs Multi-Model Architectures\n",
    "\n",
    "A key design decision is whether to use a single model or multiple models working together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Single vs Multi-Model\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Single Model\n",
    "ax = axes[0]\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axis('off')\n",
    "\n",
    "# Input\n",
    "rect = plt.Rectangle((10, 40), 20, 20, facecolor='#3498db', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(20, 50, 'Input', ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Model\n",
    "rect = plt.Rectangle((40, 35), 25, 30, facecolor='#e74c3c', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(52.5, 50, 'Single\\nModel', ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Output\n",
    "rect = plt.Rectangle((75, 40), 20, 20, facecolor='#27ae60', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(85, 50, 'Output', ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "# Arrows\n",
    "ax.annotate('', xy=(40, 50), xytext=(30, 50), arrowprops=dict(arrowstyle='->', lw=2))\n",
    "ax.annotate('', xy=(75, 50), xytext=(65, 50), arrowprops=dict(arrowstyle='->', lw=2))\n",
    "\n",
    "ax.set_title('Single Model Architecture', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Multi-Model\n",
    "ax = axes[1]\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axis('off')\n",
    "\n",
    "# Input\n",
    "rect = plt.Rectangle((5, 40), 15, 20, facecolor='#3498db', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(12.5, 50, 'Input', ha='center', va='center', color='white', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Model 1: Candidate Generation\n",
    "rect = plt.Rectangle((25, 55), 20, 25, facecolor='#e74c3c', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(35, 67.5, 'Candidate\\nGen', ha='center', va='center', color='white', fontweight='bold', fontsize=8)\n",
    "\n",
    "# Model 2: Feature Extraction\n",
    "rect = plt.Rectangle((25, 20), 20, 25, facecolor='#9b59b6', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(35, 32.5, 'Feature\\nExtract', ha='center', va='center', color='white', fontweight='bold', fontsize=8)\n",
    "\n",
    "# Model 3: Ranking\n",
    "rect = plt.Rectangle((55, 35), 20, 30, facecolor='#f39c12', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(65, 50, 'Ranking\\nModel', ha='center', va='center', color='white', fontweight='bold', fontsize=8)\n",
    "\n",
    "# Output\n",
    "rect = plt.Rectangle((80, 40), 15, 20, facecolor='#27ae60', edgecolor='white', lw=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(87.5, 50, 'Output', ha='center', va='center', color='white', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Arrows\n",
    "ax.annotate('', xy=(25, 55), xytext=(20, 50), arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "ax.annotate('', xy=(25, 35), xytext=(20, 50), arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "ax.annotate('', xy=(55, 55), xytext=(45, 60), arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "ax.annotate('', xy=(55, 45), xytext=(45, 35), arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "ax.annotate('', xy=(80, 50), xytext=(75, 50), arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "ax.set_title('Multi-Model Architecture', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Single vs Multi-Model\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Aspect': [\n",
    "        'Complexity',\n",
    "        'Latency',\n",
    "        'Maintainability',\n",
    "        'Flexibility',\n",
    "        'Debugging',\n",
    "        'Scalability',\n",
    "        'Best For'\n",
    "    ],\n",
    "    'Single Model': [\n",
    "        'Lower',\n",
    "        'Lower (single inference)',\n",
    "        'Easier',\n",
    "        'Less flexible',\n",
    "        'Easier',\n",
    "        'Scales as one unit',\n",
    "        'Simple tasks, low latency requirements'\n",
    "    ],\n",
    "    'Multi-Model': [\n",
    "        'Higher',\n",
    "        'Higher (multiple inferences)',\n",
    "        'More complex',\n",
    "        'More flexible',\n",
    "        'Harder (cascading errors)',\n",
    "        'Each component scales independently',\n",
    "        'Complex tasks, large scale systems'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Single vs Multi-Model Architecture Comparison:\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Model Architecture Patterns\n",
    "\n",
    "@dataclass\n",
    "class MultiModelArchitecture:\n",
    "    \"\"\"Represents a multi-model architecture pattern\"\"\"\n",
    "    name: str\n",
    "    components: List[str]\n",
    "    flow: str\n",
    "    use_case: str\n",
    "    benefits: List[str]\n",
    "\n",
    "architectures = [\n",
    "    MultiModelArchitecture(\n",
    "        name=\"Two-Stage Retrieval + Ranking\",\n",
    "        components=[\"Candidate Generator\", \"Ranker\"],\n",
    "        flow=\"Items -> Fast Retrieval (1000s) -> Precise Ranking (10s)\",\n",
    "        use_case=\"Recommendation systems, Search\",\n",
    "        benefits=[\"Fast candidate generation\", \"Precise final ranking\", \"Scalable\"]\n",
    "    ),\n",
    "    MultiModelArchitecture(\n",
    "        name=\"Cascade Classification\",\n",
    "        components=[\"Fast Filter\", \"Detailed Classifier\"],\n",
    "        flow=\"Items -> Quick Filter -> Deep Analysis on subset\",\n",
    "        use_case=\"Content moderation, Spam detection\",\n",
    "        benefits=[\"Efficient processing\", \"Cost reduction\", \"High precision\"]\n",
    "    ),\n",
    "    MultiModelArchitecture(\n",
    "        name=\"Ensemble\",\n",
    "        components=[\"Model A\", \"Model B\", \"Model C\", \"Aggregator\"],\n",
    "        flow=\"Input -> Multiple Models in parallel -> Combine outputs\",\n",
    "        use_case=\"High-stakes predictions, Competitions\",\n",
    "        benefits=[\"Higher accuracy\", \"Robustness\", \"Diversity\"]\n",
    "    ),\n",
    "    MultiModelArchitecture(\n",
    "        name=\"Feature Extraction + Classifier\",\n",
    "        components=[\"Embedding Model\", \"Task-Specific Classifier\"],\n",
    "        flow=\"Raw Input -> Embeddings -> Classification\",\n",
    "        use_case=\"Transfer learning, Multi-task systems\",\n",
    "        benefits=[\"Reusable features\", \"Faster training\", \"Modularity\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Common Multi-Model Architecture Patterns:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"\\n{arch.name}\")\n",
    "    print(f\"  Components: {' -> '.join(arch.components)}\")\n",
    "    print(f\"  Flow: {arch.flow}\")\n",
    "    print(f\"  Use Case: {arch.use_case}\")\n",
    "    print(f\"  Benefits: {', '.join(arch.benefits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Practical Examples: Problem Framing\n",
    "\n",
    "Let's work through several real-world examples of problem framing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: E-commerce Product Recommendation\n",
    "\n",
    "class ProblemFrame:\n",
    "    \"\"\"Complete problem framing for an ML system\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.business_objective = \"\"\n",
    "        self.ml_objective = \"\"\n",
    "        self.input_spec = {}\n",
    "        self.output_spec = {}\n",
    "        self.architecture = \"\"\n",
    "        self.models = []\n",
    "        self.metrics = []\n",
    "    \n",
    "    def display(self):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PROBLEM FRAME: {self.name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nBusiness Objective: {self.business_objective}\")\n",
    "        print(f\"ML Objective: {self.ml_objective}\")\n",
    "        print(f\"\\nInput Specification:\")\n",
    "        for k, v in self.input_spec.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "        print(f\"\\nOutput Specification:\")\n",
    "        for k, v in self.output_spec.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "        print(f\"\\nArchitecture: {self.architecture}\")\n",
    "        print(f\"Models: {', '.join(self.models)}\")\n",
    "        print(f\"Evaluation Metrics: {', '.join(self.metrics)}\")\n",
    "\n",
    "# E-commerce recommendation\n",
    "ecommerce = ProblemFrame(\"E-commerce Product Recommendation\")\n",
    "ecommerce.business_objective = \"Increase revenue by showing relevant products\"\n",
    "ecommerce.ml_objective = \"Predict purchase probability for user-product pairs, rank by expected revenue\"\n",
    "ecommerce.input_spec = {\n",
    "    \"user_id\": \"string\",\n",
    "    \"current_page\": \"enum[home, category, product, cart]\",\n",
    "    \"browsing_history\": \"List[product_id]\",\n",
    "    \"user_segment\": \"string\"\n",
    "}\n",
    "ecommerce.output_spec = {\n",
    "    \"product_ids\": \"List[string] (top-K products)\",\n",
    "    \"scores\": \"List[float]\",\n",
    "    \"explanation\": \"string (e.g., 'Based on your browsing')\"\n",
    "}\n",
    "ecommerce.architecture = \"Two-stage: Candidate Generation + Ranking\"\n",
    "ecommerce.models = [\"Collaborative Filtering (candidates)\", \"Gradient Boosted Trees (ranking)\"]\n",
    "ecommerce.metrics = [\"Precision@K\", \"Revenue per impression\", \"CTR\"]\n",
    "\n",
    "ecommerce.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Ride-Sharing ETA Prediction\n",
    "\n",
    "eta_prediction = ProblemFrame(\"Ride-Sharing ETA Prediction\")\n",
    "eta_prediction.business_objective = \"Provide accurate arrival time estimates to improve user experience\"\n",
    "eta_prediction.ml_objective = \"Predict trip duration given origin, destination, and current conditions\"\n",
    "eta_prediction.input_spec = {\n",
    "    \"origin\": \"(latitude, longitude)\",\n",
    "    \"destination\": \"(latitude, longitude)\",\n",
    "    \"request_time\": \"datetime\",\n",
    "    \"current_traffic\": \"traffic_data\",\n",
    "    \"weather\": \"weather_data\"\n",
    "}\n",
    "eta_prediction.output_spec = {\n",
    "    \"estimated_duration_seconds\": \"int\",\n",
    "    \"confidence_interval\": \"(lower, upper)\",\n",
    "    \"breakdown\": \"Dict[segment, duration]\"\n",
    "}\n",
    "eta_prediction.architecture = \"Single model with feature engineering\"\n",
    "eta_prediction.models = [\"Gradient Boosted Trees or Neural Network\"]\n",
    "eta_prediction.metrics = [\"MAE\", \"MAPE\", \"90th percentile error\"]\n",
    "\n",
    "eta_prediction.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Social Media Feed Ranking\n",
    "\n",
    "feed_ranking = ProblemFrame(\"Social Media Feed Ranking\")\n",
    "feed_ranking.business_objective = \"Maximize user engagement and time spent on platform\"\n",
    "feed_ranking.ml_objective = \"Predict engagement score for each post, rank to maximize session engagement\"\n",
    "feed_ranking.input_spec = {\n",
    "    \"user_id\": \"string\",\n",
    "    \"candidate_posts\": \"List[post_id]\",\n",
    "    \"user_context\": \"Dict (device, time, session_length)\",\n",
    "    \"social_graph\": \"Graph (friends, follows)\"\n",
    "}\n",
    "feed_ranking.output_spec = {\n",
    "    \"ranked_posts\": \"List[post_id]\",\n",
    "    \"predicted_engagement\": \"List[float]\",\n",
    "    \"diversity_score\": \"float\"\n",
    "}\n",
    "feed_ranking.architecture = \"Multi-stage: Candidate Gen -> Ranking -> Diversity Reranking\"\n",
    "feed_ranking.models = [\"Embedding model (candidates)\", \"Deep ranking model\", \"Diversity optimizer\"]\n",
    "feed_ranking.metrics = [\"Engagement rate\", \"Time spent\", \"Content diversity\"]\n",
    "\n",
    "feed_ranking.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Problem Framing Decision Tree\n",
    "\n",
    "Here's a systematic approach to framing ML problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Framing Decision Framework\n",
    "\n",
    "def frame_problem(answers: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Given answers to key questions, suggest a problem framing.\n",
    "    \n",
    "    Questions:\n",
    "    - output_type: What type of output is needed? (label, score, ranking, sequence)\n",
    "    - item_count: How many items to process? (single, batch, millions)\n",
    "    - latency: What's the latency requirement? (real-time, near-real-time, batch)\n",
    "    - complexity: How complex is the task? (simple, moderate, complex)\n",
    "    \"\"\"\n",
    "    \n",
    "    recommendation = {}\n",
    "    \n",
    "    # Determine task type\n",
    "    output_type = answers.get('output_type', 'label')\n",
    "    if output_type == 'label':\n",
    "        recommendation['task_type'] = 'Classification'\n",
    "    elif output_type == 'score':\n",
    "        recommendation['task_type'] = 'Regression'\n",
    "    elif output_type == 'ranking':\n",
    "        recommendation['task_type'] = 'Learning to Rank'\n",
    "    elif output_type == 'sequence':\n",
    "        recommendation['task_type'] = 'Sequence Generation'\n",
    "    \n",
    "    # Determine architecture\n",
    "    item_count = answers.get('item_count', 'single')\n",
    "    latency = answers.get('latency', 'real-time')\n",
    "    \n",
    "    if item_count == 'millions' and latency == 'real-time':\n",
    "        recommendation['architecture'] = 'Two-stage (Retrieval + Ranking)'\n",
    "        recommendation['reasoning'] = 'Large item space with real-time needs requires efficient retrieval'\n",
    "    elif item_count == 'millions' and latency == 'batch':\n",
    "        recommendation['architecture'] = 'Single model with batch processing'\n",
    "        recommendation['reasoning'] = 'Batch processing allows more complex models'\n",
    "    else:\n",
    "        recommendation['architecture'] = 'Single model'\n",
    "        recommendation['reasoning'] = 'Simple case, single model sufficient'\n",
    "    \n",
    "    # Model complexity\n",
    "    complexity = answers.get('complexity', 'simple')\n",
    "    if complexity == 'simple':\n",
    "        recommendation['model_suggestion'] = 'Logistic Regression, Decision Trees'\n",
    "    elif complexity == 'moderate':\n",
    "        recommendation['model_suggestion'] = 'Gradient Boosted Trees, Random Forest'\n",
    "    else:\n",
    "        recommendation['model_suggestion'] = 'Neural Networks, Transformers'\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# Example usage\n",
    "scenarios = [\n",
    "    {\n",
    "        'name': 'Email Spam Detection',\n",
    "        'answers': {'output_type': 'label', 'item_count': 'single', 'latency': 'real-time', 'complexity': 'moderate'}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Product Recommendation',\n",
    "        'answers': {'output_type': 'ranking', 'item_count': 'millions', 'latency': 'real-time', 'complexity': 'complex'}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Price Prediction',\n",
    "        'answers': {'output_type': 'score', 'item_count': 'single', 'latency': 'batch', 'complexity': 'moderate'}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Problem Framing Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    result = frame_problem(scenario['answers'])\n",
    "    print(f\"\\n{scenario['name']}:\")\n",
    "    print(f\"  Task Type: {result['task_type']}\")\n",
    "    print(f\"  Architecture: {result['architecture']}\")\n",
    "    print(f\"  Reasoning: {result['reasoning']}\")\n",
    "    print(f\"  Suggested Models: {result['model_suggestion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Hands-On Exercise\n",
    "\n",
    "Practice framing ML problems for the following scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Frame these problems\n",
    "\n",
    "exercises = [\n",
    "    {\n",
    "        \"scenario\": \"Music Streaming Service\",\n",
    "        \"business_goal\": \"Help users discover new music they'll love\",\n",
    "        \"hints\": [\"Similar to video recommendation\", \"Consider both discovery and familiar songs\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Job Matching Platform\",\n",
    "        \"business_goal\": \"Connect job seekers with relevant opportunities\",\n",
    "        \"hints\": [\"Two-sided marketplace\", \"Both jobs to users and users to jobs\"]\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"Smart Home Assistant\",\n",
    "        \"business_goal\": \"Understand and respond to voice commands\",\n",
    "        \"hints\": [\"Multi-stage: ASR -> NLU -> Action\", \"Consider latency requirements\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Problem Framing Exercises\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, ex in enumerate(exercises, 1):\n",
    "    print(f\"\\nExercise {i}: {ex['scenario']}\")\n",
    "    print(f\"Business Goal: {ex['business_goal']}\")\n",
    "    print(f\"Hints: {', '.join(ex['hints'])}\")\n",
    "    print(\"\\nYour Task:\")\n",
    "    print(\"  1. Define the ML objective\")\n",
    "    print(\"  2. Specify input/output\")\n",
    "    print(\"  3. Choose single vs multi-model\")\n",
    "    print(\"  4. Suggest evaluation metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for your solutions\n",
    "\n",
    "# Uncomment and complete:\n",
    "\n",
    "# music_rec = ProblemFrame(\"Music Streaming Recommendation\")\n",
    "# music_rec.business_objective = \"...\"\n",
    "# music_rec.ml_objective = \"...\"\n",
    "# music_rec.input_spec = {...}\n",
    "# music_rec.output_spec = {...}\n",
    "# music_rec.architecture = \"...\"\n",
    "# music_rec.models = [...]\n",
    "# music_rec.metrics = [...]\n",
    "# music_rec.display()\n",
    "\n",
    "print(\"Complete the exercises above by uncommenting and filling in the template.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Business to ML Translation**: Always start by translating business objectives to measurable ML objectives\n",
    "\n",
    "2. **I/O Specification**: Clearly define what goes in and what comes out\n",
    "   - Input schema (types, formats)\n",
    "   - Output schema (types, formats)\n",
    "   - Context requirements\n",
    "\n",
    "3. **Architecture Choice**:\n",
    "   - **Single Model**: Simpler, lower latency, easier to maintain\n",
    "   - **Multi-Model**: More flexible, scalable, better for complex tasks\n",
    "   - Common patterns: Two-stage retrieval, Cascade, Ensemble\n",
    "\n",
    "4. **Framing Process**:\n",
    "   - Identify output type (label, score, ranking, sequence)\n",
    "   - Consider scale (items, latency, complexity)\n",
    "   - Choose appropriate architecture\n",
    "   - Define evaluation metrics\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "| Problem Type | Typical Framing |\n",
    "|--------------|----------------|\n",
    "| Recommendation | Two-stage retrieval + ranking |\n",
    "| Content Moderation | Cascade classification |\n",
    "| Search | Query understanding + Retrieval + Ranking |\n",
    "| Fraud Detection | Multi-model ensemble |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next tutorial, we'll dive deep into **ML Categories** - understanding the different types of ML tasks and when to use each.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Quiz\n",
    "quiz = [\n",
    "    (\"What should you do FIRST when framing an ML problem?\", \"A\",\n",
    "     [\"A) Translate business objective to ML objective\", \"B) Choose a model\", \n",
    "      \"C) Collect data\", \"D) Set up infrastructure\"]),\n",
    "    (\"When should you use a two-stage architecture?\", \"C\",\n",
    "     [\"A) When you have little data\", \"B) When latency doesn't matter\",\n",
    "      \"C) When searching over millions of items in real-time\", \"D) Always\"]),\n",
    "    (\"What's the main benefit of multi-model architectures?\", \"B\",\n",
    "     [\"A) Lower latency\", \"B) Better scalability and flexibility\",\n",
    "      \"C) Easier debugging\", \"D) Lower cost\"])\n",
    "]\n",
    "\n",
    "print(\"Quick Self-Assessment\")\n",
    "print(\"=\" * 50)\n",
    "for i, (q, a, opts) in enumerate(quiz, 1):\n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    for opt in opts:\n",
    "        print(f\"   {opt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Answers: 1-A, 2-C, 3-B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03: ML Categories and Task Selection\n",
    "\n",
    "Welcome to the fourth tutorial in our ML System Design series! This tutorial provides a deep dive into different ML categories and helps you choose the right approach for your problem.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Understand** supervised, unsupervised, and reinforcement learning paradigms\n",
    "2. **Distinguish** between classification, regression, and ranking tasks\n",
    "3. **Make informed decisions** about ML category selection\n",
    "4. **Implement** basic examples of each category\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Categories Overview\n",
    "\n",
    "Machine Learning can be broadly categorized into three main paradigms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "ml_categories = pd.DataFrame({\n",
    "    'Category': ['Supervised', 'Unsupervised', 'Reinforcement'],\n",
    "    'Data Requirement': ['Labeled data (X, y)', 'Unlabeled data (X only)', 'Environment + Rewards'],\n",
    "    'Learning Signal': ['Ground truth labels', 'Data structure/patterns', 'Reward signal'],\n",
    "    'Goal': ['Predict labels for new data', 'Discover hidden patterns', 'Maximize cumulative reward'],\n",
    "    'Common Tasks': ['Classification, Regression', 'Clustering, Dim Reduction', 'Game playing, Robotics'],\n",
    "    'Example': ['Spam detection', 'Customer segmentation', 'Recommendation optimization']\n",
    "})\n",
    "\n",
    "print(\"ML Categories Comparison:\")\n",
    "display(ml_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Supervised Learning\n",
    "\n",
    "Supervised learning is the most common paradigm where we learn from labeled examples.\n",
    "\n",
    "### 1.1 Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Spam Detection (Binary Classification)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "emails = [\n",
    "    \"Congratulations! You've won a free iPhone!\",\n",
    "    \"Meeting reminder: Team sync at 3pm today\",\n",
    "    \"URGENT: Your account has been compromised!\",\n",
    "    \"Hi John, can you review the Q3 report?\",\n",
    "    \"FREE MONEY! No credit check required!\",\n",
    "    \"Project update: We're on track for Friday\",\n",
    "]\n",
    "\n",
    "labels = [1, 0, 1, 0, 1, 0]  # 1 = spam, 0 = not spam\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(emails)\n",
    "y = np.array(labels)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "test_emails = [\"Win a free vacation!\", \"Please review the document\"]\n",
    "X_test = vectorizer.transform(test_emails)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Binary Classification: Spam Detection\")\n",
    "print(\"=\" * 50)\n",
    "for email, pred in zip(test_emails, predictions):\n",
    "    print(f\"Email: '{email}'\")\n",
    "    print(f\"Prediction: {'SPAM' if pred == 1 else 'NOT SPAM'}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sentiment Analysis (Multi-class)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "reviews = [\n",
    "    \"This product is amazing! Best purchase ever!\",\n",
    "    \"Terrible quality. Waste of money.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"Absolutely love it! Exceeded expectations!\",\n",
    "    \"Disappointed. Doesn't work as advertised.\",\n",
    "    \"Decent product for the price.\"\n",
    "]\n",
    "\n",
    "sentiments = [2, 0, 1, 2, 0, 1]  # 0=negative, 1=neutral, 2=positive\n",
    "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "model = MultinomialNB()\n",
    "model.fit(X, sentiments)\n",
    "\n",
    "test_reviews = [\"Really enjoyed this!\", \"Not great, not terrible.\"]\n",
    "X_test = vectorizer.transform(test_reviews)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Multi-class Classification: Sentiment Analysis\")\n",
    "print(\"=\" * 50)\n",
    "for review, pred in zip(test_reviews, predictions):\n",
    "    print(f\"Review: '{review}'\")\n",
    "    print(f\"Sentiment: {sentiment_labels[pred]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: House Price Prediction (Regression)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "sqft = np.random.randint(800, 4000, n_samples)\n",
    "bedrooms = np.random.randint(1, 6, n_samples)\n",
    "age = np.random.randint(0, 50, n_samples)\n",
    "\n",
    "price = sqft * 200 + bedrooms * 20000 - age * 1000 + np.random.normal(0, 30000, n_samples)\n",
    "price = np.maximum(price, 50000)\n",
    "\n",
    "X = np.column_stack([sqft, bedrooms, age])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, price, test_size=0.2)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Regression: House Price Prediction\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE: ${mean_absolute_error(y_test, y_pred):,.0f}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in range(3):\n",
    "    print(f\"  House: {X_test[i][0]} sqft, {X_test[i][1]} bed, {X_test[i][2]} yrs old\")\n",
    "    print(f\"  Predicted: ${y_pred[i]:,.0f}, Actual: ${y_test[i]:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Unsupervised Learning\n",
    "\n",
    "### 2.1 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Customer Segmentation (Clustering)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create 3 customer segments\n",
    "seg1 = np.random.normal(loc=[500, 30], scale=[100, 5], size=(100, 2))  # High value\n",
    "seg2 = np.random.normal(loc=[200, 15], scale=[50, 3], size=(100, 2))   # Medium value\n",
    "seg3 = np.random.normal(loc=[50, 5], scale=[20, 2], size=(100, 2))     # Low value\n",
    "\n",
    "data = np.vstack([seg1, seg2, seg3])\n",
    "data = np.clip(data, 0, None)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(data[:, 0], data[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "ax.set_xlabel('Average Purchase ($)')\n",
    "ax.set_ylabel('Visits per Month')\n",
    "ax.set_title('Customer Segmentation with K-Means')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCluster Sizes:\", np.bincount(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fraud Detection (Anomaly Detection)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Normal transactions\n",
    "normal = np.random.normal(loc=[100, 12], scale=[50, 4], size=(950, 2))\n",
    "# Fraudulent transactions (anomalies)\n",
    "fraud = np.random.normal(loc=[500, 2], scale=[100, 1], size=(50, 2))\n",
    "\n",
    "X = np.vstack([normal, fraud])\n",
    "y_true = np.array([0]*950 + [1]*50)\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "y_pred = (iso_forest.fit_predict(X) == -1).astype(int)\n",
    "\n",
    "print(\"Anomaly Detection: Fraud Detection\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_true, y_pred):.2f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if p == 0 else 'red' for p in y_pred]\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors, alpha=0.5)\n",
    "ax.set_xlabel('Transaction Amount ($)')\n",
    "ax.set_ylabel('Transaction Hour')\n",
    "ax.set_title('Anomaly Detection: Normal (Green) vs Fraud (Red)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multi-Armed Bandit for Content Recommendation\n",
    "\n",
    "class MultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.counts = np.zeros(n_arms)\n",
    "        self.values = np.zeros(n_arms)\n",
    "    \n",
    "    def select_arm(self, epsilon=0.1):\n",
    "        if np.random.random() < epsilon:\n",
    "            return np.random.randint(self.n_arms)\n",
    "        return np.argmax(self.values)\n",
    "    \n",
    "    def update(self, arm, reward):\n",
    "        self.counts[arm] += 1\n",
    "        self.values[arm] += (reward - self.values[arm]) / self.counts[arm]\n",
    "\n",
    "# Simulate content types with different engagement rates\n",
    "true_rates = [0.1, 0.15, 0.3, 0.25, 0.2]\n",
    "content_types = ['News', 'Sports', 'Entertainment', 'Tech', 'Lifestyle']\n",
    "\n",
    "bandit = MultiArmedBandit(n_arms=5)\n",
    "rewards = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    arm = bandit.select_arm(epsilon=0.1)\n",
    "    reward = np.random.binomial(1, true_rates[arm])\n",
    "    bandit.update(arm, reward)\n",
    "    rewards.append(reward)\n",
    "\n",
    "print(\"Reinforcement Learning: Content Recommendation\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nLearned vs True CTR:\")\n",
    "for name, true, learned in zip(content_types, true_rates, bandit.values):\n",
    "    print(f\"  {name}: True={true:.2f}, Learned={learned:.2f}\")\n",
    "print(f\"\\nAverage Reward: {np.mean(rewards):.3f} (Best possible: {max(true_rates):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Decision Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ml_category(has_labels, output_type, feedback_type='none'):\n",
    "    \"\"\"Select the appropriate ML category.\"\"\"\n",
    "    if has_labels:\n",
    "        if output_type == 'category':\n",
    "            return 'Supervised - Classification'\n",
    "        elif output_type == 'number':\n",
    "            return 'Supervised - Regression'\n",
    "        elif output_type == 'ranking':\n",
    "            return 'Supervised - Ranking'\n",
    "    elif feedback_type == 'delayed':\n",
    "        return 'Reinforcement Learning'\n",
    "    else:\n",
    "        if output_type == 'groups':\n",
    "            return 'Unsupervised - Clustering'\n",
    "        elif output_type == 'anomalies':\n",
    "            return 'Unsupervised - Anomaly Detection'\n",
    "        else:\n",
    "            return 'Unsupervised - Dimensionality Reduction'\n",
    "    return 'Unknown'\n",
    "\n",
    "scenarios = [\n",
    "    ('Spam Detection', True, 'category', 'none'),\n",
    "    ('House Price', True, 'number', 'none'),\n",
    "    ('Customer Segmentation', False, 'groups', 'none'),\n",
    "    ('Fraud Detection', False, 'anomalies', 'none'),\n",
    "    ('Ad Optimization', False, 'actions', 'delayed'),\n",
    "]\n",
    "\n",
    "print(\"ML Category Selection:\")\n",
    "print(\"=\" * 50)\n",
    "for name, labels, output, feedback in scenarios:\n",
    "    result = select_ml_category(labels, output, feedback)\n",
    "    print(f\"\\n{name}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Task Type': ['Binary Classification', 'Multi-class', 'Regression', 'Clustering', 'Anomaly Detection', 'RL'],\n",
    "    'Category': ['Supervised', 'Supervised', 'Supervised', 'Unsupervised', 'Unsupervised', 'RL'],\n",
    "    'Output': ['0 or 1', 'One of N', 'Continuous', 'Cluster ID', 'Normal/Anomaly', 'Actions'],\n",
    "    'Key Metrics': ['AUC, F1', 'Accuracy, F1-macro', 'MSE, R2', 'Silhouette', 'Precision, Recall', 'Reward'],\n",
    "    'Example': ['Spam', 'Sentiment', 'Price', 'Segmentation', 'Fraud', 'Ads']\n",
    "})\n",
    "\n",
    "print(\"\\nTask Types Comparison:\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Hands-On Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercises = [\n",
    "    (\"Predict if a loan will default\", \"Binary Classification\"),\n",
    "    (\"Group customers by behavior\", \"Clustering\"),\n",
    "    (\"Predict stock price\", \"Regression\"),\n",
    "    (\"Find network intrusions\", \"Anomaly Detection\"),\n",
    "    (\"Optimize email send times\", \"Reinforcement Learning\"),\n",
    "]\n",
    "\n",
    "print(\"Exercise: What ML Category?\")\n",
    "print(\"=\" * 50)\n",
    "for i, (scenario, answer) in enumerate(exercises, 1):\n",
    "    print(f\"\\n{i}. {scenario}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ANSWERS:\")\n",
    "for i, (_, answer) in enumerate(exercises, 1):\n",
    "    print(f\"{i}. {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Three Main Categories**:\n",
    "   - **Supervised**: Has labels, predicts for new data\n",
    "   - **Unsupervised**: No labels, discovers patterns\n",
    "   - **Reinforcement**: Learns from feedback/rewards\n",
    "\n",
    "2. **Supervised Learning Tasks**:\n",
    "   - Binary/Multi-class Classification\n",
    "   - Regression\n",
    "   - Ranking\n",
    "\n",
    "3. **Unsupervised Learning Tasks**:\n",
    "   - Clustering\n",
    "   - Anomaly Detection\n",
    "   - Dimensionality Reduction\n",
    "\n",
    "4. **Decision Framework**:\n",
    "   - Start with data availability (labeled or not)\n",
    "   - Consider output type needed\n",
    "   - Match to appropriate task\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "You're now ready for:\n",
    "- **Data Preparation**: ETL and feature engineering\n",
    "- **Model Development**: Selection and training\n",
    "- **Evaluation**: Metrics and testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Quiz\n",
    "quiz = [\n",
    "    (\"Which ML category requires labeled data?\", \"A\", \n",
    "     [\"A) Supervised\", \"B) Unsupervised\", \"C) Reinforcement\", \"D) All\"]),\n",
    "    (\"Best task for predicting prices?\", \"C\",\n",
    "     [\"A) Classification\", \"B) Clustering\", \"C) Regression\", \"D) Anomaly\"]),\n",
    "    (\"When to use RL?\", \"D\",\n",
    "     [\"A) Lots of labels\", \"B) Need clusters\", \"C) Continuous output\", \"D) Delayed feedback\"])\n",
    "]\n",
    "\n",
    "print(\"Quick Quiz\")\n",
    "print(\"=\" * 40)\n",
    "for i, (q, _, opts) in enumerate(quiz, 1):\n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    for opt in opts:\n",
    "        print(f\"   {opt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Answers: 1-A, 2-C, 3-D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
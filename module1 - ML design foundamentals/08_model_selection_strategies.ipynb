{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 08: Model Selection Strategies\n",
    "\n",
    "## Module 4: Model Development\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Establish appropriate baselines** for any ML problem\n",
    "2. **Progress from simple to complex models** systematically\n",
    "3. **Understand model trade-offs** across multiple dimensions\n",
    "4. **Apply ensemble methods** to improve performance\n",
    "5. **Make informed model selection decisions** based on requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Model Selection\n",
    "\n",
    "Model selection depends on:\n",
    "- **Problem type**: Classification, regression, ranking\n",
    "- **Data characteristics**: Size, dimensionality, noise\n",
    "- **Performance requirements**: Accuracy, latency, throughput\n",
    "- **Operational constraints**: Interpretability, deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "cancer_data = load_breast_cancer()\n",
    "X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "y_cancer = cancer_data.target\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "scaler_clf = StandardScaler()\n",
    "X_train_clf_scaled = scaler_clf.fit_transform(X_train_clf)\n",
    "X_test_clf_scaled = scaler_clf.transform(X_test_clf)\n",
    "\n",
    "print(f\"Classification Dataset: {len(X_train_clf)} training, {len(X_test_clf)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = fetch_california_housing()\n",
    "X_housing = pd.DataFrame(housing_data.data[:5000], columns=housing_data.feature_names)\n",
    "y_housing = housing_data.target[:5000]\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_reg_scaled = scaler_reg.fit_transform(X_train_reg)\n",
    "X_test_reg_scaled = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "print(f\"Regression Dataset: {len(X_train_reg)} training, {len(X_test_reg)} test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Establishing Baselines\n",
    "\n",
    "| Baseline Type | Description | When to Use |\n",
    "|--------------|-------------|-------------|\n",
    "| **Random** | Random predictions | Sanity check |\n",
    "| **Majority/Mean** | Most common class/mean | Minimum bar |\n",
    "| **Stratified** | Random with class distribution | Imbalanced data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelResult:\n",
    "    name: str\n",
    "    accuracy: float = 0.0\n",
    "    f1: float = 0.0\n",
    "    auc: float = 0.0\n",
    "    train_time: float = 0.0\n",
    "    rmse: float = 0.0\n",
    "    r2: float = 0.0\n",
    "\n",
    "def evaluate_classifier(model, X_train, X_test, y_train, y_test, name):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "    y_pred = model.predict(X_test)\n",
    "    result = ModelResult(\n",
    "        name=name,\n",
    "        accuracy=accuracy_score(y_test, y_pred),\n",
    "        f1=f1_score(y_test, y_pred, average='weighted'),\n",
    "        train_time=train_time\n",
    "    )\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "            if y_proba.shape[1] == 2:\n",
    "                result.auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "        except: pass\n",
    "    return result\n",
    "\n",
    "def evaluate_regressor(model, X_train, X_test, y_train, y_test, name):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return ModelResult(\n",
    "        name=name, rmse=np.sqrt(mse), r2=r2_score(y_test, y_pred), train_time=train_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification baselines\n",
    "all_clf_results = []\n",
    "baselines = {\n",
    "    'Random': DummyClassifier(strategy='uniform', random_state=42),\n",
    "    'Most Frequent': DummyClassifier(strategy='most_frequent'),\n",
    "    'Stratified': DummyClassifier(strategy='stratified', random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Classification Baselines\")\n",
    "for name, model in baselines.items():\n",
    "    result = evaluate_classifier(model, X_train_clf_scaled, X_test_clf_scaled, y_train_clf, y_test_clf, name)\n",
    "    all_clf_results.append(result)\n",
    "    print(f\"{name}: Accuracy={result.accuracy:.4f}, F1={result.f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression baselines\n",
    "all_reg_results = []\n",
    "reg_baselines = {\n",
    "    'Mean': DummyRegressor(strategy='mean'),\n",
    "    'Median': DummyRegressor(strategy='median')\n",
    "}\n",
    "\n",
    "print(\"Regression Baselines\")\n",
    "for name, model in reg_baselines.items():\n",
    "    result = evaluate_regressor(model, X_train_reg_scaled, X_test_reg_scaled, y_train_reg, y_test_reg, name)\n",
    "    all_reg_results.append(result)\n",
    "    print(f\"{name}: RMSE={result.rmse:.4f}, R2={result.r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Models\n",
    "\n",
    "| Model | Pros | Cons |\n",
    "|-------|------|------|\n",
    "| Logistic Regression | Interpretable, fast | Linear boundary |\n",
    "| Decision Tree | No scaling needed | Overfits easily |\n",
    "| Naive Bayes | Very fast | Independence assumption |\n",
    "| KNN | Simple | Slow prediction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree (depth=5)': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(\"Simple Models\")\n",
    "for name, model in simple_models.items():\n",
    "    result = evaluate_classifier(model, X_train_clf_scaled, X_test_clf_scaled, y_train_clf, y_test_clf, name)\n",
    "    all_clf_results.append(result)\n",
    "    print(f\"{name}: Accuracy={result.accuracy:.4f}, F1={result.f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "importance = np.abs(lr.coef_[0])\n",
    "sorted_idx = np.argsort(importance)[::-1][:10]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(range(10), importance[sorted_idx][::-1], color='steelblue')\n",
    "plt.yticks(range(10), [cancer_data.feature_names[i] for i in sorted_idx[::-1]])\n",
    "plt.xlabel('Absolute Coefficient')\n",
    "plt.title('Top 10 Feature Importance (Logistic Regression)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting analysis for Decision Tree\n",
    "depths = range(1, 15)\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for depth in depths:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train_clf_scaled, y_train_clf)\n",
    "    train_scores.append(dt.score(X_train_clf_scaled, y_train_clf))\n",
    "    test_scores.append(dt.score(X_test_clf_scaled, y_test_clf))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(depths, train_scores, 'b-', label='Training', linewidth=2)\n",
    "plt.plot(depths, test_scores, 'r-', label='Test', linewidth=2)\n",
    "plt.fill_between(depths, train_scores, test_scores, alpha=0.2)\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree Overfitting Analysis')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f\"Optimal depth: {depths[np.argmax(test_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple regression models\n",
    "simple_reg = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'Decision Tree Reg': DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Simple Regression Models\")\n",
    "for name, model in simple_reg.items():\n",
    "    result = evaluate_regressor(model, X_train_reg_scaled, X_test_reg_scaled, y_train_reg, y_test_reg, name)\n",
    "    all_reg_results.append(result)\n",
    "    print(f\"{name}: RMSE={result.rmse:.4f}, R2={result.r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Complex Models\n",
    "\n",
    "- **Random Forest**: Ensemble of decision trees\n",
    "- **Gradient Boosting**: Sequential error correction\n",
    "- **SVM**: Non-linear boundaries with kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Complex Models\")\n",
    "for name, model in complex_models.items():\n",
    "    result = evaluate_classifier(model, X_train_clf_scaled, X_test_clf_scaled, y_train_clf, y_test_clf, name)\n",
    "    all_clf_results.append(result)\n",
    "    print(f\"{name}: Accuracy={result.accuracy:.4f}, F1={result.f1:.4f}, AUC={result.auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_reg = {\n",
    "    'Random Forest Reg': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting Reg': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Complex Regression Models\")\n",
    "for name, model in complex_reg.items():\n",
    "    result = evaluate_regressor(model, X_train_reg_scaled, X_test_reg_scaled, y_train_reg, y_test_reg, name)\n",
    "    all_reg_results.append(result)\n",
    "    print(f\"{name}: RMSE={result.rmse:.4f}, R2={result.r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Methods\n",
    "\n",
    "| Method | Description | Best For |\n",
    "|--------|-------------|----------|\n",
    "| Bagging | Bootstrap samples | Reducing variance |\n",
    "| Boosting | Sequential correction | Reducing bias |\n",
    "| Stacking | Meta-learner | Maximum performance |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = {\n",
    "    'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=5), n_estimators=50, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3), n_estimators=100, random_state=42),\n",
    "    'Voting': VotingClassifier(\n",
    "        estimators=[('lr', LogisticRegression(max_iter=1000)), ('rf', RandomForestClassifier(n_estimators=50))],\n",
    "        voting='soft'\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Ensemble Methods\")\n",
    "for name, model in ensemble_models.items():\n",
    "    result = evaluate_classifier(model, X_train_clf_scaled, X_test_clf_scaled, y_train_clf, y_test_clf, name)\n",
    "    all_clf_results.append(result)\n",
    "    print(f\"{name}: Accuracy={result.accuracy:.4f}, F1={result.f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=50)),\n",
    "        ('svc', SVC(probability=True))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "result = evaluate_classifier(stacking, X_train_clf_scaled, X_test_clf_scaled, y_train_clf, y_test_clf, 'Stacking')\n",
    "all_clf_results.append(result)\n",
    "print(f\"Stacking: Accuracy={result.accuracy:.4f}, F1={result.f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "print(\"Grid Search Results\")\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test score: {grid_search.score(X_test_clf_scaled, y_test_clf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'min_samples_split': randint(2, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_clf_scaled, y_train_clf)\n",
    "\n",
    "print(\"\\nRandom Search Results\")\n",
    "print(f\"Best params: {random_search.best_params_}\")\n",
    "print(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "print(f\"Test score: {random_search.score(X_test_clf_scaled, y_test_clf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification comparison\n",
    "clf_df = pd.DataFrame([{'Model': r.name, 'Accuracy': r.accuracy, 'F1': r.f1} for r in all_clf_results])\n",
    "clf_df = clf_df.sort_values('Accuracy', ascending=False)\n",
    "print(\"Classification Model Comparison\")\n",
    "print(clf_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_models = clf_df.head(12)\n",
    "colors = ['green' if acc > 0.95 else 'steelblue' if acc > 0.9 else 'coral' for acc in top_models['Accuracy']]\n",
    "ax.barh(range(len(top_models)), top_models['Accuracy'], color=colors)\n",
    "ax.set_yticks(range(len(top_models)))\n",
    "ax.set_yticklabels(top_models['Model'])\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Top Models by Accuracy')\n",
    "ax.axvline(x=0.95, color='green', linestyle='--', alpha=0.7)\n",
    "ax.axvline(x=0.90, color='orange', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression comparison\n",
    "reg_df = pd.DataFrame([{'Model': r.name, 'RMSE': r.rmse, 'R2': r.r2} for r in all_reg_results])\n",
    "reg_df = reg_df.sort_values('R2', ascending=False)\n",
    "print(\"\\nRegression Model Comparison\")\n",
    "print(reg_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hands-on Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset\n",
    "X_ex, y_ex = make_classification(n_samples=2000, n_features=20, n_informative=15, random_state=42)\n",
    "X_train_ex, X_test_ex, y_train_ex, y_test_ex = train_test_split(X_ex, y_ex, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_ex = StandardScaler()\n",
    "X_train_ex = scaler_ex.fit_transform(X_train_ex)\n",
    "X_test_ex = scaler_ex.transform(X_test_ex)\n",
    "\n",
    "print(\"Exercise: Progressive Model Selection\")\n",
    "print(f\"Dataset: {len(X_train_ex)} training, {len(X_test_ex)} test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Baseline\n",
    "baseline = DummyClassifier(strategy='stratified', random_state=42)\n",
    "baseline.fit(X_train_ex, y_train_ex)\n",
    "print(f\"Step 1 - Baseline: {baseline.score(X_test_ex, y_test_ex):.4f}\")\n",
    "\n",
    "# Step 2: Simple Model\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_ex, y_train_ex)\n",
    "print(f\"Step 2 - Logistic Regression: {lr.score(X_test_ex, y_test_ex):.4f}\")\n",
    "\n",
    "# Step 3: Complex Model\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train_ex, y_train_ex)\n",
    "print(f\"Step 3 - Gradient Boosting: {gb.score(X_test_ex, y_test_ex):.4f}\")\n",
    "\n",
    "# Step 4: Tuning\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [3, 5], 'learning_rate': [0.05, 0.1]}\n",
    "tuned_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)\n",
    "tuned_gb.fit(X_train_ex, y_train_ex)\n",
    "print(f\"Step 4 - Tuned GB: {tuned_gb.score(X_test_ex, y_test_ex):.4f}\")\n",
    "print(f\"Best params: {tuned_gb.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Always start with baselines** to establish minimum performance thresholds\n",
    "2. **Progress from simple to complex** models systematically\n",
    "3. **Consider trade-offs** between accuracy, speed, interpretability, and memory\n",
    "4. **Ensemble methods** often provide the best performance\n",
    "5. **Hyperparameter tuning** can significantly improve model performance\n",
    "\n",
    "### Model Selection Guidelines\n",
    "\n",
    "| Scenario | Recommended Approach |\n",
    "|----------|---------------------|\n",
    "| Quick prototype | Logistic Regression / Decision Tree |\n",
    "| Interpretability needed | Logistic Regression / Small Decision Tree |\n",
    "| Maximum accuracy | Gradient Boosting / Stacking |\n",
    "| Large dataset | Random Forest / XGBoost |\n",
    "| Low latency required | Simple models or compressed ensembles |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
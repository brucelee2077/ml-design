{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 09: Dataset Construction for ML\n",
    "\n",
    "## Module 4: Model Development\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Apply effective data collection strategies** including active learning and augmentation\n",
    "2. **Implement various labeling approaches** from hand labeling to weak supervision\n",
    "3. **Use appropriate sampling strategies** for different scenarios\n",
    "4. **Create proper train/validation/test splits** including time-based splitting\n",
    "5. **Implement cross-validation techniques** for robust model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "from sklearn.datasets import make_classification, make_regression, load_iris, load_digits\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, KFold, TimeSeriesSplit,\n",
    "    cross_val_score, LeaveOneOut, GroupKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection Strategies\n",
    "\n",
    "Effective data collection is crucial for ML success.\n",
    "\n",
    "### Collection Methods\n",
    "\n",
    "| Method | Description | When to Use |\n",
    "|--------|-------------|-------------|\n",
    "| **Direct Collection** | Collect from primary sources | Have access to data source |\n",
    "| **Active Learning** | Selectively label most informative samples | Limited labeling budget |\n",
    "| **Data Augmentation** | Create variations of existing data | Limited training data |\n",
    "| **Synthetic Generation** | Generate artificial data | Need more samples |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Active Learning\n",
    "\n",
    "Active learning selects the most informative samples for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearner:\n",
    "    \"\"\"Simple active learning implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, strategy='uncertainty'):\n",
    "        self.model = model\n",
    "        self.strategy = strategy\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def query(self, X_pool, n_samples=10):\n",
    "        \"\"\"Select most informative samples from pool.\"\"\"\n",
    "        if self.strategy == 'uncertainty':\n",
    "            return self._uncertainty_sampling(X_pool, n_samples)\n",
    "        elif self.strategy == 'margin':\n",
    "            return self._margin_sampling(X_pool, n_samples)\n",
    "        elif self.strategy == 'entropy':\n",
    "            return self._entropy_sampling(X_pool, n_samples)\n",
    "        else:\n",
    "            return self._random_sampling(X_pool, n_samples)\n",
    "    \n",
    "    def _uncertainty_sampling(self, X_pool, n_samples):\n",
    "        \"\"\"Select samples with highest uncertainty (lowest confidence).\"\"\"\n",
    "        proba = self.model.predict_proba(X_pool)\n",
    "        confidence = np.max(proba, axis=1)\n",
    "        indices = np.argsort(confidence)[:n_samples]\n",
    "        return indices\n",
    "    \n",
    "    def _margin_sampling(self, X_pool, n_samples):\n",
    "        \"\"\"Select samples with smallest margin between top two predictions.\"\"\"\n",
    "        proba = self.model.predict_proba(X_pool)\n",
    "        sorted_proba = np.sort(proba, axis=1)[:, ::-1]\n",
    "        margin = sorted_proba[:, 0] - sorted_proba[:, 1]\n",
    "        indices = np.argsort(margin)[:n_samples]\n",
    "        return indices\n",
    "    \n",
    "    def _entropy_sampling(self, X_pool, n_samples):\n",
    "        \"\"\"Select samples with highest entropy.\"\"\"\n",
    "        proba = self.model.predict_proba(X_pool)\n",
    "        entropy = -np.sum(proba * np.log(proba + 1e-10), axis=1)\n",
    "        indices = np.argsort(entropy)[::-1][:n_samples]\n",
    "        return indices\n",
    "    \n",
    "    def _random_sampling(self, X_pool, n_samples):\n",
    "        \"\"\"Random sampling baseline.\"\"\"\n",
    "        indices = np.random.choice(len(X_pool), n_samples, replace=False)\n",
    "        return indices\n",
    "\n",
    "print(\"ActiveLearner class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate active learning\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=3, random_state=42)\n",
    "\n",
    "# Split into initial labeled set, pool, and test set\n",
    "X_initial, X_rest, y_initial, y_rest = train_test_split(X, y, train_size=50, random_state=42, stratify=y)\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(X_rest, y_rest, test_size=200, random_state=42)\n",
    "\n",
    "# Initialize model and active learner\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "al = ActiveLearner(model, strategy='uncertainty')\n",
    "\n",
    "# Active learning loop\n",
    "X_train, y_train = X_initial.copy(), y_initial.copy()\n",
    "n_queries = 10\n",
    "samples_per_query = 20\n",
    "\n",
    "accuracy_history = []\n",
    "\n",
    "for i in range(n_queries):\n",
    "    # Train on current labeled data\n",
    "    al.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, al.model.predict(X_test))\n",
    "    accuracy_history.append((len(y_train), accuracy))\n",
    "    \n",
    "    if len(y_pool) == 0:\n",
    "        break\n",
    "        \n",
    "    # Query most informative samples\n",
    "    query_indices = al.query(X_pool, n_samples=min(samples_per_query, len(y_pool)))\n",
    "    \n",
    "    # Add to training set\n",
    "    X_train = np.vstack([X_train, X_pool[query_indices]])\n",
    "    y_train = np.concatenate([y_train, y_pool[query_indices]])\n",
    "    \n",
    "    # Remove from pool\n",
    "    X_pool = np.delete(X_pool, query_indices, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_indices)\n",
    "\n",
    "print(\"Active Learning Progress:\")\n",
    "for n_samples, acc in accuracy_history:\n",
    "    print(f\"  {n_samples} samples: {acc:.4f} accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare active learning strategies\n",
    "strategies = ['uncertainty', 'margin', 'entropy', 'random']\n",
    "results = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    # Reset data\n",
    "    X_train, y_train = X_initial.copy(), y_initial.copy()\n",
    "    X_pool_copy, y_pool_copy = X_rest[:len(X_rest)-200].copy(), y_rest[:len(y_rest)-200].copy()\n",
    "    \n",
    "    al = ActiveLearner(LogisticRegression(max_iter=1000, random_state=42), strategy=strategy)\n",
    "    accuracy_hist = []\n",
    "    \n",
    "    for _ in range(n_queries):\n",
    "        al.fit(X_train, y_train)\n",
    "        accuracy_hist.append((len(y_train), accuracy_score(y_test, al.model.predict(X_test))))\n",
    "        \n",
    "        if len(y_pool_copy) == 0:\n",
    "            break\n",
    "            \n",
    "        query_idx = al.query(X_pool_copy, min(samples_per_query, len(y_pool_copy)))\n",
    "        X_train = np.vstack([X_train, X_pool_copy[query_idx]])\n",
    "        y_train = np.concatenate([y_train, y_pool_copy[query_idx]])\n",
    "        X_pool_copy = np.delete(X_pool_copy, query_idx, axis=0)\n",
    "        y_pool_copy = np.delete(y_pool_copy, query_idx)\n",
    "    \n",
    "    results[strategy] = accuracy_hist\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for strategy, hist in results.items():\n",
    "    samples, accs = zip(*hist)\n",
    "    plt.plot(samples, accs, marker='o', label=strategy.capitalize())\n",
    "\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Active Learning Strategy Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Augmentation\n",
    "\n",
    "Data augmentation creates variations of existing data to increase dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmenter:\n",
    "    \"\"\"Data augmentation for tabular and text data.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_noise(X, noise_level=0.1):\n",
    "        \"\"\"Add Gaussian noise to features.\"\"\"\n",
    "        noise = np.random.normal(0, noise_level, X.shape)\n",
    "        return X + noise * np.std(X, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def feature_dropout(X, dropout_rate=0.1):\n",
    "        \"\"\"Randomly set features to zero.\"\"\"\n",
    "        mask = np.random.random(X.shape) > dropout_rate\n",
    "        return X * mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def mixup(X1, X2, y1, y2, alpha=0.2):\n",
    "        \"\"\"Mixup augmentation: blend two samples.\"\"\"\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        X_mix = lam * X1 + (1 - lam) * X2\n",
    "        y_mix = lam * y1 + (1 - lam) * y2\n",
    "        return X_mix, y_mix\n",
    "    \n",
    "    @staticmethod\n",
    "    def smote_single(X, y, target_class, n_samples=10, k=5):\n",
    "        \"\"\"Simple SMOTE-like oversampling for single class.\"\"\"\n",
    "        X_class = X[y == target_class]\n",
    "        n_existing = len(X_class)\n",
    "        \n",
    "        synthetic_samples = []\n",
    "        for _ in range(n_samples):\n",
    "            idx = np.random.randint(0, n_existing)\n",
    "            sample = X_class[idx]\n",
    "            \n",
    "            # Find k nearest neighbors\n",
    "            distances = np.linalg.norm(X_class - sample, axis=1)\n",
    "            neighbor_idx = np.argsort(distances)[1:k+1]\n",
    "            neighbor = X_class[np.random.choice(neighbor_idx)]\n",
    "            \n",
    "            # Interpolate\n",
    "            diff = neighbor - sample\n",
    "            synthetic = sample + np.random.random() * diff\n",
    "            synthetic_samples.append(synthetic)\n",
    "        \n",
    "        return np.array(synthetic_samples)\n",
    "\n",
    "print(\"DataAugmenter class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate augmentation\n",
    "X_small, y_small = make_classification(n_samples=100, n_features=10, random_state=42)\n",
    "\n",
    "# Apply augmentations\n",
    "X_noisy = DataAugmenter.add_noise(X_small, noise_level=0.1)\n",
    "X_dropout = DataAugmenter.feature_dropout(X_small, dropout_rate=0.2)\n",
    "\n",
    "# Combine original and augmented\n",
    "X_augmented = np.vstack([X_small, X_noisy, X_dropout])\n",
    "y_augmented = np.concatenate([y_small, y_small, y_small])\n",
    "\n",
    "print(f\"Original size: {len(X_small)}\")\n",
    "print(f\"Augmented size: {len(X_augmented)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentation effects\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].scatter(X_small[:, 0], X_small[:, 1], c=y_small, cmap='coolwarm', alpha=0.7)\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "\n",
    "axes[1].scatter(X_noisy[:, 0], X_noisy[:, 1], c=y_small, cmap='coolwarm', alpha=0.7)\n",
    "axes[1].set_title('With Noise Added')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "\n",
    "axes[2].scatter(X_dropout[:, 0], X_dropout[:, 1], c=y_small, cmap='coolwarm', alpha=0.7)\n",
    "axes[2].set_title('With Feature Dropout')\n",
    "axes[2].set_xlabel('Feature 1')\n",
    "axes[2].set_ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataGenerator:\n",
    "    \"\"\"Generate synthetic data based on existing data patterns.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_distribution(X, n_samples=100):\n",
    "        \"\"\"Generate samples from estimated distribution.\"\"\"\n",
    "        mean = np.mean(X, axis=0)\n",
    "        cov = np.cov(X.T)\n",
    "        return np.random.multivariate_normal(mean, cov, n_samples)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_clusters(X, y, n_samples_per_class=50):\n",
    "        \"\"\"Generate samples around class centroids.\"\"\"\n",
    "        synthetic_X, synthetic_y = [], []\n",
    "        \n",
    "        for c in np.unique(y):\n",
    "            X_class = X[y == c]\n",
    "            mean = np.mean(X_class, axis=0)\n",
    "            std = np.std(X_class, axis=0)\n",
    "            \n",
    "            # Generate around centroid\n",
    "            samples = mean + np.random.randn(n_samples_per_class, len(mean)) * std\n",
    "            synthetic_X.append(samples)\n",
    "            synthetic_y.extend([c] * n_samples_per_class)\n",
    "        \n",
    "        return np.vstack(synthetic_X), np.array(synthetic_y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def bootstrap_sample(X, y, n_samples=None):\n",
    "        \"\"\"Generate bootstrap samples.\"\"\"\n",
    "        if n_samples is None:\n",
    "            n_samples = len(X)\n",
    "        indices = np.random.choice(len(X), n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "print(\"SyntheticDataGenerator class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "X_orig, y_orig = make_classification(n_samples=200, n_features=2, n_redundant=0, \n",
    "                                      n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "X_synthetic, y_synthetic = SyntheticDataGenerator.from_clusters(X_orig, y_orig, n_samples_per_class=100)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].scatter(X_orig[:, 0], X_orig[:, 1], c=y_orig, cmap='coolwarm', alpha=0.7)\n",
    "axes[0].set_title(f'Original Data (n={len(X_orig)})')\n",
    "\n",
    "axes[1].scatter(X_synthetic[:, 0], X_synthetic[:, 1], c=y_synthetic, cmap='coolwarm', alpha=0.7)\n",
    "axes[1].set_title(f'Synthetic Data (n={len(X_synthetic)})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Labeling Approaches\n",
    "\n",
    "| Approach | Description | Quality | Cost |\n",
    "|----------|-------------|---------|------|\n",
    "| **Hand Labeling** | Human annotators | High | High |\n",
    "| **Natural Labels** | Labels from user behavior | Medium | Low |\n",
    "| **Weak Supervision** | Programmatic labeling | Medium | Low |\n",
    "| **Semi-supervised** | Use unlabeled data | Medium | Medium |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Natural Label Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_natural_labels(interactions_df):\n",
    "    \"\"\"\n",
    "    Extract natural labels from user interactions.\n",
    "    \n",
    "    Common patterns:\n",
    "    - Clicks on recommendations -> positive\n",
    "    - Skips -> negative\n",
    "    - Purchases -> strong positive\n",
    "    - Time spent -> engagement level\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in interactions_df.iterrows():\n",
    "        if row['action'] == 'purchase':\n",
    "            label = 2  # Strong positive\n",
    "        elif row['action'] == 'click':\n",
    "            label = 1  # Positive\n",
    "        elif row['action'] == 'skip':\n",
    "            label = 0  # Negative\n",
    "        else:\n",
    "            label = -1  # Unknown\n",
    "        labels.append(label)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Simulate user interaction data\n",
    "np.random.seed(42)\n",
    "n_interactions = 1000\n",
    "\n",
    "interactions = pd.DataFrame({\n",
    "    'user_id': np.random.randint(1, 100, n_interactions),\n",
    "    'item_id': np.random.randint(1, 500, n_interactions),\n",
    "    'action': np.random.choice(['click', 'skip', 'purchase', 'view'], n_interactions, \n",
    "                               p=[0.3, 0.4, 0.1, 0.2]),\n",
    "    'timestamp': pd.date_range('2024-01-01', periods=n_interactions, freq='T')\n",
    "})\n",
    "\n",
    "interactions['label'] = extract_natural_labels(interactions)\n",
    "\n",
    "print(\"Sample Interactions with Natural Labels:\")\n",
    "print(interactions.head(10))\n",
    "print(f\"\\nLabel Distribution:\")\n",
    "print(interactions['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Weak Supervision with Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakSupervisionLabeler:\n",
    "    \"\"\"Apply multiple weak labeling functions and combine.\"\"\"\n",
    "    \n",
    "    def __init__(self, labeling_functions):\n",
    "        self.labeling_functions = labeling_functions\n",
    "    \n",
    "    def apply(self, X):\n",
    "        \"\"\"Apply all labeling functions to data.\"\"\"\n",
    "        labels_matrix = []\n",
    "        for lf in self.labeling_functions:\n",
    "            labels_matrix.append([lf(x) for x in X])\n",
    "        return np.array(labels_matrix).T\n",
    "    \n",
    "    def majority_vote(self, X):\n",
    "        \"\"\"Combine labels using majority voting.\"\"\"\n",
    "        labels_matrix = self.apply(X)\n",
    "        final_labels = []\n",
    "        \n",
    "        for row in labels_matrix:\n",
    "            valid_labels = row[row >= 0]  # Ignore abstentions (-1)\n",
    "            if len(valid_labels) == 0:\n",
    "                final_labels.append(-1)  # No valid labels\n",
    "            else:\n",
    "                # Majority vote\n",
    "                counts = np.bincount(valid_labels.astype(int))\n",
    "                final_labels.append(np.argmax(counts))\n",
    "        \n",
    "        return np.array(final_labels)\n",
    "\n",
    "# Example: Text classification with labeling functions\n",
    "def lf_contains_urgent(text):\n",
    "    \"\"\"Label as positive if contains 'urgent'.\"\"\"\n",
    "    if 'urgent' in text.lower():\n",
    "        return 1\n",
    "    return -1  # Abstain\n",
    "\n",
    "def lf_contains_free(text):\n",
    "    \"\"\"Label as positive if contains 'free'.\"\"\"\n",
    "    if 'free' in text.lower():\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "def lf_contains_meeting(text):\n",
    "    \"\"\"Label as negative if contains 'meeting'.\"\"\"\n",
    "    if 'meeting' in text.lower():\n",
    "        return 0\n",
    "    return -1\n",
    "\n",
    "def lf_short_text(text):\n",
    "    \"\"\"Short texts are often spam.\"\"\"\n",
    "    if len(text) < 20:\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    \"URGENT: You've won a free prize!\",\n",
    "    \"Meeting scheduled for tomorrow at 3pm\",\n",
    "    \"Free money waiting for you\",\n",
    "    \"Can we reschedule our meeting?\",\n",
    "    \"Act now! Limited time offer!\",\n",
    "    \"Quarterly report attached for review\"\n",
    "]\n",
    "\n",
    "labeler = WeakSupervisionLabeler([lf_contains_urgent, lf_contains_free, \n",
    "                                   lf_contains_meeting, lf_short_text])\n",
    "\n",
    "labels_matrix = labeler.apply(texts)\n",
    "final_labels = labeler.majority_vote(texts)\n",
    "\n",
    "print(\"Weak Supervision Results:\")\n",
    "print(f\"Labeling Functions: {len(labeler.labeling_functions)}\")\n",
    "print(\"\\nLabels Matrix (rows=samples, cols=LFs):\")\n",
    "print(labels_matrix)\n",
    "print(f\"\\nFinal Labels (majority vote): {final_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Strategies\n",
    "\n",
    "| Strategy | Description | Use Case |\n",
    "|----------|-------------|----------|\n",
    "| **Random** | Uniform random selection | General purpose |\n",
    "| **Stratified** | Preserve class proportions | Imbalanced classes |\n",
    "| **Importance** | Weight by importance | Rare events |\n",
    "| **Reservoir** | Fixed-size sample from stream | Streaming data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \"\"\"Various sampling strategies.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_sample(X, y, n_samples):\n",
    "        \"\"\"Simple random sampling.\"\"\"\n",
    "        indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def stratified_sample(X, y, n_samples):\n",
    "        \"\"\"Stratified sampling preserving class proportions.\"\"\"\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        proportions = counts / len(y)\n",
    "        \n",
    "        sampled_X, sampled_y = [], []\n",
    "        for c, prop in zip(classes, proportions):\n",
    "            n_class = max(1, int(n_samples * prop))\n",
    "            class_indices = np.where(y == c)[0]\n",
    "            selected = np.random.choice(class_indices, min(n_class, len(class_indices)), replace=False)\n",
    "            sampled_X.append(X[selected])\n",
    "            sampled_y.extend([c] * len(selected))\n",
    "        \n",
    "        return np.vstack(sampled_X), np.array(sampled_y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def importance_sample(X, y, n_samples, weights):\n",
    "        \"\"\"Importance sampling with custom weights.\"\"\"\n",
    "        weights = weights / weights.sum()\n",
    "        indices = np.random.choice(len(X), n_samples, replace=False, p=weights)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def reservoir_sample(stream, k):\n",
    "        \"\"\"Reservoir sampling for streaming data.\"\"\"\n",
    "        reservoir = []\n",
    "        for i, item in enumerate(stream):\n",
    "            if i < k:\n",
    "                reservoir.append(item)\n",
    "            else:\n",
    "                j = np.random.randint(0, i + 1)\n",
    "                if j < k:\n",
    "                    reservoir[j] = item\n",
    "        return reservoir\n",
    "\n",
    "print(\"Sampler class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imbalanced dataset\n",
    "X_imb, y_imb = make_classification(n_samples=1000, n_features=10, n_classes=3,\n",
    "                                    weights=[0.7, 0.2, 0.1], random_state=42)\n",
    "\n",
    "print(\"Original Class Distribution:\")\n",
    "print(pd.Series(y_imb).value_counts())\n",
    "\n",
    "# Compare sampling methods\n",
    "n_samples = 200\n",
    "\n",
    "X_rand, y_rand = Sampler.random_sample(X_imb, y_imb, n_samples)\n",
    "X_strat, y_strat = Sampler.stratified_sample(X_imb, y_imb, n_samples)\n",
    "\n",
    "# Create importance weights (favor minority classes)\n",
    "class_weights = {0: 1, 1: 3, 2: 5}\n",
    "weights = np.array([class_weights[c] for c in y_imb]).astype(float)\n",
    "X_imp, y_imp = Sampler.importance_sample(X_imb, y_imb, n_samples, weights)\n",
    "\n",
    "print(f\"\\nRandom Sampling: {pd.Series(y_rand).value_counts().to_dict()}\")\n",
    "print(f\"Stratified Sampling: {pd.Series(y_strat).value_counts().to_dict()}\")\n",
    "print(f\"Importance Sampling: {pd.Series(y_imp).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sampling results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, (name, y_sampled) in zip(axes.flat, [\n",
    "    ('Original', y_imb),\n",
    "    ('Random', y_rand),\n",
    "    ('Stratified', y_strat),\n",
    "    ('Importance', y_imp)\n",
    "]):\n",
    "    counts = pd.Series(y_sampled).value_counts().sort_index()\n",
    "    ax.bar(counts.index, counts.values, color=['steelblue', 'coral', 'green'])\n",
    "    ax.set_title(f'{name} Sampling (n={len(y_sampled)})')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate reservoir sampling for streaming\n",
    "stream = range(10000)\n",
    "sample_size = 100\n",
    "\n",
    "reservoir = Sampler.reservoir_sample(stream, sample_size)\n",
    "\n",
    "print(f\"Reservoir Sampling Demo:\")\n",
    "print(f\"Stream size: 10000\")\n",
    "print(f\"Sample size: {len(reservoir)}\")\n",
    "print(f\"Sample mean: {np.mean(reservoir):.1f} (expected: ~5000)\")\n",
    "print(f\"Sample std: {np.std(reservoir):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting\n",
    "\n",
    "### Splitting Strategies\n",
    "\n",
    "| Strategy | Description | When to Use |\n",
    "|----------|-------------|-------------|\n",
    "| **Random** | Random assignment | IID data |\n",
    "| **Stratified** | Preserve class ratios | Classification |\n",
    "| **Time-based** | Chronological split | Time series |\n",
    "| **Group-based** | Keep groups together | Grouped data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard train/validation/test split\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# First split: train+val vs test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train vs val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, random_state=42, stratify=y_trainval\n",
    ")  # 0.25 of 0.8 = 0.2\n",
    "\n",
    "print(\"Standard Split (60/20/20):\")\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Validation: {len(X_val)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")\n",
    "print(f\"\\nClass distribution maintained:\")\n",
    "print(f\"Train: {np.bincount(y_train)}\")\n",
    "print(f\"Val: {np.bincount(y_val)}\")\n",
    "print(f\"Test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Time-Based Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_split(X, y, timestamps, train_ratio=0.6, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Split data chronologically.\n",
    "    Training data comes before validation, which comes before test.\n",
    "    \"\"\"\n",
    "    # Sort by timestamp\n",
    "    sorted_indices = np.argsort(timestamps)\n",
    "    X_sorted = X[sorted_indices]\n",
    "    y_sorted = y[sorted_indices]\n",
    "    \n",
    "    n = len(X)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_sorted[:train_end],\n",
    "        'y_train': y_sorted[:train_end],\n",
    "        'X_val': X_sorted[train_end:val_end],\n",
    "        'y_val': y_sorted[train_end:val_end],\n",
    "        'X_test': X_sorted[val_end:],\n",
    "        'y_test': y_sorted[val_end:]\n",
    "    }\n",
    "\n",
    "# Create time-series data\n",
    "n_samples = 1000\n",
    "timestamps = np.array([datetime(2024, 1, 1) + timedelta(hours=i) for i in range(n_samples)])\n",
    "X_ts, y_ts = make_classification(n_samples=n_samples, n_features=10, random_state=42)\n",
    "\n",
    "splits = time_based_split(X_ts, y_ts, timestamps)\n",
    "\n",
    "print(\"Time-Based Split:\")\n",
    "print(f\"Train: {len(splits['X_train'])} samples (earliest data)\")\n",
    "print(f\"Val: {len(splits['X_val'])} samples\")\n",
    "print(f\"Test: {len(splits['X_test'])} samples (most recent data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time-based split\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "train_end = int(n_samples * 0.6)\n",
    "val_end = int(n_samples * 0.8)\n",
    "\n",
    "ax.axvspan(0, train_end, alpha=0.3, color='blue', label='Train')\n",
    "ax.axvspan(train_end, val_end, alpha=0.3, color='orange', label='Validation')\n",
    "ax.axvspan(val_end, n_samples, alpha=0.3, color='green', label='Test')\n",
    "\n",
    "ax.scatter(range(n_samples), y_ts, c=y_ts, cmap='coolwarm', s=10, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Time Index')\n",
    "ax.set_ylabel('Label')\n",
    "ax.set_title('Time-Based Data Split')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Group-Based Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with groups (e.g., user IDs)\n",
    "n_samples = 500\n",
    "n_groups = 50\n",
    "\n",
    "groups = np.random.randint(0, n_groups, n_samples)\n",
    "X_grouped, y_grouped = make_classification(n_samples=n_samples, n_features=10, random_state=42)\n",
    "\n",
    "# Split by groups\n",
    "unique_groups = np.unique(groups)\n",
    "np.random.shuffle(unique_groups)\n",
    "\n",
    "n_train_groups = int(len(unique_groups) * 0.6)\n",
    "n_val_groups = int(len(unique_groups) * 0.2)\n",
    "\n",
    "train_groups = set(unique_groups[:n_train_groups])\n",
    "val_groups = set(unique_groups[n_train_groups:n_train_groups + n_val_groups])\n",
    "test_groups = set(unique_groups[n_train_groups + n_val_groups:])\n",
    "\n",
    "train_mask = np.array([g in train_groups for g in groups])\n",
    "val_mask = np.array([g in val_groups for g in groups])\n",
    "test_mask = np.array([g in test_groups for g in groups])\n",
    "\n",
    "print(\"Group-Based Split:\")\n",
    "print(f\"Train: {train_mask.sum()} samples from {len(train_groups)} groups\")\n",
    "print(f\"Val: {val_mask.sum()} samples from {len(val_groups)} groups\")\n",
    "print(f\"Test: {test_mask.sum()} samples from {len(test_groups)} groups\")\n",
    "print(f\"\\nNo group appears in multiple splits: {len(train_groups & val_groups) == 0 and len(val_groups & test_groups) == 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation\n",
    "\n",
    "Cross-validation provides robust model evaluation by using multiple train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# K-Fold CV\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "kfold_scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skfold_scores = cross_val_score(model, X, y, cv=skfold, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"\\nK-Fold (5 folds):\")\n",
    "print(f\"  Scores: {kfold_scores}\")\n",
    "print(f\"  Mean: {kfold_scores.mean():.4f} (+/- {kfold_scores.std()*2:.4f})\")\n",
    "\n",
    "print(f\"\\nStratified K-Fold (5 folds):\")\n",
    "print(f\"  Scores: {skfold_scores}\")\n",
    "print(f\"  Mean: {skfold_scores.mean():.4f} (+/- {skfold_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross-Validation\n",
    "X_ts = np.random.randn(200, 5)\n",
    "y_ts = (X_ts[:, 0] + np.random.randn(200) * 0.1 > 0).astype(int)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(\"Time Series Cross-Validation:\")\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_ts)):\n",
    "    print(f\"Fold {fold + 1}: Train[0-{train_idx[-1]}], Test[{test_idx[0]}-{test_idx[-1]}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV splits\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "cv_methods = [\n",
    "    ('K-Fold', KFold(n_splits=5, shuffle=True, random_state=42)),\n",
    "    ('Stratified K-Fold', StratifiedKFold(n_splits=5, shuffle=True, random_state=42)),\n",
    "    ('Time Series', TimeSeriesSplit(n_splits=5))\n",
    "]\n",
    "\n",
    "X_viz = np.arange(100).reshape(-1, 1)\n",
    "y_viz = np.array([0]*50 + [1]*50)\n",
    "\n",
    "for ax, (name, cv) in zip(axes, cv_methods):\n",
    "    for fold, (train, test) in enumerate(cv.split(X_viz, y_viz)):\n",
    "        ax.scatter(train, [fold]*len(train), c='blue', marker='s', s=20, alpha=0.5)\n",
    "        ax.scatter(test, [fold]*len(test), c='red', marker='s', s=20, alpha=0.5)\n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('Fold')\n",
    "    ax.set_title(f'{name} Cross-Validation')\n",
    "    ax.set_yticks(range(5))\n",
    "\n",
    "axes[0].scatter([], [], c='blue', marker='s', label='Train')\n",
    "axes[0].scatter([], [], c='red', marker='s', label='Test')\n",
    "axes[0].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group K-Fold\n",
    "X_groups = np.random.randn(100, 5)\n",
    "y_groups = np.random.randint(0, 2, 100)\n",
    "groups = np.repeat(range(20), 5)  # 20 groups, 5 samples each\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "print(\"Group K-Fold Cross-Validation:\")\n",
    "for fold, (train_idx, test_idx) in enumerate(group_kfold.split(X_groups, y_groups, groups)):\n",
    "    train_groups = np.unique(groups[train_idx])\n",
    "    test_groups = np.unique(groups[test_idx])\n",
    "    print(f\"Fold {fold + 1}: {len(train_groups)} train groups, {len(test_groups)} test groups\")\n",
    "    print(f\"         Overlap check: {len(set(train_groups) & set(test_groups))} groups in common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hands-on Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Build a Complete Dataset Construction Pipeline\n",
    "\n",
    "print(\"Exercise: Complete Dataset Construction Pipeline\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Create initial dataset\n",
    "X_initial, y_initial = make_classification(\n",
    "    n_samples=500, n_features=15, n_informative=10,\n",
    "    n_classes=3, weights=[0.5, 0.3, 0.2], random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Step 1: Initial dataset - {len(X_initial)} samples\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(y_initial, return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply augmentation\n",
    "X_aug1 = DataAugmenter.add_noise(X_initial, noise_level=0.05)\n",
    "X_augmented = np.vstack([X_initial, X_aug1])\n",
    "y_augmented = np.concatenate([y_initial, y_initial])\n",
    "\n",
    "print(f\"Step 2: After augmentation - {len(X_augmented)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Stratified sampling\n",
    "X_sampled, y_sampled = Sampler.stratified_sample(X_augmented, y_augmented, n_samples=600)\n",
    "\n",
    "print(f\"Step 3: After stratified sampling - {len(X_sampled)} samples\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(y_sampled, return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create train/val/test splits\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, random_state=42, stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(f\"Step 4: Final splits\")\n",
    "print(f\"  Train: {len(X_train)} samples\")\n",
    "print(f\"  Val: {len(X_val)} samples\")\n",
    "print(f\"  Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Validate with cross-validation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Cross-validation on training set\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Step 5: Cross-validation results\")\n",
    "print(f\"  CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Final evaluation\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "val_acc = accuracy_score(y_val, model.predict(X_val_scaled))\n",
    "test_acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "\n",
    "print(f\"Step 6: Final evaluation\")\n",
    "print(f\"  Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\nPipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Data Collection**: Use active learning for efficient labeling, augmentation for more data\n",
    "2. **Labeling**: Combine multiple approaches - natural labels, weak supervision, hand labeling\n",
    "3. **Sampling**: Choose strategy based on data characteristics and goals\n",
    "4. **Splitting**: Always use appropriate splits for your data type (time-based, group-based)\n",
    "5. **Cross-Validation**: Essential for robust model evaluation\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "| Task | Recommendation |\n",
    "|------|----------------|\n",
    "| Limited budget | Active learning with uncertainty sampling |\n",
    "| Limited data | Data augmentation + synthetic generation |\n",
    "| Imbalanced classes | Stratified sampling + oversampling |\n",
    "| Time series | Time-based splitting + TimeSeriesSplit CV |\n",
    "| Grouped data | Group-based splitting + GroupKFold CV |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
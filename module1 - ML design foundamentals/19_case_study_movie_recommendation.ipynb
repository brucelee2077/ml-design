{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 19: Case Study - Movie Recommendation System\n",
    "\n",
    "## End-to-End ML System Design Using the 7-Step Framework\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Apply the complete 7-step ML system design framework** to build a movie recommendation system\n",
    "2. **Design candidate generation and ranking stages** using the two-tower architecture\n",
    "3. **Implement collaborative filtering, content-based filtering, and hybrid approaches**\n",
    "4. **Handle cold start problems** for new users and new items\n",
    "5. **Design offline and online evaluation strategies** for recommendation quality\n",
    "6. **Create a production-ready deployment architecture** with monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "np.random.seed(42)\n",
    "print('All imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Problem Statement and Requirements\n",
    "\n",
    "## 1.1 Business Context\n",
    "\n",
    "**Scenario**: Design a movie recommendation system for a streaming platform that:\n",
    "1. Increases user engagement (watch time)\n",
    "2. Helps users discover new content\n",
    "3. Reduces churn by keeping users satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequirementsDocument:\n",
    "    def __init__(self):\n",
    "        self.business = {\n",
    "            'primary_objective': 'Maximize user engagement (watch time)',\n",
    "            'secondary': ['Content discovery', 'User retention', 'Catalog coverage']\n",
    "        }\n",
    "        self.scale = {\n",
    "            'users': '100 million',\n",
    "            'items': '50,000 movies',\n",
    "            'qps': '100,000 at peak'\n",
    "        }\n",
    "        self.latency = {'p50': '50ms', 'p99': '200ms'}\n",
    "        \n",
    "    def display(self):\n",
    "        print('REQUIREMENTS SUMMARY')\n",
    "        print('=' * 50)\n",
    "        print(f\"Objective: {self.business['primary_objective']}\")\n",
    "        print(f\"Scale: {self.scale['users']} users, {self.scale['items']}\")\n",
    "        print(f\"Latency: p50={self.latency['p50']}, p99={self.latency['p99']}\")\n",
    "\n",
    "req = RequirementsDocument()\n",
    "req.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Two-Stage Architecture\n",
    "\n",
    "```\n",
    "User Request -> Candidate Generation (50K -> 500) -> Ranking (500 -> 20) -> Results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 4)\n",
    "ax.axis('off')\n",
    "\n",
    "boxes = [\n",
    "    (0.5, 1, 2, 2, 'User\\nRequest', '#3498db'),\n",
    "    (3.5, 0.5, 2.5, 3, 'Candidate\\nGeneration\\n50K->500', '#2ecc71'),\n",
    "    (7, 0.5, 2.5, 3, 'Ranking\\nModel\\n500->20', '#e74c3c'),\n",
    "    (10.5, 1, 1.5, 2, 'Results', '#9b59b6')\n",
    "]\n",
    "\n",
    "for x, y, w, h, label, color in boxes:\n",
    "    rect = plt.Rectangle((x, y), w, h, facecolor=color, alpha=0.3, edgecolor=color, lw=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + w/2, y + h/2, label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "for x1, x2 in [(2.5, 3.5), (6, 7), (9.5, 10.5)]:\n",
    "    ax.annotate('', xy=(x2, 2), xytext=(x1, 2), arrowprops=dict(arrowstyle='->', lw=2))\n",
    "\n",
    "ax.set_title('Two-Stage Recommendation Architecture', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Generation and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataGenerator:\n",
    "    def __init__(self, n_users=5000, n_movies=2000, n_interactions=100000):\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        self.n_interactions = n_interactions\n",
    "        self.genres = ['Action', 'Comedy', 'Drama', 'Horror', 'Sci-Fi', 'Romance', 'Thriller']\n",
    "        \n",
    "    def generate_users(self):\n",
    "        np.random.seed(42)\n",
    "        users = pd.DataFrame({\n",
    "            'user_id': [f'user_{i}' for i in range(self.n_users)],\n",
    "            'age_group': np.random.choice(['18-24', '25-34', '35-44', '45+'], self.n_users),\n",
    "            'country': np.random.choice(['US', 'UK', 'CA', 'DE', 'FR'], self.n_users)\n",
    "        })\n",
    "        users['preferred_genres'] = [list(np.random.choice(self.genres, 2, replace=False)) for _ in range(self.n_users)]\n",
    "        return users\n",
    "    \n",
    "    def generate_movies(self):\n",
    "        np.random.seed(43)\n",
    "        movies = pd.DataFrame({\n",
    "            'movie_id': [f'movie_{i}' for i in range(self.n_movies)],\n",
    "            'title': [f'Movie {i}' for i in range(self.n_movies)],\n",
    "            'year': np.random.randint(1990, 2024, self.n_movies),\n",
    "            'duration': np.random.normal(110, 25, self.n_movies).astype(int).clip(75, 200),\n",
    "            'avg_rating': np.random.beta(6, 4, self.n_movies) * 4 + 1\n",
    "        })\n",
    "        movies['genres'] = [list(np.random.choice(self.genres, np.random.randint(1, 3), replace=False)) for _ in range(self.n_movies)]\n",
    "        return movies\n",
    "    \n",
    "    def generate_interactions(self, users, movies):\n",
    "        np.random.seed(44)\n",
    "        interactions = []\n",
    "        user_prefs = dict(zip(users['user_id'], users['preferred_genres']))\n",
    "        movie_genres = dict(zip(movies['movie_id'], movies['genres']))\n",
    "        \n",
    "        for _ in range(self.n_interactions):\n",
    "            user_id = np.random.choice(users['user_id'])\n",
    "            prefs = user_prefs[user_id]\n",
    "            \n",
    "            # Prefer movies matching user preferences\n",
    "            if np.random.random() < 0.7:\n",
    "                matching = [m for m, g in movie_genres.items() if any(x in prefs for x in g)]\n",
    "                movie_id = np.random.choice(matching) if matching else np.random.choice(movies['movie_id'])\n",
    "            else:\n",
    "                movie_id = np.random.choice(movies['movie_id'])\n",
    "            \n",
    "            watch_pct = np.clip(np.random.beta(5, 3), 0, 1)\n",
    "            rating = round(np.clip(np.random.normal(3.5 + watch_pct, 0.8), 1, 5), 1) if np.random.random() < 0.3 else None\n",
    "            \n",
    "            interactions.append({\n",
    "                'user_id': user_id,\n",
    "                'movie_id': movie_id,\n",
    "                'timestamp': pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 365)),\n",
    "                'watch_pct': round(watch_pct * 100, 1),\n",
    "                'rating': rating,\n",
    "                'completed': watch_pct >= 0.9\n",
    "            })\n",
    "        return pd.DataFrame(interactions)\n",
    "    \n",
    "    def generate_all(self):\n",
    "        users = self.generate_users()\n",
    "        movies = self.generate_movies()\n",
    "        interactions = self.generate_interactions(users, movies)\n",
    "        print(f'Generated: {len(users)} users, {len(movies)} movies, {len(interactions)} interactions')\n",
    "        return users, movies, interactions\n",
    "\n",
    "gen = MovieDataGenerator()\n",
    "users_df, movies_df, interactions_df = gen.generate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Users:')\n",
    "print(users_df.head())\n",
    "print('\\nMovies:')\n",
    "print(movies_df[['movie_id', 'title', 'year', 'genres']].head())\n",
    "print('\\nInteractions:')\n",
    "print(interactions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Ratings\n",
    "ratings = interactions_df[interactions_df['rating'].notna()]['rating']\n",
    "axes[0, 0].hist(ratings, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Rating Distribution')\n",
    "\n",
    "# Watch percentage\n",
    "axes[0, 1].hist(interactions_df['watch_pct'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Watch Percentage Distribution')\n",
    "\n",
    "# User activity\n",
    "user_counts = interactions_df['user_id'].value_counts()\n",
    "axes[1, 0].hist(user_counts, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Interactions per User')\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Movie popularity\n",
    "movie_counts = interactions_df['movie_id'].value_counts()\n",
    "axes[1, 1].hist(movie_counts, bins=50, edgecolor='black', alpha=0.7, color='red')\n",
    "axes[1, 1].set_title('Movie Popularity (Long Tail)')\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sparsity = 1 - len(interactions_df) / (5000 * 2000)\n",
    "print(f'Matrix sparsity: {sparsity:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User features\n",
    "user_stats = interactions_df.groupby('user_id').agg({\n",
    "    'movie_id': 'count',\n",
    "    'rating': 'mean',\n",
    "    'watch_pct': 'mean',\n",
    "    'completed': 'mean'\n",
    "}).reset_index()\n",
    "user_stats.columns = ['user_id', 'total_watches', 'avg_rating', 'avg_watch_pct', 'completion_rate']\n",
    "user_features = users_df.merge(user_stats, on='user_id', how='left').fillna(0)\n",
    "\n",
    "# Movie features\n",
    "movie_stats = interactions_df.groupby('movie_id').agg({\n",
    "    'user_id': 'count',\n",
    "    'rating': 'mean',\n",
    "    'watch_pct': 'mean',\n",
    "    'completed': 'mean'\n",
    "}).reset_index()\n",
    "movie_stats.columns = ['movie_id', 'total_views', 'actual_rating', 'avg_watch_pct', 'completion_rate']\n",
    "movie_stats['popularity'] = np.log1p(movie_stats['total_views'])\n",
    "movie_features = movies_df.merge(movie_stats, on='movie_id', how='left').fillna(0)\n",
    "\n",
    "# Genre matrix\n",
    "all_genres = sorted(set(g for genres in movies_df['genres'] for g in genres))\n",
    "genre_matrix = np.zeros((len(movies_df), len(all_genres)))\n",
    "for i, genres in enumerate(movies_df['genres']):\n",
    "    for g in genres:\n",
    "        genre_matrix[i, all_genres.index(g)] = 1\n",
    "genre_df = pd.DataFrame(genre_matrix, columns=[f'genre_{g}' for g in all_genres])\n",
    "\n",
    "print(f'User features: {user_features.shape}')\n",
    "print(f'Movie features: {movie_features.shape}')\n",
    "print(f'Genre matrix: {genre_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "interactions_sorted = interactions_df.sort_values('timestamp')\n",
    "split_idx = int(len(interactions_sorted) * 0.8)\n",
    "train_df = interactions_sorted.iloc[:split_idx]\n",
    "test_df = interactions_sorted.iloc[split_idx:]\n",
    "\n",
    "print(f'Train: {len(train_df):,} ({train_df[\"timestamp\"].min().date()} to {train_df[\"timestamp\"].max().date()})')\n",
    "print(f'Test: {len(test_df):,} ({test_df[\"timestamp\"].min().date()} to {test_df[\"timestamp\"].max().date()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Model Development\n",
    "\n",
    "## 3.1 Collaborative Filtering (Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "    def __init__(self, n_factors=50):\n",
    "        self.n_factors = n_factors\n",
    "        self.user_factors = None\n",
    "        self.item_factors = None\n",
    "        self.user_to_idx = {}\n",
    "        self.movie_to_idx = {}\n",
    "        self.idx_to_movie = {}\n",
    "        \n",
    "    def fit(self, interactions):\n",
    "        print('Training Collaborative Filtering...')\n",
    "        users = interactions['user_id'].unique()\n",
    "        movies = interactions['movie_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {u: i for i, u in enumerate(users)}\n",
    "        self.movie_to_idx = {m: i for i, m in enumerate(movies)}\n",
    "        self.idx_to_movie = {i: m for m, i in self.movie_to_idx.items()}\n",
    "        \n",
    "        rows, cols, data = [], [], []\n",
    "        for _, row in interactions.iterrows():\n",
    "            rows.append(self.user_to_idx[row['user_id']])\n",
    "            cols.append(self.movie_to_idx[row['movie_id']])\n",
    "            data.append(row['watch_pct'] / 100)\n",
    "        \n",
    "        matrix = csr_matrix((data, (rows, cols)), shape=(len(users), len(movies)))\n",
    "        n_factors = min(self.n_factors, min(matrix.shape) - 1)\n",
    "        U, sigma, Vt = svds(matrix, k=n_factors)\n",
    "        \n",
    "        self.user_factors = U * np.sqrt(sigma)\n",
    "        self.item_factors = Vt.T * np.sqrt(sigma)\n",
    "        print(f'  Trained: {self.user_factors.shape[0]} users, {self.item_factors.shape[0]} movies')\n",
    "        \n",
    "    def recommend(self, user_id, n=10, exclude=None):\n",
    "        if user_id not in self.user_to_idx:\n",
    "            return []\n",
    "        user_idx = self.user_to_idx[user_id]\n",
    "        scores = self.user_factors[user_idx] @ self.item_factors.T\n",
    "        \n",
    "        if exclude:\n",
    "            for m in exclude:\n",
    "                if m in self.movie_to_idx:\n",
    "                    scores[self.movie_to_idx[m]] = -np.inf\n",
    "        \n",
    "        top_idx = np.argsort(scores)[::-1][:n]\n",
    "        return [(self.idx_to_movie[i], scores[i]) for i in top_idx]\n",
    "    \n",
    "    def similar_items(self, movie_id, n=10):\n",
    "        if movie_id not in self.movie_to_idx:\n",
    "            return []\n",
    "        idx = self.movie_to_idx[movie_id]\n",
    "        sims = cosine_similarity([self.item_factors[idx]], self.item_factors)[0]\n",
    "        top_idx = np.argsort(sims)[::-1][1:n+1]\n",
    "        return [(self.idx_to_movie[i], sims[i]) for i in top_idx]\n",
    "\n",
    "cf_model = CollaborativeFiltering(n_factors=50)\n",
    "cf_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CF model\n",
    "test_user = train_df['user_id'].iloc[0]\n",
    "watched = set(train_df[train_df['user_id'] == test_user]['movie_id'])\n",
    "\n",
    "print(f'Recommendations for {test_user}:')\n",
    "for movie_id, score in cf_model.recommend(test_user, n=5, exclude=watched):\n",
    "    title = movies_df[movies_df['movie_id'] == movie_id]['title'].values[0]\n",
    "    print(f'  {title}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedFiltering:\n",
    "    def __init__(self):\n",
    "        self.movie_vectors = None\n",
    "        self.movie_ids = None\n",
    "        self.movie_to_idx = {}\n",
    "        \n",
    "    def fit(self, movies, genre_matrix):\n",
    "        print('Building content-based model...')\n",
    "        self.movie_ids = movies['movie_id'].values\n",
    "        self.movie_to_idx = {m: i for i, m in enumerate(self.movie_ids)}\n",
    "        \n",
    "        year_norm = (movies['year'] - movies['year'].min()) / (movies['year'].max() - movies['year'].min())\n",
    "        dur_norm = (movies['duration'] - movies['duration'].min()) / (movies['duration'].max() - movies['duration'].min())\n",
    "        \n",
    "        self.movie_vectors = np.hstack([genre_matrix.values, year_norm.values.reshape(-1, 1), dur_norm.values.reshape(-1, 1)])\n",
    "        print(f'  Content vectors: {self.movie_vectors.shape}')\n",
    "    \n",
    "    def similar_items(self, movie_id, n=10):\n",
    "        if movie_id not in self.movie_to_idx:\n",
    "            return []\n",
    "        idx = self.movie_to_idx[movie_id]\n",
    "        sims = cosine_similarity([self.movie_vectors[idx]], self.movie_vectors)[0]\n",
    "        top_idx = np.argsort(sims)[::-1][1:n+1]\n",
    "        return [(self.movie_ids[i], sims[i]) for i in top_idx]\n",
    "    \n",
    "    def recommend_for_user(self, history, n=10):\n",
    "        if not history:\n",
    "            return []\n",
    "        user_vec = np.mean([self.movie_vectors[self.movie_to_idx[m]] for m in history if m in self.movie_to_idx], axis=0)\n",
    "        sims = cosine_similarity([user_vec], self.movie_vectors)[0]\n",
    "        for m in history:\n",
    "            if m in self.movie_to_idx:\n",
    "                sims[self.movie_to_idx[m]] = -1\n",
    "        top_idx = np.argsort(sims)[::-1][:n]\n",
    "        return [(self.movie_ids[i], sims[i]) for i in top_idx]\n",
    "\n",
    "cb_model = ContentBasedFiltering()\n",
    "cb_model.fit(movies_df, genre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CB model\n",
    "print('Similar movies to movie_0:')\n",
    "for movie_id, sim in cb_model.similar_items('movie_0', n=5):\n",
    "    info = movies_df[movies_df['movie_id'] == movie_id].iloc[0]\n",
    "    print(f'  {info[\"title\"]} ({info[\"year\"]}) - {info[\"genres\"]}: {sim:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, cf, cb, cf_weight=0.7):\n",
    "        self.cf = cf\n",
    "        self.cb = cb\n",
    "        self.cf_weight = cf_weight\n",
    "        \n",
    "    def recommend(self, user_id, history, n=10):\n",
    "        cf_recs = dict(self.cf.recommend(user_id, n=n*2, exclude=history))\n",
    "        cb_recs = dict(self.cb.recommend_for_user(history, n=n*2))\n",
    "        \n",
    "        # Normalize\n",
    "        if cf_recs:\n",
    "            cf_min, cf_max = min(cf_recs.values()), max(cf_recs.values())\n",
    "            cf_range = cf_max - cf_min if cf_max != cf_min else 1\n",
    "            cf_recs = {k: (v - cf_min) / cf_range for k, v in cf_recs.items()}\n",
    "        if cb_recs:\n",
    "            cb_min, cb_max = min(cb_recs.values()), max(cb_recs.values())\n",
    "            cb_range = cb_max - cb_min if cb_max != cb_min else 1\n",
    "            cb_recs = {k: (v - cb_min) / cb_range for k, v in cb_recs.items()}\n",
    "        \n",
    "        # Combine\n",
    "        combined = {}\n",
    "        for m in set(cf_recs) | set(cb_recs):\n",
    "            combined[m] = self.cf_weight * cf_recs.get(m, 0) + (1 - self.cf_weight) * cb_recs.get(m, 0)\n",
    "        \n",
    "        return sorted(combined.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "hybrid = HybridRecommender(cf_model, cb_model)\n",
    "\n",
    "history = list(train_df[train_df['user_id'] == test_user]['movie_id'].unique()[:10])\n",
    "print(f'Hybrid recommendations for {test_user}:')\n",
    "for movie_id, score in hybrid.recommend(test_user, history, n=5):\n",
    "    title = movies_df[movies_df['movie_id'] == movie_id]['title'].values[0]\n",
    "    print(f'  {title}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Two-Tower Model (Neural Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel:\n",
    "    def __init__(self, embedding_dim=32):\n",
    "        self.dim = embedding_dim\n",
    "        self.user_emb = None\n",
    "        self.item_emb = None\n",
    "        self.user_to_idx = {}\n",
    "        self.item_to_idx = {}\n",
    "        self.idx_to_item = {}\n",
    "        \n",
    "    def fit(self, interactions, epochs=10, lr=0.01):\n",
    "        print('Training Two-Tower Model...')\n",
    "        users = interactions['user_id'].unique()\n",
    "        items = interactions['movie_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {u: i for i, u in enumerate(users)}\n",
    "        self.item_to_idx = {m: i for i, m in enumerate(items)}\n",
    "        self.idx_to_item = {i: m for m, i in self.item_to_idx.items()}\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.user_emb = np.random.randn(len(users), self.dim) * 0.1\n",
    "        self.item_emb = np.random.randn(len(items), self.dim) * 0.1\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            loss = 0\n",
    "            for _, row in interactions.sample(min(10000, len(interactions))).iterrows():\n",
    "                u_idx = self.user_to_idx[row['user_id']]\n",
    "                i_idx = self.item_to_idx[row['movie_id']]\n",
    "                label = row['watch_pct'] / 100\n",
    "                \n",
    "                pred = 1 / (1 + np.exp(-np.dot(self.user_emb[u_idx], self.item_emb[i_idx])))\n",
    "                error = pred - label\n",
    "                loss += error ** 2\n",
    "                \n",
    "                self.user_emb[u_idx] -= lr * error * self.item_emb[i_idx]\n",
    "                self.item_emb[i_idx] -= lr * error * self.user_emb[u_idx]\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print(f'  Epoch {epoch + 1}, Loss: {loss:.2f}')\n",
    "        \n",
    "    def get_candidates(self, user_id, n=100):\n",
    "        if user_id not in self.user_to_idx:\n",
    "            return []\n",
    "        scores = np.dot(self.item_emb, self.user_emb[self.user_to_idx[user_id]])\n",
    "        top_idx = np.argsort(scores)[::-1][:n]\n",
    "        return [(self.idx_to_item[i], scores[i]) for i in top_idx]\n",
    "\n",
    "two_tower = TwoTowerModel(embedding_dim=32)\n",
    "two_tower.fit(train_df, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Evaluation Strategy\n",
    "\n",
    "## 4.1 Offline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationEvaluator:\n",
    "    @staticmethod\n",
    "    def precision_at_k(recommended, relevant, k):\n",
    "        return len(set(recommended[:k]) & set(relevant)) / k if k > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall_at_k(recommended, relevant, k):\n",
    "        return len(set(recommended[:k]) & set(relevant)) / len(relevant) if relevant else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def ndcg_at_k(recommended, relevant, k):\n",
    "        rel_set = set(relevant)\n",
    "        dcg = sum(1 / np.log2(i + 2) if recommended[i] in rel_set else 0 for i in range(min(k, len(recommended))))\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(k, len(rel_set))))\n",
    "        return dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def mrr(recommended, relevant):\n",
    "        rel_set = set(relevant)\n",
    "        for i, item in enumerate(recommended):\n",
    "            if item in rel_set:\n",
    "                return 1 / (i + 1)\n",
    "        return 0\n",
    "\n",
    "evaluator = RecommendationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_df, train_df, k_values=[5, 10, 20]):\n",
    "    results = {k: {'prec': [], 'recall': [], 'ndcg': []} for k in k_values}\n",
    "    test_users = test_df.groupby('user_id').filter(lambda x: len(x) >= 3)['user_id'].unique()\n",
    "    sample_users = np.random.choice(test_users, min(300, len(test_users)), replace=False)\n",
    "    \n",
    "    for user_id in sample_users:\n",
    "        train_history = set(train_df[train_df['user_id'] == user_id]['movie_id'])\n",
    "        relevant = test_df[(test_df['user_id'] == user_id) & (test_df['watch_pct'] >= 70)]['movie_id'].tolist()\n",
    "        \n",
    "        if not relevant:\n",
    "            continue\n",
    "            \n",
    "        recs = model.recommend(user_id, n=max(k_values), exclude=train_history) if hasattr(model, 'recommend') else model.get_candidates(user_id, max(k_values))\n",
    "        recommended = [r[0] for r in recs]\n",
    "        \n",
    "        for k in k_values:\n",
    "            results[k]['prec'].append(evaluator.precision_at_k(recommended, relevant, k))\n",
    "            results[k]['recall'].append(evaluator.recall_at_k(recommended, relevant, k))\n",
    "            results[k]['ndcg'].append(evaluator.ndcg_at_k(recommended, relevant, k))\n",
    "    \n",
    "    return {k: {m: np.mean(v) for m, v in metrics.items()} for k, metrics in results.items()}\n",
    "\n",
    "print('Evaluating CF Model...')\n",
    "cf_results = evaluate_model(cf_model, test_df, train_df)\n",
    "print('\\nResults:')\n",
    "for k, metrics in cf_results.items():\n",
    "    print(f'  @{k}: Prec={metrics[\"prec\"]:.4f}, Recall={metrics[\"recall\"]:.4f}, NDCG={metrics[\"ndcg\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "models = {\n",
    "    'Collaborative Filtering': cf_model,\n",
    "    'Two-Tower': two_tower\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'Evaluating {name}...')\n",
    "    all_results[name] = evaluate_model(model, test_df, train_df)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "k_values = [5, 10, 20]\n",
    "metrics = ['prec', 'recall', 'ndcg']\n",
    "titles = ['Precision@K', 'Recall@K', 'NDCG@K']\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics, titles):\n",
    "    for name, results in all_results.items():\n",
    "        values = [results[k][metric] for k in k_values]\n",
    "        ax.plot(k_values, values, marker='o', label=name)\n",
    "    ax.set_xlabel('K')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Online Evaluation (A/B Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABTestSimulator:\n",
    "    def __init__(self, control_ctr=0.05, treatment_effect=0.1):\n",
    "        self.control_ctr = control_ctr\n",
    "        self.treatment_ctr = control_ctr * (1 + treatment_effect)\n",
    "        \n",
    "    def simulate(self, n_users=10000, n_days=14):\n",
    "        np.random.seed(42)\n",
    "        results = []\n",
    "        \n",
    "        for day in range(n_days):\n",
    "            for _ in range(n_users // n_days):\n",
    "                group = np.random.choice(['control', 'treatment'])\n",
    "                ctr = self.control_ctr if group == 'control' else self.treatment_ctr\n",
    "                clicked = np.random.random() < ctr\n",
    "                results.append({'day': day, 'group': group, 'clicked': clicked})\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def analyze(self, results):\n",
    "        control = results[results['group'] == 'control']['clicked']\n",
    "        treatment = results[results['group'] == 'treatment']['clicked']\n",
    "        \n",
    "        control_ctr = control.mean()\n",
    "        treatment_ctr = treatment.mean()\n",
    "        lift = (treatment_ctr - control_ctr) / control_ctr * 100\n",
    "        \n",
    "        # Z-test\n",
    "        n_c, n_t = len(control), len(treatment)\n",
    "        p_pooled = (control.sum() + treatment.sum()) / (n_c + n_t)\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_c + 1/n_t))\n",
    "        z = (treatment_ctr - control_ctr) / se if se > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'control_ctr': control_ctr,\n",
    "            'treatment_ctr': treatment_ctr,\n",
    "            'lift': lift,\n",
    "            'z_score': z,\n",
    "            'significant': abs(z) > 1.96\n",
    "        }\n",
    "\n",
    "ab_sim = ABTestSimulator(control_ctr=0.05, treatment_effect=0.10)\n",
    "ab_results = ab_sim.simulate()\n",
    "analysis = ab_sim.analyze(ab_results)\n",
    "\n",
    "print('A/B Test Results:')\n",
    "print(f'  Control CTR: {analysis[\"control_ctr\"]:.4f}')\n",
    "print(f'  Treatment CTR: {analysis[\"treatment_ctr\"]:.4f}')\n",
    "print(f'  Lift: {analysis[\"lift\"]:.2f}%')\n",
    "print(f'  Z-score: {analysis[\"z_score\"]:.2f}')\n",
    "print(f'  Significant (p<0.05): {analysis[\"significant\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Deployment Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationService:\n",
    "    \"\"\"Production recommendation service.\"\"\"\n",
    "    \n",
    "    def __init__(self, cf_model, cb_model, two_tower, popular_items):\n",
    "        self.cf = cf_model\n",
    "        self.cb = cb_model\n",
    "        self.retrieval = two_tower\n",
    "        self.popular = popular_items\n",
    "        \n",
    "    def get_recommendations(self, user_id, history, context=None, n=20):\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        # Cold start handling\n",
    "        if user_id not in self.cf.user_to_idx:\n",
    "            recs = self.popular[:n]\n",
    "            source = 'popularity'\n",
    "        else:\n",
    "            # Stage 1: Candidate generation\n",
    "            candidates = self.retrieval.get_candidates(user_id, n=100)\n",
    "            candidate_ids = [c[0] for c in candidates if c[0] not in history]\n",
    "            \n",
    "            # Stage 2: Rerank with hybrid\n",
    "            cf_scores = dict(self.cf.recommend(user_id, n=100, exclude=history))\n",
    "            \n",
    "            final_scores = []\n",
    "            for cid in candidate_ids[:50]:\n",
    "                score = cf_scores.get(cid, 0)\n",
    "                final_scores.append((cid, score))\n",
    "            \n",
    "            recs = sorted(final_scores, key=lambda x: x[1], reverse=True)[:n]\n",
    "            source = 'hybrid'\n",
    "        \n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'recommendations': [{'item_id': r[0], 'score': float(r[1]) if isinstance(r, tuple) else 0} for r in recs],\n",
    "            'source': source,\n",
    "            'latency_ms': round(latency, 2)\n",
    "        }\n",
    "\n",
    "# Create service\n",
    "popular_items = movie_features.nlargest(100, 'popularity')['movie_id'].tolist()\n",
    "service = RecommendationService(cf_model, cb_model, two_tower, popular_items)\n",
    "\n",
    "# Test service\n",
    "response = service.get_recommendations(test_user, history)\n",
    "print(f'Response for {response[\"user_id\"]}:')\n",
    "print(f'  Source: {response[\"source\"]}')\n",
    "print(f'  Latency: {response[\"latency_ms\"]}ms')\n",
    "print(f'  Top 5 recommendations:')\n",
    "for rec in response['recommendations'][:5]:\n",
    "    title = movies_df[movies_df['movie_id'] == rec['item_id']]['title'].values[0]\n",
    "    print(f'    {title}: {rec[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System architecture diagram\n",
    "print(\"\"\"\n",
    "Production Recommendation System Architecture\n",
    "============================================\n",
    "\n",
    "                    ┌─────────────────┐\n",
    "                    │   API Gateway   │\n",
    "                    │   (Load Balancer)│\n",
    "                    └────────┬────────┘\n",
    "                             │\n",
    "                    ┌────────▼────────┐\n",
    "                    │  Recommendation │\n",
    "                    │     Service     │\n",
    "                    └────────┬────────┘\n",
    "                             │\n",
    "        ┌────────────────────┼────────────────────┐\n",
    "        │                    │                    │\n",
    "┌───────▼───────┐   ┌───────▼───────┐   ┌───────▼───────┐\n",
    "│   Candidate   │   │    Ranking    │   │   Feature     │\n",
    "│   Generation  │   │    Service    │   │    Store      │\n",
    "│  (Two-Tower)  │   │   (XGBoost)   │   │   (Redis)     │\n",
    "└───────────────┘   └───────────────┘   └───────────────┘\n",
    "        │                    │                    │\n",
    "        └────────────────────┼────────────────────┘\n",
    "                             │\n",
    "                    ┌────────▼────────┐\n",
    "                    │   Model Store   │\n",
    "                    │   (S3/GCS)      │\n",
    "                    └─────────────────┘\n",
    "\n",
    "Data Pipeline:\n",
    "User Events → Kafka → Spark → Feature Store → Model Training → Model Store\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Monitoring and Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationMonitor:\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "        \n",
    "    def log_request(self, user_id, latency_ms, source, n_recs):\n",
    "        self.metrics.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'user_id': user_id,\n",
    "            'latency_ms': latency_ms,\n",
    "            'source': source,\n",
    "            'n_recs': n_recs\n",
    "        })\n",
    "    \n",
    "    def get_summary(self):\n",
    "        if not self.metrics:\n",
    "            return {}\n",
    "        df = pd.DataFrame(self.metrics)\n",
    "        return {\n",
    "            'total_requests': len(df),\n",
    "            'latency_p50': df['latency_ms'].quantile(0.5),\n",
    "            'latency_p99': df['latency_ms'].quantile(0.99),\n",
    "            'source_distribution': df['source'].value_counts().to_dict()\n",
    "        }\n",
    "\n",
    "# Simulate monitoring\n",
    "monitor = RecommendationMonitor()\n",
    "\n",
    "# Simulate requests\n",
    "sample_users = np.random.choice(users_df['user_id'], 100)\n",
    "for user_id in sample_users:\n",
    "    hist = list(train_df[train_df['user_id'] == user_id]['movie_id'].unique()[:5])\n",
    "    response = service.get_recommendations(user_id, hist)\n",
    "    monitor.log_request(user_id, response['latency_ms'], response['source'], len(response['recommendations']))\n",
    "\n",
    "summary = monitor.get_summary()\n",
    "print('Monitoring Summary:')\n",
    "print(f'  Total Requests: {summary[\"total_requests\"]}')\n",
    "print(f'  Latency P50: {summary[\"latency_p50\"]:.2f}ms')\n",
    "print(f'  Latency P99: {summary[\"latency_p99\"]:.2f}ms')\n",
    "print(f'  Source Distribution: {summary[\"source_distribution\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage and diversity metrics\n",
    "def calculate_coverage(recommendations_list, total_items):\n",
    "    unique_items = set()\n",
    "    for recs in recommendations_list:\n",
    "        unique_items.update([r['item_id'] for r in recs])\n",
    "    return len(unique_items) / total_items\n",
    "\n",
    "# Collect recommendations for analysis\n",
    "all_recs = []\n",
    "for user_id in np.random.choice(users_df['user_id'], 500):\n",
    "    hist = list(train_df[train_df['user_id'] == user_id]['movie_id'].unique()[:5])\n",
    "    response = service.get_recommendations(user_id, hist)\n",
    "    all_recs.append(response['recommendations'])\n",
    "\n",
    "coverage = calculate_coverage(all_recs, len(movies_df))\n",
    "print(f'Catalog Coverage: {coverage:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Requirements**: Clearly define business objectives, scale, and latency requirements\n",
    "2. **Two-Stage Architecture**: Candidate generation (fast, broad) + Ranking (precise, personalized)\n",
    "3. **Multiple Approaches**: Collaborative filtering, content-based, and hybrid methods\n",
    "4. **Cold Start**: Handle new users with popularity-based recommendations\n",
    "5. **Evaluation**: Use ranking metrics (Precision@K, NDCG) offline, CTR/engagement online\n",
    "6. **Monitoring**: Track latency, coverage, diversity, and model freshness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "7-Step Framework Applied to Movie Recommendations\n",
    "=================================================\n",
    "\n",
    "Step 1: Requirements\n",
    "  - Primary: Maximize watch time\n",
    "  - Scale: 100M users, 50K items, 100K QPS\n",
    "  - Latency: p50 < 50ms, p99 < 200ms\n",
    "\n",
    "Step 2: Problem Framing\n",
    "  - Stage 1: Retrieval (representation learning)\n",
    "  - Stage 2: Ranking (pointwise classification)\n",
    "  - Labels: Implicit (watch %) + Explicit (ratings)\n",
    "\n",
    "Step 3: Data Preparation\n",
    "  - User features: demographics, behavior stats\n",
    "  - Item features: metadata, popularity, genres\n",
    "  - Interaction features: time, device, context\n",
    "\n",
    "Step 4: Model Development\n",
    "  - Collaborative Filtering (SVD)\n",
    "  - Content-Based (TF-IDF similarity)\n",
    "  - Two-Tower Neural Network\n",
    "  - Hybrid ensemble\n",
    "\n",
    "Step 5: Evaluation\n",
    "  - Offline: Precision@K, Recall@K, NDCG\n",
    "  - Online: A/B testing, CTR, watch time\n",
    "\n",
    "Step 6: Deployment\n",
    "  - Microservices architecture\n",
    "  - Feature store for real-time features\n",
    "  - Model versioning and rollback\n",
    "\n",
    "Step 7: Monitoring\n",
    "  - Latency tracking\n",
    "  - Coverage and diversity\n",
    "  - Model freshness alerts\n",
    "\"\"\")\n",
    "\n",
    "print('Tutorial 19 Complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
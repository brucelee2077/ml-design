{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 20: Case Study - Content Moderation System\n",
    "\n",
    "## End-to-End ML System Design for Harmful Content Detection\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. **Design a multi-modal content moderation system** handling text and images\n",
    "2. **Apply the 7-step ML framework** to safety-critical systems\n",
    "3. **Implement text toxicity classifiers**\n",
    "4. **Balance precision and recall** for user safety vs over-moderation\n",
    "5. **Design low-latency serving** for real-time moderation\n",
    "6. **Build monitoring systems** for false positives/negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import re\n",
    "\n",
    "np.random.seed(42)\n",
    "print('All imports successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Problem Statement and Requirements\n",
    "\n",
    "## 1.1 Business Context\n",
    "\n",
    "**Scenario**: Design a content moderation system for a social media platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModerationRequirements:\n",
    "    def __init__(self):\n",
    "        self.categories = {\n",
    "            'hate_speech': 'Content attacking protected groups',\n",
    "            'harassment': 'Targeted abuse or bullying',\n",
    "            'spam': 'Unsolicited commercial content',\n",
    "            'violence': 'Graphic violence or threats',\n",
    "            'safe': 'Content that does not violate policies'\n",
    "        }\n",
    "        self.scale = {'posts_per_day': '500M', 'qps_peak': '50K'}\n",
    "        self.latency = {'p99': '100ms'}\n",
    "        self.accuracy = {'precision_target': 0.90, 'recall_target': 0.95}\n",
    "        \n",
    "    def display(self):\n",
    "        print('CONTENT MODERATION REQUIREMENTS')\n",
    "        print('=' * 50)\n",
    "        print('Categories:', list(self.categories.keys()))\n",
    "        print('Scale:', self.scale)\n",
    "        print('Latency:', self.latency)\n",
    "        print('Accuracy targets:', self.accuracy)\n",
    "\n",
    "req = ModerationRequirements()\n",
    "req.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 System Architecture\n",
    "\n",
    "```\n",
    "Content -> Pre-filter -> ML Models -> Decision Engine -> Action\n",
    "                              |              |\n",
    "                              v              v\n",
    "                         [Text Model]   [Threshold]\n",
    "                         [Image Model]  [Ensemble]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 4)\n",
    "ax.axis('off')\n",
    "\n",
    "boxes = [\n",
    "    (0.5, 1, 1.5, 2, 'Content', '#3498db'),\n",
    "    (2.5, 1, 2, 2, 'Pre-filter', '#95a5a6'),\n",
    "    (5, 0.5, 2, 3, 'ML Models', '#2ecc71'),\n",
    "    (7.5, 0.5, 2, 3, 'Decision\\nEngine', '#e74c3c'),\n",
    "    (10, 1, 1.5, 2, 'Action', '#9b59b6')\n",
    "]\n",
    "\n",
    "for x, y, w, h, label, color in boxes:\n",
    "    rect = plt.Rectangle((x, y), w, h, facecolor=color, alpha=0.3, edgecolor=color, lw=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + w/2, y + h/2, label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "for x1, x2 in [(2, 2.5), (4.5, 5), (7, 7.5), (9.5, 10)]:\n",
    "    ax.annotate('', xy=(x2, 2), xytext=(x1, 2), arrowprops=dict(arrowstyle='->', lw=2))\n",
    "\n",
    "ax.set_title('Content Moderation Architecture', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentDataGenerator:\n",
    "    def __init__(self, n_samples=30000):\n",
    "        self.n_samples = n_samples\n",
    "        self.categories = ['safe', 'hate_speech', 'harassment', 'spam', 'violence']\n",
    "        self.templates = {\n",
    "            'safe': [\n",
    "                'I love this beautiful day',\n",
    "                'Great meal at the restaurant',\n",
    "                'Happy birthday to you',\n",
    "                'The weather is perfect today',\n",
    "                'Congratulations on your success'\n",
    "            ],\n",
    "            'hate_speech': [\n",
    "                'Those people from X are terrible',\n",
    "                'Group Y should not exist',\n",
    "                'I hate everyone who believes Z'\n",
    "            ],\n",
    "            'harassment': [\n",
    "                'You are so stupid person',\n",
    "                'Nobody likes you loser',\n",
    "                'You should be ashamed'\n",
    "            ],\n",
    "            'spam': [\n",
    "                'CLICK HERE for FREE money',\n",
    "                'Buy followers at low prices',\n",
    "                'Make money from home easy'\n",
    "            ],\n",
    "            'violence': [\n",
    "                'I want to hurt people',\n",
    "                'Someone should attack them',\n",
    "                'Violence is the solution'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def augment(self, text):\n",
    "        variations = [text, text.upper(), text.lower(), text + '!!!']\n",
    "        return np.random.choice(variations)\n",
    "    \n",
    "    def generate(self):\n",
    "        np.random.seed(42)\n",
    "        probs = [0.85, 0.04, 0.04, 0.04, 0.03]\n",
    "        \n",
    "        data = []\n",
    "        for i in range(self.n_samples):\n",
    "            cat = np.random.choice(self.categories, p=probs)\n",
    "            text = self.augment(np.random.choice(self.templates[cat]))\n",
    "            data.append({\n",
    "                'content_id': f'post_{i}',\n",
    "                'text': text,\n",
    "                'category': cat,\n",
    "                'user_id': f'user_{np.random.randint(0, 10000)}',\n",
    "                'text_length': len(text),\n",
    "                'num_caps': sum(1 for c in text if c.isupper()),\n",
    "                'hour_posted': np.random.randint(0, 24),\n",
    "                'user_age_days': np.random.exponential(365),\n",
    "                'prior_violations': np.random.poisson(0.5),\n",
    "                'timestamp': pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 365))\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['is_violation'] = (df['category'] != 'safe').astype(int)\n",
    "        print(f'Generated {len(df)} samples')\n",
    "        print(df['category'].value_counts())\n",
    "        return df\n",
    "\n",
    "gen = ContentDataGenerator()\n",
    "df = gen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample data:')\n",
    "print(df[['content_id', 'text', 'category', 'is_violation']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "cat_counts = df['category'].value_counts()\n",
    "colors = ['#27ae60' if c == 'safe' else '#e74c3c' for c in cat_counts.index]\n",
    "axes[0].bar(cat_counts.index, cat_counts.values, color=colors, alpha=0.7)\n",
    "axes[0].set_title('Category Distribution')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "hourly = df.groupby('hour_posted')['is_violation'].mean()\n",
    "axes[1].plot(hourly.index, hourly.values, marker='o')\n",
    "axes[1].set_title('Violation Rate by Hour')\n",
    "axes[1].set_xlabel('Hour')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def fit_text(self, texts):\n",
    "        return self.tfidf.fit_transform(texts)\n",
    "    \n",
    "    def transform_text(self, texts):\n",
    "        return self.tfidf.transform(texts)\n",
    "    \n",
    "    def get_meta_features(self, df):\n",
    "        features = df[['text_length', 'num_caps', 'hour_posted', 'user_age_days', 'prior_violations']].copy()\n",
    "        features['caps_ratio'] = df['num_caps'] / (df['text_length'] + 1)\n",
    "        features['is_new_user'] = (df['user_age_days'] < 30).astype(int)\n",
    "        features['is_repeat'] = (df['prior_violations'] > 0).astype(int)\n",
    "        return features.values\n",
    "    \n",
    "    def encode_labels(self, labels):\n",
    "        return self.le.fit_transform(labels)\n",
    "\n",
    "fe = FeatureEngineering()\n",
    "X_text = fe.fit_text(df['text'])\n",
    "X_meta = fe.get_meta_features(df)\n",
    "y_binary = df['is_violation'].values\n",
    "y_multi = fe.encode_labels(df['category'])\n",
    "\n",
    "print(f'Text features: {X_text.shape}')\n",
    "print(f'Meta features: {X_meta.shape}')\n",
    "print(f'Categories: {fe.le.classes_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('timestamp')\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "\n",
    "train_idx = df_sorted.index[:split_idx]\n",
    "test_idx = df_sorted.index[split_idx:]\n",
    "\n",
    "X_text_train, X_text_test = X_text[train_idx], X_text[test_idx]\n",
    "X_meta_train, X_meta_test = X_meta[train_idx], X_meta[test_idx]\n",
    "y_train, y_test = y_binary[train_idx], y_binary[test_idx]\n",
    "\n",
    "print(f'Train: {len(train_idx)}, Test: {len(test_idx)}')\n",
    "print(f'Train violation rate: {y_train.mean():.3f}')\n",
    "print(f'Test violation rate: {y_test.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Model Development\n",
    "\n",
    "## 3.1 Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        print('Training Text Classifier...')\n",
    "        self.model.fit(X, y)\n",
    "        print(f'  Train accuracy: {self.model.score(X, y):.4f}')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "text_clf = TextClassifier()\n",
    "text_clf.fit(X_text_train, y_train)\n",
    "\n",
    "y_pred = text_clf.predict(X_text_test)\n",
    "print('\\nText Classifier Performance:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Safe', 'Violation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleClassifier:\n",
    "    def __init__(self, text_weight=0.7):\n",
    "        self.text_weight = text_weight\n",
    "        self.text_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        self.meta_model = GradientBoostingClassifier(n_estimators=50, max_depth=5)\n",
    "        \n",
    "    def fit(self, X_text, X_meta, y):\n",
    "        print('Training Ensemble...')\n",
    "        self.text_model.fit(X_text, y)\n",
    "        self.meta_model.fit(X_meta, y)\n",
    "        print('  Training complete')\n",
    "        \n",
    "    def predict_proba(self, X_text, X_meta):\n",
    "        text_prob = self.text_model.predict_proba(X_text)[:, 1]\n",
    "        meta_prob = self.meta_model.predict_proba(X_meta)[:, 1]\n",
    "        return self.text_weight * text_prob + (1 - self.text_weight) * meta_prob\n",
    "    \n",
    "    def predict(self, X_text, X_meta, threshold=0.5):\n",
    "        return (self.predict_proba(X_text, X_meta) >= threshold).astype(int)\n",
    "\n",
    "ensemble = EnsembleClassifier()\n",
    "ensemble.fit(X_text_train, X_meta_train, y_train)\n",
    "\n",
    "y_prob = ensemble.predict_proba(X_text_test, X_meta_test)\n",
    "y_pred = ensemble.predict(X_text_test, X_meta_test)\n",
    "\n",
    "print('\\nEnsemble Performance:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Safe', 'Violation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Evaluation\n",
    "\n",
    "## 4.1 Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_prob):\n",
    "    precs, recs, threshs = precision_recall_curve(y_true, y_prob)\n",
    "    f1s = [2*p*r/(p+r) if (p+r) > 0 else 0 for p, r in zip(precs[:-1], recs[:-1])]\n",
    "    best_idx = np.argmax(f1s)\n",
    "    return threshs[best_idx], precs, recs, threshs\n",
    "\n",
    "opt_thresh, precs, recs, threshs = find_optimal_threshold(y_test, y_prob)\n",
    "print(f'Optimal threshold: {opt_thresh:.3f}')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(recs, precs[:-1], 'b-', lw=2)\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision-Recall Curve')\n",
    "axes[0].axhline(0.9, color='r', ls='--', label='Precision target')\n",
    "axes[0].axvline(0.95, color='g', ls='--', label='Recall target')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "f1s = [2*p*r/(p+r) if (p+r) > 0 else 0 for p, r in zip(precs[:-1], recs[:-1])]\n",
    "axes[1].plot(threshs, f1s, 'g-', lw=2)\n",
    "axes[1].axvline(opt_thresh, color='r', ls='--', label=f'Optimal: {opt_thresh:.2f}')\n",
    "axes[1].set_xlabel('Threshold')\n",
    "axes[1].set_ylabel('F1')\n",
    "axes[1].set_title('F1 vs Threshold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Decision Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionEngine:\n",
    "    def __init__(self, remove_thresh=0.9, review_thresh=0.5):\n",
    "        self.remove_thresh = remove_thresh\n",
    "        self.review_thresh = review_thresh\n",
    "        \n",
    "    def decide(self, probs):\n",
    "        decisions = []\n",
    "        for p in probs:\n",
    "            if p >= self.remove_thresh:\n",
    "                decisions.append('REMOVE')\n",
    "            elif p >= self.review_thresh:\n",
    "                decisions.append('REVIEW')\n",
    "            else:\n",
    "                decisions.append('ALLOW')\n",
    "        return decisions\n",
    "\n",
    "engine = DecisionEngine()\n",
    "decisions = engine.decide(y_prob)\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(decisions)\n",
    "print('Decision Distribution:')\n",
    "for d, c in counts.items():\n",
    "    print(f'  {d}: {c} ({c/len(decisions)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_opt = (y_prob >= opt_thresh).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_opt)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pred Safe', 'Pred Violation'],\n",
    "            yticklabels=['Actual Safe', 'Actual Violation'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'False Positives (over-moderation): {fp} ({fp/(tn+fp)*100:.2f}%)')\n",
    "print(f'False Negatives (missed): {fn} ({fn/(tp+fn)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModerationService:\n",
    "    def __init__(self, ensemble, decision_engine, feature_eng):\n",
    "        self.ensemble = ensemble\n",
    "        self.engine = decision_engine\n",
    "        self.fe = feature_eng\n",
    "        \n",
    "    def moderate(self, content):\n",
    "        import time\n",
    "        start = time.time()\n",
    "        \n",
    "        text_feat = self.fe.tfidf.transform([content['text']])\n",
    "        meta_df = pd.DataFrame([{\n",
    "            'text_length': len(content['text']),\n",
    "            'num_caps': sum(1 for c in content['text'] if c.isupper()),\n",
    "            'hour_posted': content.get('hour', 12),\n",
    "            'user_age_days': content.get('user_age', 365),\n",
    "            'prior_violations': content.get('prior_violations', 0)\n",
    "        }])\n",
    "        meta_feat = self.fe.get_meta_features(meta_df)\n",
    "        \n",
    "        prob = self.ensemble.predict_proba(text_feat, meta_feat)[0]\n",
    "        decision = self.engine.decide([prob])[0]\n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        return {\n",
    "            'content_id': content.get('id', 'unknown'),\n",
    "            'probability': round(prob, 4),\n",
    "            'decision': decision,\n",
    "            'latency_ms': round(latency, 2)\n",
    "        }\n",
    "\n",
    "service = ModerationService(ensemble, engine, fe)\n",
    "\n",
    "# Test\n",
    "test_items = [\n",
    "    {'id': '1', 'text': 'What a beautiful day for a walk'},\n",
    "    {'id': '2', 'text': 'You are so stupid nobody likes you'},\n",
    "    {'id': '3', 'text': 'CLICK HERE for FREE money NOW'},\n",
    "]\n",
    "\n",
    "print('Moderation Results:')\n",
    "for item in test_items:\n",
    "    result = service.moderate(item)\n",
    "    print(f\"  {result['content_id']}: {result['decision']} (p={result['probability']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModerationMonitor:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "        \n",
    "    def log(self, content_id, decision, prob, latency, actual=None):\n",
    "        self.logs.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'content_id': content_id,\n",
    "            'decision': decision,\n",
    "            'prob': prob,\n",
    "            'latency': latency,\n",
    "            'actual': actual\n",
    "        })\n",
    "    \n",
    "    def metrics(self):\n",
    "        if not self.logs:\n",
    "            return {}\n",
    "        df = pd.DataFrame(self.logs)\n",
    "        return {\n",
    "            'total': len(df),\n",
    "            'decisions': df['decision'].value_counts().to_dict(),\n",
    "            'latency_p50': df['latency'].quantile(0.5),\n",
    "            'latency_p99': df['latency'].quantile(0.99)\n",
    "        }\n",
    "\n",
    "monitor = ModerationMonitor()\n",
    "\n",
    "# Simulate\n",
    "test_df = df.iloc[test_idx]\n",
    "for _, row in test_df.sample(500).iterrows():\n",
    "    result = service.moderate({'id': row['content_id'], 'text': row['text']})\n",
    "    monitor.log(result['content_id'], result['decision'], result['probability'],\n",
    "               result['latency_ms'], row['is_violation'])\n",
    "\n",
    "m = monitor.metrics()\n",
    "print('Monitoring Metrics:')\n",
    "print(f\"  Total: {m['total']}\")\n",
    "print(f\"  Decisions: {m['decisions']}\")\n",
    "print(f\"  Latency p50: {m['latency_p50']:.2f}ms\")\n",
    "print(f\"  Latency p99: {m['latency_p99']:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Requirements**: Define content categories, scale, latency, and accuracy targets\n",
    "2. **Class Imbalance**: Most content is safe (85%+), use balanced class weights\n",
    "3. **Multi-Level Decisions**: REMOVE/REVIEW/ALLOW based on probability thresholds\n",
    "4. **Threshold Tuning**: Balance precision (avoid over-moderation) and recall (catch violations)\n",
    "5. **Monitoring**: Track false positives/negatives, latency, and decision distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "7-Step Framework Applied to Content Moderation\n",
    "==============================================\n",
    "\n",
    "Step 1: Requirements\n",
    "  - Categories: hate_speech, harassment, spam, violence, safe\n",
    "  - Scale: 500M posts/day, 50K QPS\n",
    "  - Latency: p99 < 100ms\n",
    "  - Precision >= 0.90, Recall >= 0.95\n",
    "\n",
    "Step 2: Problem Framing\n",
    "  - Binary classification (violation vs safe)\n",
    "  - Multi-class for specific categories\n",
    "  - Multi-modal (text + images)\n",
    "\n",
    "Step 3: Data Preparation\n",
    "  - TF-IDF text features\n",
    "  - Metadata features (user history, text stats)\n",
    "  - Time-based split for evaluation\n",
    "\n",
    "Step 4: Model Development\n",
    "  - Text classifier (Logistic Regression)\n",
    "  - Metadata classifier (Gradient Boosting)\n",
    "  - Ensemble combining both\n",
    "\n",
    "Step 5: Evaluation\n",
    "  - Precision-Recall tradeoff\n",
    "  - Threshold optimization\n",
    "  - Error analysis (FP/FN)\n",
    "\n",
    "Step 6: Deployment\n",
    "  - Real-time moderation service\n",
    "  - Multi-level decision engine\n",
    "  - Human review queue\n",
    "\n",
    "Step 7: Monitoring\n",
    "  - Decision distribution\n",
    "  - Latency tracking\n",
    "  - False positive/negative rates\n",
    "\"\"\")\n",
    "\n",
    "print('Tutorial 20 Complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}